"1705.09242","David Coomes Prof","Tommaso Jucker, Gregory P. Asner, Michele Dalponte, Philip Brodrick,
  Christopher D. Philipson, Nick Vaughn, Craig Brelsford, David F.R.P. Burslem,
  Nicholas J. Deere, Robert M. Ewers, Jakub Kvasnica, Simon L. Lewis, Yadvinder
  Malhi, Sol Milne, Reuben Nilus, Marion Pfeifer, Oliver Phillips, Lan Qie,
  Nathan Renneboog, Glen Reynolds, Terhi Riutta, Matthew J. Struebig, Martin
  Sv\'atek, Yit Arn Teh, Edgar C. Turner and David A. Coomes","A regional model for estimating the aboveground carbon density of
  Borneo's tropical forests from airborne laser scanning",,,,,"q-bio.QM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Borneo contains some of the world's most biodiverse and carbon dense tropical
forest, but this 750,000-km2 island has lost 62% of its old-growth forests
within the last 40 years. Efforts to protect and restore the remaining forests
of Borneo hinge on recognising the ecosystem services they provide, including
their ability to store and sequester carbon. Airborne Laser Scanning (ALS) is a
remote sensing technology that allows forest structural properties to be
captured in great detail across vast geographic areas. In recent years ALS has
been integrated into state-wide assessment of forest carbon in Neotropical and
African regions, but not yet in Asia. For this to happen new regional models
need to be developed for estimating carbon stocks from ALS in tropical Asia, as
the forests of this region are structurally and compositionally distinct from
those found elsewhere in the tropics. By combining ALS imagery with data from
173 permanent forest plots spanning the lowland rain forests of Sabah, on the
island of Borneo, we develop a simple-yet-general model for estimating forest
carbon stocks using ALS-derived canopy height and canopy cover as input
metrics. An advanced feature of this new model is the propagation of
uncertainty in both ALS- and ground-based data, allowing uncertainty in
hectare-scale estimates of carbon stocks to be quantified robustly. We show
that the model effectively captures variation in aboveground carbons stocks
across extreme disturbance gradients spanning tall dipterocarp forests and
heavily logged regions, and clearly outperforms existing ALS-based models
calibrated for the tropics, as well as currently available satellite-derived
products. Our model provides a simple, generalised and effective approach for
mapping forest carbon stocks in Borneo, providing a key tool to support the
protection and restoration of its tropical forests.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 16:01:15 GMT""}]","2017-05-26"
"1705.09243","Michael A. Hermele","Sheng-Jie Huang, Hao Song, Yi-Ping Huang, Michael Hermele","Building crystalline topological phases from lower-dimensional states","18+14 pages. S.-J.H. and H.S. are co-first-authors. v2: published
  version","Phys. Rev. B 96, 205106 (2017)","10.1103/PhysRevB.96.205106",,"cond-mat.str-el cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the classification of symmetry protected topological (SPT) phases
with crystalline symmetry (cSPT phases). Focusing on bosonic cSPT phases in two
and three dimensions, we introduce a simple family of cSPT states, where the
system is comprised of decoupled lower-dimensional building blocks that are
themselves SPT states. We introduce a procedure to classify these block states,
which surprisingly reproduces a classification of cSPT phases recently obtained
by Thorngren and Else using very different methods, for all wallpaper and space
groups. The explicit constructions underlying our results clarify the physical
properties of the phases classified by Thorngren and Else, and expose
additional structure in the classification. Moreover, the states we classify
can be completely characterized by point group SPT (pgSPT) invariants and
related weak pgSPT invariants that we introduce. In many cases, the weak
invariants can be visualized in terms of translation-symmetric stacking of
lower-dimensional pgSPT states. We apply our classification to propose a
Lieb-Shultz-Mattis type constraint for two-dimensional spin systems with only
crystalline symmetry, and establish this constraint by a dimensional reduction
argument. Finally, the surprising matching with the Thorngren-Else
classification leads us to conjecture that all SPT phases protected only by
crystalline symmetry can be built from lower-dimensional blocks of invertible
topological states. We argue that this conjecture holds if we make a certain
physically reasonable but unproven assumption.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 16:04:17 GMT""},{""version"":""v2"",""created"":""Tue, 19 Dec 2017 18:33:55 GMT""}]","2017-12-20"
"1705.09244","Daniel Loughran","Daniel Loughran, Ramin Takloo-Bighash, and Sho Tanimoto","Zero-loci of Brauer group elements on semi-simple algebraic groups","35 pages. Added more details and fixed typos. Final version",,,,"math.NT math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the problem of counting the number of rational points of bounded
height in the zero-loci of Brauer group elements on semi-simple algebraic
groups over number fields. We obtain asymptotic formulae for the counting
problem for wonderful compactifications using the spectral theory of
automorphic forms. Applications include asymptotic formulae for the number of
matrices over Q whose determinant is a sum of two squares. These results
provide a positive answer to some cases of a question of Serre concerning such
counting problems.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 16:12:04 GMT""},{""version"":""v2"",""created"":""Mon, 8 Oct 2018 09:53:41 GMT""}]","2018-10-09"
"1705.09245","Pei-Sheng Lin","Pei-Sheng Lin, Denis Rosset, Yanbao Zhang, Jean-Daniel Bancal, and
  Yeong-Cherng Liang","Device-independent point estimation from finite data and its application
  to device-independent property estimation","Essentially published version, but with the typo in Eq. (E5)
  corrected","Phys. Rev. A 97, 032309 (2018)","10.1103/PhysRevA.97.032309",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The device-independent approach to physics is one where conclusions are drawn
directly from the observed correlations between measurement outcomes. In
quantum information, this approach allows one to make strong statements about
the properties of the underlying systems or devices solely via the observation
of Bell-inequality-violating correlations. However, since one can only perform
a {\em finite number} of experimental trials, statistical fluctuations
necessarily accompany any estimation of these correlations. Consequently, an
important gap remains between the many theoretical tools developed for the
asymptotic scenario and the experimentally obtained raw data. In particular, a
physical and concurrently practical way to estimate the underlying quantum
distribution has so far remained elusive. Here, we show that the natural
analogs of the maximum-likelihood estimation technique and the
least-square-error estimation technique in the device-independent context
result in point estimates of the true distribution that are physical, unique,
computationally tractable and consistent. They thus serve as sound algorithmic
tools allowing one to bridge the aforementioned gap. As an application, we
demonstrate how such estimates of the underlying quantum distribution can be
used to provide, in certain cases, trustworthy estimates of the amount of
entanglement present in the measured system. In stark contrast to existing
approaches to device-independent parameter estimations, our estimation does not
require the prior knowledge of {\em any} Bell inequality tailored for the
specific property and the specific distribution of interest.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 16:14:12 GMT""},{""version"":""v2"",""created"":""Thu, 20 Jul 2017 09:33:19 GMT""},{""version"":""v3"",""created"":""Thu, 26 Oct 2017 05:00:26 GMT""},{""version"":""v4"",""created"":""Fri, 16 Mar 2018 17:29:55 GMT""},{""version"":""v5"",""created"":""Tue, 27 Mar 2018 02:40:31 GMT""}]","2018-03-28"
"1705.09246","Andrea Giusti","Andrea Giusti, Ivano Colombaro","Prabhakar-like fractional viscoelasticity","9 pages","Comm. Nonlin. Sci. Num. Sim. 56C (2018) pp. 138-143","10.1016/j.cnsns.2017.08.002",,"math-ph cond-mat.mtrl-sci math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The aim of this paper is to present a linear viscoelastic model based on
Prabhakar fractional operators. In particular, we propose a modification of the
classical fractional Maxwell model, in which we replace the Caputo derivative
with the Prabhakar one. Furthermore, we also discuss how to recover a formal
equivalence between the new model and the known classical models of linear
viscoelasticity by means of a suitable choice of the parameters in the
Prabhakar derivative. Moreover, we also underline an interesting connection
between the theory of Prabhakar fractional integrals and the recently
introduced Caputo-Fabrizio differential operator.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 16:18:48 GMT""},{""version"":""v2"",""created"":""Sun, 28 May 2017 11:00:27 GMT""},{""version"":""v3"",""created"":""Sun, 6 Aug 2017 10:05:16 GMT""},{""version"":""v4"",""created"":""Wed, 9 Aug 2017 06:15:58 GMT""}]","2017-08-10"
"1705.09247","Yusuke Yamada","Renata Kallosh, Andrei Linde, Diederik Roest, Yusuke Yamada","$\overline{D3}$ Induced Geometric Inflation","22 pages, 7 figures, v2: typos corrected, v3: references added",,"10.1007/JHEP07(2017)057",,"hep-th astro-ph.CO gr-qc hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Effective supergravity inflationary models induced by anti-D3 brane
interaction with the moduli fields in the bulk geometry have a geometric
description. The K\""ahler function carries the complete geometric information
on the theory. The non-vanishing bisectional curvature plays an important role
in the construction. The new geometric formalism, with the nilpotent superfield
representing the anti-D3 brane, allows a powerful generalization of the
existing inflationary models based on supergravity. They can easily incorporate
arbitrary values of the Hubble parameter, cosmological constant and gravitino
mass. We illustrate it by providing generalized versions of polynomial chaotic
inflation, T- and E-models of $\alpha$-attractor type, disk merger. We also
describe a multi-stage cosmological attractor regime, which we call cascade
inflation.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 16:21:23 GMT""},{""version"":""v2"",""created"":""Thu, 1 Jun 2017 19:54:53 GMT""},{""version"":""v3"",""created"":""Fri, 18 Aug 2017 19:09:34 GMT""}]","2017-08-22"
"1705.09248","Edgar Costa","Edgar Costa, Nicolas Mascot, Jeroen Sijsling and John Voight","Rigorous computation of the endomorphism ring of a Jacobian","37 pages, 1 figure; v5 missing reference added",,"10.1090/mcom/3373",,"math.NT math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We describe several improvements to algorithms for the rigorous computation
of the endomorphism ring of the Jacobian of a curve defined over a number
field.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 16:25:09 GMT""},{""version"":""v2"",""created"":""Sun, 14 Jan 2018 17:06:04 GMT""},{""version"":""v3"",""created"":""Tue, 24 Apr 2018 12:23:10 GMT""},{""version"":""v4"",""created"":""Tue, 4 Jun 2019 22:27:10 GMT""},{""version"":""v5"",""created"":""Thu, 9 Jan 2020 18:49:33 GMT""}]","2020-01-10"
"1705.09249","Xinwei Sun","Xinwei Sun, Lingjing Hu, Yuan Yao, Yizhou Wang","GSplit LBI: Taming the Procedural Bias in Neuroimaging for Disease
  Prediction","Conditional Accepted by Miccai,2017",,,,"stat.AP q-bio.NC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In voxel-based neuroimage analysis, lesion features have been the main focus
in disease prediction due to their interpretability with respect to the related
diseases. However, we observe that there exists another type of features
introduced during the preprocessing steps and we call them ""\textbf{Procedural
Bias}"". Besides, such bias can be leveraged to improve classification accuracy.
Nevertheless, most existing models suffer from either under-fit without
considering procedural bias or poor interpretability without differentiating
such bias from lesion ones. In this paper, a novel dual-task algorithm namely
\emph{GSplit LBI} is proposed to resolve this problem. By introducing an
augmented variable enforced to be structural sparsity with a variable splitting
term, the estimators for prediction and selecting lesion features can be
optimized separately and mutually monitored by each other following an
iterative scheme. Empirical experiments have been evaluated on the Alzheimer's
Disease Neuroimaging Initiative\thinspace(ADNI) database. The advantage of
proposed model is verified by improved stability of selected lesion features
and better classification results.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 16:25:14 GMT""},{""version"":""v2"",""created"":""Sun, 11 Jun 2017 06:01:19 GMT""}]","2017-06-13"
"1705.09250","Andrea Galliani","Andrea Galliani, Stefano Giusto, Rodolfo Russo","Holographic 4-point correlators with heavy states","31 pages; v3: citations added, typos corrected",,"10.1007/JHEP10(2017)040",,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The AdS/CFT duality maps supersymmetric heavy operators with conformal
dimension of the order of the central charge to asymptotically AdS supergravity
solutions. We show that by studying the quadratic fluctuations around such
backgrounds it is possible to derive the 4-point correlators of two light and
two heavy states in the supergravity approximation. We provide an explicit
example in the AdS$_3$ setup relevant for the duality with the D1-D5 CFT.
Contrary to previously studied examples, the supergravity correlator derived in
this work differs from the result obtained at the CFT orbifold point. Our
method bypasses the difficulties of applying the standard Witten's diagrams
approach to correlators with operators of large conformal dimension and also
avoids some technical steps that have made the computation of dynamical 4-point
correlators in the AdS$_3$/CFT$_2$ context unfeasible until now.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 16:26:09 GMT""},{""version"":""v2"",""created"":""Wed, 14 Jun 2017 15:04:23 GMT""},{""version"":""v3"",""created"":""Wed, 18 Oct 2017 19:38:18 GMT""}]","2017-10-25"
"1705.09251","Hector Pasten","Hector Pasten","Shimura curves and the abc conjecture","Several improvements and new applications. Added an appendix by R.
  Lemke Oliver and J. Thorner which allows one to relax some conditions in the
  totally real case. Degree comparison (Sec. 6) is now done differently, to
  bypass certain technical gap in the literature (explained in the text).
  Results and structure of the paper are now outlined in more detail in the
  introduction",,,,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We develop a general framework to study Szpiro's conjecture and the $abc$
conjecture by means of Shimura curves and their maps to elliptic curves,
introducing new techniques that allow us to obtain several unconditional
results for these conjectures. We first prove various general results about
modular and Shimura curves, including bounds for the Manin constant in the case
of additive reduction, a detailed study of maps from Shimura curves to elliptic
curves and comparisons between their degrees, and lower bounds for the
Petersson norm of integral modular forms on Shimura curves. Our main
applications for Szpiro's conjecture and the $abc$ conjecture include improved
effective bounds for the Faltings height of elliptic curves over $\mathbb{Q}$
in terms of the conductor, bounds for products of $p$-adic valuations of the
discriminant of elliptic curves over $\mathbb{Q}$ which are polynomial on the
conductor, and results that yield a modular approach to Szpiro's conjecture
over totally real number fields with the expected dependence on the
discriminant of the field. These applications lie beyond the scope of previous
techniques in the subject. A main difficulty in the theory is the lack of
$q$-expansions, which we overcome by making essential use of suitable integral
models and CM points. Our proofs require a number of tools from Arakelov
geometry, analytic number theory, Galois representations, complex-analytic
estimates on Shimura curves, automorphic forms, known cases of the Colmez
conjecture, and results on generalized Fermat equations.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 16:32:46 GMT""},{""version"":""v2"",""created"":""Sun, 4 Jun 2017 23:46:33 GMT""},{""version"":""v3"",""created"":""Sun, 27 Aug 2017 22:36:42 GMT""},{""version"":""v4"",""created"":""Thu, 5 Jul 2018 15:29:06 GMT""}]","2018-07-06"
"1705.09252","Zhichao Ruan","Yisheng Fang, Yijie Lou, Zhichao Ruan","On-grating graphene surface plasmons enabling spatial differentiation in
  terahertz region",,,"10.1364/OL.42.003840",,"physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a graphene-on-grating nanostructure to enable second-order spatial
differentiation computation in terahertz (THz) region. The differentiation
operation is based on the interference between the direct reflected field and
the leakage of two excited surface plasmon polaritons counter-propagating along
the graphene sheet. With the spatial coupled-mode theory, we derive out that
the requirement for the second-order spatial differentiation is the critical
coupling condition. We numerically demonstrate such an analog computation with
Gaussian beams. It shows that the spatial bandwidth of the proposed
differentiator is large enough such that even when the waist radius of the
Gaussian beam is as narrow as ${{w}_{0}}=0.68\lambda $ ($\lambda $ is the
free-space wavelength), the accuracy of the differentiator is higher than 95\%.
The proposed differentiator is ultra-compact, with a thickness less than
$0.1\lambda $, and useful for real-time imaging applications in THz security
detections.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 16:36:20 GMT""}]","2017-10-11"
"1705.09253","Konrad Swanepoel","M\'arton Nasz\'odi and Konrad J. Swanepoel","Arrangements of homothets of a convex body II","9 pages","Contributions to Discrete Mathematics 13 (2018), 116--123","10.11575/cdm.v13i2.62732",,"math.MG math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A family of homothets of an o-symmetric convex body K in d-dimensional
Euclidean space is called a Minkowski arrangement if no homothet contains the
center of any other homothet in its interior. We show that any pairwise
intersecting Minkowski arrangement of a d-dimensional convex body has at most
$2\cdot 3^d$ members. This improves a result of Polyanskii (arXiv:1610.04400).
Using similar ideas, we also give a proof the following result of Polyanskii:
Let $K_1,\dots,K_n$ be a sequence of homothets of the o-symmetric convex body
$K$, such that for any $i<j$, the center of $K_j$ lies on the boundary of
$K_i$. Then $n\leq O(3^d d)$.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 16:38:26 GMT""}]","2020-02-25"
"1705.09254","Ctirad Klimcik","Peter Bouwknegt, Mark Bugden, Ctirad Klimcik and Kyle Wright","Hidden isometry of ""T-duality without isometry""","15 pages",,"10.1007/JHEP08(2017)116",,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the T-dualisability criteria of Chatzistavrakidis, Deser and Jonke
[3] who recently used Lie algebroid gauge theories to obtain sigma models
exhibiting a ""T-duality without isometry"". We point out that those
T-dualisability criteria are not written invariantly in [3] and depend on the
choice of the algebroid framing. We then show that there always exists an
isometric framing for which the Lie algebroid gauging boils down to standard
Yang-Mills gauging. The ""T-duality without isometry"" of Chatzistavrakidis,
Deser and Jonke is therefore nothing but traditional isometric non-Abelian
T-duality in disguise.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 16:42:28 GMT""}]","2017-09-13"
"1705.09255","Benjamin Bode","Benjamin Bode","Constructing links of isolated singularities of polynomials
  $\mathbb{R}^4\to\mathbb{R}^2$","28 pages",,,,"math.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show that if a braid $B$ can be parametrised in a certain way, then
previous work can be extended to a construction of a polynomial
$f:\mathbb{R}^4\to\mathbb{R}^2$ with the closure of $B$ as the link of an
isolated singularity of $f$, showing that the closure of $B$ is real algebraic.
In particular, we prove that closures of squares of strictly homogeneous braids
and certain lemniscate links are real algebraic. We also show that the
constructed polynomials satisfy the strong Milnor condition, providing an
explicit fibration of the complement of the closure of $B$ over $S^1$.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 16:43:59 GMT""}]","2017-05-26"
"1705.09256","Remigijus Mikulevicius","R. Mikulevicius and C. Phonsom","On the Cauchy problem for integro-differential equations in the scale of
  spaces of generalized smoothness",,,,,"math.PR math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Parabolic integro-differential model Cauchy problem is considered in the
scale of Lp -spaces of functions whose regularity is defined by a scalable Levy
measure. Existence and uniqueness of a solution is proved by deriving apriori
estimates. Some rough probability density function estimates of the associated
Levy process are used as well.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 16:45:26 GMT""}]","2017-05-26"
"1705.09257","Vinicius Rodrigues Debastiani","V. R. Debastiani, J. M. Dias and E. Oset","Study of the $DKK$ and $DK\bar{K}$ systems","10 pages, 6 figures","Phys. Rev. D 96, 016014 (2017)","10.1103/PhysRevD.96.016014",,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Using the Fixed Center Approximation to Faddeev equations we have
investigated the $DKK$ and $DK\bar{K}$ three-body systems, considering that the
$DK$ dynamically generates, through its $I=0$ component, the $D^*_{s0}(2317)$
molecule. According to our findings, for $DK\bar{K}$ interaction we have found
an evidence of a state $I(J^P)=1/2(0^-)$ just above the $D^*_{s0}(2317)\bar{K}$
threshold and around the $Df_0(980)$ thresholds, with mass about $2833 - 2858$
MeV, made mostly of $Df_0(980)$. On the other hand, no evidence related to a
state from the $DKK$ interaction is found. The state found could be seen in the
$\pi \pi D$ invariant mass.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 16:48:26 GMT""}]","2017-08-01"
"1705.09258","Aleksey Fedorov","E.O. Kiktenko, N.O. Pozhar, M.N. Anufriev, A.S. Trushechkin, R.R.
  Yunusov, Y.V. Kurochkin, A.I. Lvovsky, and A.K. Fedorov","Quantum-secured blockchain","7 pages, 2 figures; published version","Quantum Sci. Technol. 3, 035004 (2018)","10.1088/2058-9565/aabc6b",,"quant-ph cs.CR cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Blockchain is a distributed database which is cryptographically protected
against malicious modifications. While promising for a wide range of
applications, current blockchain platforms rely on digital signatures, which
are vulnerable to attacks by means of quantum computers. The same, albeit to a
lesser extent, applies to cryptographic hash functions that are used in
preparing new blocks, so parties with access to quantum computation would have
unfair advantage in procuring mining rewards. Here we propose a possible
solution to the quantum era blockchain challenge and report an experimental
realization of a quantum-safe blockchain platform that utilizes quantum key
distribution across an urban fiber network for information-theoretically secure
authentication. These results address important questions about realizability
and scalability of quantum-safe blockchains for commercial and governmental
applications.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 16:52:10 GMT""},{""version"":""v2"",""created"":""Fri, 26 May 2017 17:46:49 GMT""},{""version"":""v3"",""created"":""Sun, 3 Jun 2018 10:51:11 GMT""}]","2018-06-05"
"1705.09259","Maika Takita","Maika Takita, Andrew W. Cross, A. D. C\'orcoles, Jerry M. Chow, Jay M.
  Gambetta","Experimental demonstration of fault-tolerant state preparation with
  superconducting qubits",,"Phys. Rev. Lett. 119, 180501 (2017)","10.1103/PhysRevLett.119.180501",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Robust quantum computation requires encoding delicate quantum information
into degrees of freedom that are hard for the environment to change. Quantum
encodings have been demonstrated in many physical systems by observing and
correcting storage errors, but applications require not just storing
information; we must accurately compute even with faulty operations. The theory
of fault-tolerant quantum computing illuminates a way forward by providing a
foundation and collection of techniques for limiting the spread of errors. Here
we implement one of the smallest quantum codes in a five-qubit superconducting
transmon device and demonstrate fault-tolerant state preparation. We
characterize the resulting codewords through quantum process tomography and
study the free evolution of the logical observables. Our results are consistent
with fault-tolerant state preparation in a protected qubit subspace.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 16:54:49 GMT""}]","2017-11-08"
"1705.09260","Nikita Kamraj","N. Kamraj, E. Rivers, F. A. Harrison, M. Brightman, M. Balokovic","The NuSTAR View of the Seyfert 2 Galaxy NGC 4388","5 pages, 2 figures. Accepted for publication in ApJ",,"10.3847/1538-4357/aa7563",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present analysis of NuSTAR X-ray observations in the 3-79 keV energy band
of the Seyfert 2 galaxy NGC 4388, taken in 2013. The broadband sensitivity of
NuSTAR, covering the Fe K$\alpha$ line and Compton reflection hump, enables
tight constraints to be placed on reflection features in AGN X-ray spectra,
thereby providing insight into the geometry of the circumnuclear material. In
this observation, we found the X-ray spectrum of NGC 4388 to be well described
by a moderately absorbed power law with non-relativistic reflection. We fit the
spectrum with phenomenological reflection models and a physical torus model,
and find the source to be absorbed by Compton-thin material (N$_{H} =
(6.5\pm0.8)\times10^{23}$ cm$^{-2}$) with a very weak Compton reflection hump
(R $<$ 0.09) and an exceptionally large Fe K$\alpha$ line (EW $=
368^{+56}_{-53}$ eV) for a source with weak or no reflection. Calculations
using a thin-shell approximation for the expected Fe K$\alpha$ EW indicate that
an Fe K$\alpha$ line originating from Compton-thin material presents a possible
explanation.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 17:01:19 GMT""}]","2017-07-19"
"1705.09261","Otfried G\""uhne","Joshua Lockhart, Otfried G\""uhne, Simone Severini","Entanglement properties of quantum grid states","6 pages, 4 figures, v2: small changes, final version","Phys. Rev. A 97, 062340 (2018)","10.1103/PhysRevA.97.062340",,"quant-ph math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Grid states form a discrete set of mixed quantum states that can be described
by graphs. We characterize the entanglement properties of these states and
provide methods to evaluate entanglement criteria for grid states in a
graphical way. With these ideas we find bound entangled grid states for
two-particle systems of any dimension and multiparticle grid states that
provide examples for the different aspects of genuine multiparticle
entanglement. Our findings suggest that entanglement theory for grid states,
although being a discrete set, has already a complexity similar to the one for
general states.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 17:04:07 GMT""},{""version"":""v2"",""created"":""Fri, 24 Aug 2018 19:49:52 GMT""}]","2018-08-28"
"1705.09262","Ernesto Jimenez-Villar","Ernesto Jimenez-Villar, M.C. S. Xavier, Niklaus U. Wetter, Valdeci
  Mestre, Weliton S. Martins, Gabriel F. Basso, V. A. Ermakov, F. C. Marques,
  Gilberto F. de Sa","Anderson localization of light: Strong dependence with incident angle","In this lastest version of manuscript, new experiments were added
  and, additional ideas and concepts are introduced",,,,"cond-mat.mes-hall physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper studies the transport of light for different incidence angles in a
strongly disordered optical medium composed by core-shell nanoparticles
(TiO2@Silica) suspended in ethanol solution. A decrease of optical conductance
and an increase of absorption near the input border are reported when the
incidence angle is increased. We associated this phenomenon to an increase of
the density of localized states (localization increase) near the input border,
which could be explained by a large increase of internal reflection with the
incidence angle, which in turn would be a direct consequence of the enhancement
of the effective refractive index near the input border by localization itself.
The specular reflection, measured for the photons that enter the sample, is
considerably lower than the effective internal reflection undergone by the
coherently backscattered photons in the exact opposite direction, indicating a
non-reciprocal propagation of light (mirror-symmetry breaking). This study
represents a novel approach in order to understand the complex physics involved
in a strongly disordered optical medium at the critical regime of approaching
localization.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 17:07:43 GMT""},{""version"":""v2"",""created"":""Fri, 24 Nov 2017 18:06:25 GMT""},{""version"":""v3"",""created"":""Mon, 27 Nov 2017 13:12:33 GMT""},{""version"":""v4"",""created"":""Mon, 1 Oct 2018 17:41:30 GMT""}]","2018-10-16"
"1705.09263","Siddharth Prabhu","Walter D. Goldberger, Siddharth G. Prabhu, and Jedidiah O. Thompson","Classical gluon and graviton radiation from the bi-adjoint scalar double
  copy","9+2 pages, 1 figure. v3: Added an appendix. Published version","Phys. Rev. D 96, 065009 (2017)","10.1103/PhysRevD.96.065009",,"hep-th gr-qc hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We find double copy relations between classical radiating solutions in
Yang-Mills theory coupled to dynamical color charges and their counterparts in
a cubic bi-adjoint scalar field theory which interacts linearly with particles
carrying bi-adjoint charge. The particular color-to-kinematics replacements we
employ are motivated by the BCJ double copy correspondence for on-shell
amplitudes in gauge and gravity theories. They are identical to those recently
used to establish relations between classical radiating solutions in gauge
theory and in dilaton gravity. Our explicit bi-adjoint solutions are
constructed to second order in a perturbative expansion, and map under the
double copy onto gauge theory solutions which involve at most cubic gluon
self-interactions. If the correspondence is found to persist to higher orders
in perturbation theory, our results suggest the possibility of calculating
gravitational radiation from colliding compact objects, directly from a scalar
field with vastly simpler (purely cubic) Feynman vertices.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 17:09:57 GMT""},{""version"":""v2"",""created"":""Fri, 30 Jun 2017 15:47:02 GMT""},{""version"":""v3"",""created"":""Tue, 26 Dec 2017 20:00:24 GMT""}]","2017-12-29"
"1705.09264","Micha{\l} Tomza","Micha{\l} Tomza","Cold interactions and chemical reactions of linear polyatomic anions
  with alkali-metal and alkaline-earth-metal atoms","12 pages, 4 figures, 3 tables","Phys. Chem. Chem. Phys. 19, 16512 (2017)","10.1039/C7CP02127E",,"physics.atom-ph cond-mat.quant-gas physics.chem-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider collisional studies of linear polyatomic ions immersed in
ultracold atomic gases and investigate the intermolecular interactions and
chemical reactions of several molecular anions ($\mathrm{OH}^-$,
$\mathrm{CN}^-$, $\mathrm{NCO}^-$, $\mathrm{C}_2\mathrm{H}^-$,
$\mathrm{C}_4\mathrm{H}^-$) with alkali-metal (Li, Na, K, Rb, Cs) and
alkaline-earth-metal (Mg, Ca, Sr, Ba) atoms. State-of-the-art ab initio
techniques are applied to compute the potential energy surfaces (PESs) for
these systems. The coupled cluster method restricted to single, double, and
noniterative triple excitations, CCSD(T), is employed and the scalar
relativistic effects in heavier metal atoms are modeled within the small-core
energy-consistent pseudopotentials. The leading long-range isotropic and
anisotropic induction and dispersion interaction coefficients are obtained
within the perturbation theory. The PESs are characterized in detail and their
universal similarities typical for systems dominated by the induction
interaction are discussed. The two-dimensional PESs are provided for selected
systems and can be employed in scattering calculations. The possible channels
of chemical reactions and their control are analyzed based on the energetics of
reactants. The present study of the electronic structure is the first step
towards the evaluation of prospects for sympathetic cooling and controlled
chemistry of linear polyatomic ions with ultracold atoms.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 17:11:59 GMT""}]","2017-07-04"
"1705.09265","Riddhi Chatterjee","Riddhi Chatterjee and A. S. Majumdar","Preservation of quantum coherence under Lorentz boost for narrow
  uncertainty wave packets","9 pages, 9 figures, RevTeX 4-1, comments welcome","Phys. Rev. A 96, 052301 (2017)","10.1103/PhysRevA.96.052301",,"quant-ph gr-qc hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the effect of relativistic boosts on single particle Gaussian
wave packets. The coherence of the wave function as measured by the boosted
observer is studied as a function of the momentum and the boost parameter.
Using various formulations of coherence it is shown that in general the
coherence decays with the increase of the momentum of the state, as well as the
boost applied to it. Employing a basis-independent formulation, we show
however, that coherence may be preserved even for large boosts applied on
narrow uncertainty wave packets. Our result is exemplified quantitatively for
practically realizable neutron wave functions.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 17:13:55 GMT""}]","2017-11-08"
"1705.09266","Yoritaka Furukawa","Yoritaka Furukawa and Yu-ichiro Matsushita","Analysis of single and composite structural defects in pure amorphous
  silicon: a first-principles study",,,"10.1016/j.jnoncrysol.2017.07.031",,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The structural and electronic properties of amorphous silicon ($a$-Si) are
investigated by first-principles calculations based on the density-functional
theory (DFT), focusing on the intrinsic structural defects. By simulated
melting and quenching of a crystalline silicon model through the Car-Parrinello
molecular dynamics (CPMD), we generate several different $a$-Si samples, in
which three-fold ($T_3$), five-fold ($T_5$), and anomalous four-fold ($T_{4a}$)
defects are contained. Using the samples, we clarify how the disordered
structure of $a$-Si affects the characters of its density of states (DOS). We
subsequently study the properties of defect complexes found in the obtained
samples, including one that comprises three $T_5$ defects, and we show the
conditions for the defect complexes to be energetically stable. Finally, we
investigate the hydrogen passivation process of the $T_5$ defects in $a$-Si and
show that the hydrogenation of $T_5$ is an exothermic reaction and that the
activation energy for a H$_2$ molecule to passivate two $T_5$ sites is
calculated to be 1.05 eV.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 17:15:44 GMT""}]","2017-10-11"
"1705.09267","Shahram Abbassi","Akram Yaghouti, Mohsen Nejad-Asghar and Shahram Abbassi","The Kelvin-Helmholtz instability in the Orion nebula: The effect of
  radiation pressure","Accepted for publication in MNRAS","MNRAS 470, 2559 (2017)","10.1093/mnras/stx1327",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The recent observations of rippled structures on the surface of the Orion
molecular cloud (Bern\'{e} et al. 2010), have been attributed to the
Kelvin-Helmholtz (KH) instability. The wavelike structures which have mainly
seen near star-forming regions taking place at the interface between the hot
diffuse gas, which is ionized by massive stars, and the cold dense molecular
clouds. The radiation pressure of massive stars and stellar clusters is one of
the important issues that has been considered frequently in the dynamics of
clouds. Here, we investigate the influence of radiation pressure, from
well-known Trapezium cluster in the Orion nebula, on the evolution of KH
instability. The stability of the interface between HII region and molecular
clouds in the presence of the radiation pressure, has been studied using the
linear perturbation analysis for the certain range of the wavelengths. The
linear analysis show that consideration of the radiation pressure intensifies
the growth rate of KH modes and consequently decreases the e-fold time-scale of
the instability. On the other hand the domain of the instability is extended
and includes the more wavelengths, consisting of smaller ones rather than the
case when the effect of the radiation pressure is not considered. Our results
shows that for $\lambda_{\rm KH}>0.15\rm pc$, the growth rate of KH instability
dose not depend to the radiation pressure. Based on our results, the radiation
pressure is a triggering mechanism in development of the KH instability and
subsequently formation of turbulent sub-structures in the molecular clouds near
massive stars. The role of magnetic fields in the presence of the radiation
pressure is also investigated and it is resulted that the magnetic field
suppresses the effects induced by the radiation pressure.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 17:19:47 GMT""}]","2017-07-26"
"1705.09268","Fangzhao An","Fangzhao Alex An, Eric J. Meier, and Bryce Gadway","Engineering a flux-dependent mobility edge in disordered zigzag chains","10 pages, 5 figures, 5 pages of supplementary materials; updated
  version has additional data","Phys. Rev. X 8, 031045 (2018)","10.1103/PhysRevX.8.031045",,"cond-mat.quant-gas cond-mat.dis-nn physics.atom-ph quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  There has been great interest in realizing quantum simulators of charged
particles in artificial gauge fields. Here, we perform the first quantum
simulation explorations of the combination of artificial gauge fields and
disorder. Using synthetic lattice techniques based on parametrically-coupled
atomic momentum states, we engineer zigzag chains with a tunable homogeneous
flux. The breaking of time-reversal symmetry by the applied flux leads to
analogs of spin-orbit coupling and spin-momentum locking, which we observe
directly through the chiral dynamics of atoms initialized to single lattice
sites. We additionally introduce precisely controlled disorder in the site
energy landscape, allowing us to explore the interplay of disorder and large
effective magnetic fields. The combination of correlated disorder and
controlled intra- and inter-row tunneling in this system naturally supports
energy-dependent localization, relating to a single-particle mobility edge. We
measure the localization properties of the extremal eigenstates of this system,
the ground state and the most-excited state, and demonstrate clear evidence for
a flux-dependent mobility edge. These measurements constitute the first direct
evidence for energy-dependent localization in a lower-dimensional system, as
well as the first explorations of the combined influence of artificial gauge
fields and engineered disorder. Moreover, we provide direct evidence for
interaction shifts of the localization transitions for both low- and
high-energy eigenstates in correlated disorder, relating to the presence of a
many-body mobility edge. The unique combination of strong interactions,
controlled disorder, and tunable artificial gauge fields present in this
synthetic lattice system should enable myriad explorations into intriguing
correlated transport phenomena.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 17:20:09 GMT""},{""version"":""v2"",""created"":""Tue, 10 Apr 2018 18:43:46 GMT""}]","2018-08-22"
"1705.09269","Joseph Anderson","Joseph Anderson","Geometric Methods for Robust Data Analysis in High Dimension","180 Pages, 7 Figures, PhD thesis, Ohio State (2017)",,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Machine learning and data analysis now finds both scientific and industrial
application in biology, chemistry, geology, medicine, and physics. These
applications rely on large quantities of data gathered from automated sensors
and user input. Furthermore, the dimensionality of many datasets is extreme:
more details are being gathered about single user interactions or sensor
readings. All of these applications encounter problems with a common theme: use
observed data to make inferences about the world. Our work obtains the first
provably efficient algorithms for Independent Component Analysis (ICA) in the
presence of heavy-tailed data. The main tool in this result is the centroid
body (a well-known topic in convex geometry), along with optimization and
random walks for sampling from a convex body. This is the first algorithmic use
of the centroid body and it is of independent theoretical interest, since it
effectively replaces the estimation of covariance from samples, and is more
generally accessible.
  This reduction relies on a non-linear transformation of samples from such an
intersection of halfspaces (i.e. a simplex) to samples which are approximately
from a linearly transformed product distribution. Through this transformation
of samples, which can be done efficiently, one can then use an ICA algorithm to
recover the vertices of the intersection of halfspaces.
  Finally, we again use ICA as an algorithmic primitive to construct an
efficient solution to the widely-studied problem of learning the parameters of
a Gaussian mixture model. Our algorithm again transforms samples from a
Gaussian mixture model into samples which fit into the ICA model and, when
processed by an ICA algorithm, result in recovery of the mixture parameters.
Our algorithm is effective even when the number of Gaussians in the mixture
grows polynomially with the ambient dimension
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 17:25:04 GMT""}]","2017-05-26"
"1705.09270","Alvise Bastianello","Alvise Bastianello and Andrea De Luca","Non-Equilibrium Steady State generated by a moving defect: the
  supersonic threshold","18 pages, 13 figures","Phys. Rev. Lett. 120, 060602 (2018)","10.1103/PhysRevLett.120.060602",,"cond-mat.stat-mech cond-mat.quant-gas quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the dynamics of a system of free fermions on a 1D lattice in the
presence of a defect moving at constant velocity. The defect has the form of a
localized time-dependent variation of the chemical potential and induces at
long times a Non-Equilibrium Steady State (NESS), which spreads around the
defect. We present a general formulation which allows recasting the
time-dependent protocol in a scattering problem on a static potential. We
obtain a complete characterization of the NESS. In particular, we show a strong
dependence on the defect velocity and the existence of a sharp threshold when
such velocity exceeds the speed of sound. Beyond this value, the NESS is not
produced and remarkably the defect travels without significantly perturbing the
system. We present an exact solution for a $\delta-$like defect traveling with
an arbitrary velocity and we develop a semiclassical approximation which
provides accurate results for smooth defects.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 17:30:58 GMT""},{""version"":""v2"",""created"":""Mon, 12 Feb 2018 17:14:48 GMT""}]","2018-02-13"
"1705.09271","Maxwell Young","William C. Anderton and Maxwell Young","Is Our Model for Contention Resolution Wrong?","Accepted to the 29th ACM Symposium on Parallelism in Algorithms and
  Architectures (SPAA 2017)",,,,"cs.DC cs.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Randomized binary exponential backoff (BEB) is a popular algorithm for
coordinating access to a shared channel. With an operational history exceeding
four decades, BEB is currently an important component of several wireless
standards. Despite this track record, prior theoretical results indicate that
under bursty traffic (1) BEB yields poor makespan and (2) superior algorithms
are possible. To date, the degree to which these findings manifest in practice
has not been resolved.
  To address this issue, we examine one of the strongest cases against BEB: $n$
packets that simultaneously begin contending for the wireless channel. Using
Network Simulator 3, we compare against more recent algorithms that are
inspired by BEB, but whose makespan guarantees are superior. Surprisingly, we
discover that these newer algorithms significantly underperform. Through
further investigation, we identify as the culprit a flawed but common
abstraction regarding the cost of collisions. Our experimental results are
complemented by analytical arguments that the number of collisions -- and not
solely makespan -- is an important metric to optimize. We believe that these
findings have implications for the design of contention-resolution algorithms.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 17:37:53 GMT""},{""version"":""v2"",""created"":""Thu, 1 Jun 2017 16:37:32 GMT""}]","2017-06-02"
"1705.09272","Abdel\^aali Boudjem\^aa abdou abdel aalim","Abdelaali Boudjemaa","Dipolar Bose gas with three-body interactions at finite temperature","5 pages, 3 figures",,"10.1088/1361-6455/aa9b8f",,"cond-mat.quant-gas","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate effects of three-body contact interactions on a trapped
dipolar Bose gas at finite temperature using the Hartree-Fock-Bogoliubov
approximation. We analyze numerically the behavior of the transition
temperature and the condensed fraction. Effects of the three-body interactions,
anomalous pair correlations and temperature on the collective modes are
discussed.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 17:38:15 GMT""}]","2018-01-17"
"1705.09274","Mats Andersson","Mats Andersson, Zbigniew B{\l}ocki, Elizabeth Wulcan","On a Monge-Amp\`ere operator for plurisubharmonic functions with
  analytic singularities",,,,,"math.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study continuity properties of generalized Monge-Amp\`ere operators for
plurisubharmonic functions with analytic singularities. In particular, we prove
continuity for a natural class of decreasing approximating sequences. We also
prove a formula for the total mass of the Monge-Amp\`ere measure of such a
function on a compact K\""ahler manifold.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 17:46:10 GMT""},{""version"":""v2"",""created"":""Fri, 9 Jun 2017 12:20:22 GMT""},{""version"":""v3"",""created"":""Sun, 19 Nov 2017 18:15:23 GMT""}]","2017-11-21"
"1705.09275","Wenjian Hu","Wenjian Hu, Krishna Kumar Singh, Fanyi Xiao, Jinyoung Han, Chen-Nee
  Chuah, Yong Jae Lee","Who Will Share My Image? Predicting the Content Diffusion Path in Online
  Social Networks","9 pages, 6 figures",,,,"cs.CV cs.SI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Content popularity prediction has been extensively studied due to its
importance and interest for both users and hosts of social media sites like
Facebook, Instagram, Twitter, and Pinterest. However, existing work mainly
focuses on modeling popularity using a single metric such as the total number
of likes or shares. In this work, we propose Diffusion-LSTM, a memory-based
deep recurrent network that learns to recursively predict the entire diffusion
path of an image through a social network. By combining user social features
and image features, and encoding the diffusion path taken thus far with an
explicit memory cell, our model predicts the diffusion path of an image more
accurately compared to alternate baselines that either encode only image or
social features, or lack memory. By mapping individual users to user
prototypes, our model can generalize to new users not seen during training.
Finally, we demonstrate our model's capability of generating diffusion trees,
and show that the generated trees closely resemble ground-truth trees.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 17:46:52 GMT""},{""version"":""v2"",""created"":""Sat, 3 Jun 2017 19:53:05 GMT""},{""version"":""v3"",""created"":""Tue, 24 Oct 2017 06:00:27 GMT""},{""version"":""v4"",""created"":""Wed, 29 Nov 2017 18:40:13 GMT""}]","2017-11-30"
"1705.09276","Yue Wang","Yue Wang and Yeye He","Synthesizing Mapping Relationships Using Table Corpus","The long version of a paper published at SIGMOD 2017",,,,"cs.DB","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Mapping relationships, such as (country, country-code) or (company,
stock-ticker), are versatile data assets for an array of applications in data
cleaning and data integration like auto-correction and auto-join. However,
today there are no good repositories of mapping tables that can enable these
intelligent applications.
  Given a corpus of tables such as web tables or spreadsheet tables, we observe
that values of these mappings often exist in pairs of columns in same tables.
Motivated by their broad applicability, we study the problem of synthesizing
mapping relationships using a large table corpus. Our synthesis process
leverages compatibility of tables based on co-occurrence statistics, as well as
constraints such as functional dependency. Experiment results using web tables
and enterprise spreadsheets suggest that the proposed approach can produce high
quality mappings.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 17:46:55 GMT""},{""version"":""v2"",""created"":""Tue, 30 May 2017 17:52:50 GMT""}]","2017-05-31"
"1705.09277","Roman Popovych","Stanislav Opanasenko, Alexander Bihlo, Roman O. Popovych and Artur
  Sergyeyev","Extended symmetry analysis of isothermal no-slip drift flux model","29 pages, minor corrections","Phys. D 402 (2020), 132188","10.1016/j.physd.2019.132188",,"math.AP math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We perform extended group analysis for a system of differential equations
modeling an isothermal no-slip drift flux. The maximal Lie invariance algebra
of this system is proved to be infinite-dimensional. We also find the complete
point symmetry group of this system, including discrete symmetries, using the
megaideal-based version of the algebraic method. Optimal lists of one- and
two-dimensional subalgebras of the maximal Lie invariance algebra in question
are constructed and employed for obtaining reductions of the system under
study. Since this system contains a subsystem of two equations that involves
only two of three dependent variables, we also perform group analysis of this
subsystem. The latter can be linearized by a composition of a fiber-preserving
point transformation with a two-dimensional hodograph transformation to the
Klein-Gordon equation. We also employ both the linearization and the
generalized hodograph method for constructing the general solution of the
entire system under study. We find inter alia genuinely generalized symmetries
for this system and present the connection between them and the Lie symmetries
of the subsystem we mentioned earlier. Hydrodynamic conservation laws and their
generalizations are also constructed.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 17:48:24 GMT""},{""version"":""v2"",""created"":""Tue, 22 Jan 2019 21:02:49 GMT""},{""version"":""v3"",""created"":""Thu, 4 Apr 2019 11:48:26 GMT""},{""version"":""v4"",""created"":""Tue, 31 Dec 2019 10:28:17 GMT""}]","2020-01-01"
"1705.09278","Narayan Banerjee","Weiqiang Yang, Narayan Banerjee and Supriya Pan","Constraining a dark matter and dark energy interaction scenario with a
  dynamical equation of state","Accepted for publication in Physical Review D",,"10.1103/PhysRevD.95.123527",,"astro-ph.CO gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work we have used the recent cosmic chronometers data along with the
latest estimation of the local Hubble parameter value, $H_0$ at 2.4\% precision
as well as the standard dark energy probes, such as the Supernovae Type Ia,
baryon acoustic oscillation distance measurements, and cosmic microwave
background measurements (PlanckTT $+$ lowP) to constrain a dark energy model
where the dark energy is allowed to interact with the dark matter. A general
equation of state of dark energy parametrized by a dimensionless parameter
`$\beta$' is utilized. From our analysis, we find that the interaction is
compatible with zero within the 1$\sigma$ confidence limit. We also show that
the same evolution history can be reproduced by a small pressure of the dark
matter.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 17:49:55 GMT""}]","2017-08-02"
"1705.09279","Chris J. Maddison","Chris J. Maddison, Dieterich Lawson, George Tucker, Nicolas Heess,
  Mohammad Norouzi, Andriy Mnih, Arnaud Doucet, Yee Whye Teh","Filtering Variational Objectives",,,,,"cs.LG cs.AI cs.NE stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  When used as a surrogate objective for maximum likelihood estimation in
latent variable models, the evidence lower bound (ELBO) produces
state-of-the-art results. Inspired by this, we consider the extension of the
ELBO to a family of lower bounds defined by a particle filter's estimator of
the marginal likelihood, the filtering variational objectives (FIVOs). FIVOs
take the same arguments as the ELBO, but can exploit a model's sequential
structure to form tighter bounds. We present results that relate the tightness
of FIVO's bound to the variance of the particle filter's estimator by
considering the generic case of bounds defined as log-transformed likelihood
estimators. Experimentally, we show that training with FIVO results in
substantial improvements over training the same model architecture with the
ELBO on sequential data.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 17:52:41 GMT""},{""version"":""v2"",""created"":""Mon, 28 Aug 2017 17:58:51 GMT""},{""version"":""v3"",""created"":""Sun, 12 Nov 2017 20:38:13 GMT""}]","2017-11-15"
"1705.09280","Suriya Gunasekar","Suriya Gunasekar, Blake Woodworth, Srinadh Bhojanapalli, Behnam
  Neyshabur, Nathan Srebro","Implicit Regularization in Matrix Factorization",,,,,"stat.ML cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study implicit regularization when optimizing an underdetermined quadratic
objective over a matrix $X$ with gradient descent on a factorization of $X$. We
conjecture and provide empirical and theoretical evidence that with small
enough step sizes and initialization close enough to the origin, gradient
descent on a full dimensional factorization converges to the minimum nuclear
norm solution.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 17:55:24 GMT""}]","2017-05-26"
"1705.09281","Hamid Hezari","Hamid Hezari, Zhiqin Lu, Hang Xu","Off-diagonal asymptotic properties of Bergman kernels associated to
  analytic K\""ahler potentials",,,,,"math.DG math.AP math.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove a new off-diagonal asymptotic of the Bergman kernels associated to
tensor powers of a positive line bundle on a compact K\""ahler manifold. We show
that if the K\""ahler potential is real analytic, then the Bergman kernel
accepts a complete asymptotic expansion in a neighborhood of the diagonal of
shrinking size $k^{-\frac14}$. These improve the earlier results in the subject
for smooth potentials, where an expansion exists in a $k^{-\frac12}$
neighborhood of the diagonal. We obtain our results by finding upper bounds of
the form $C^m m!^{2}$ for the Bergman coefficients $b_m(x, \bar y)$, which is
an interesting problem on its own. We find such upper bounds using the method
of Berman-Berndtsson-Sj\""ostrand. We also show that sharpening these upper
bounds would improve the rate of shrinking neighborhoods of the diagonal $x=y$
in our results. In the special case of metrics with local constant holomorphic
sectional curvatures, we obtain off-diagonal asymptotic in a fixed (as $k \to
\infty$) neighborhood of the diagonal, which recovers a result of Berman [Ber]
(see Remark 3.5 of [Ber] for higher dimensions). In this case, we also find an
explicit formula for the Bergman kernel mod $O(e^{-k \delta} )$.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 17:56:39 GMT""}]","2017-05-26"
"1705.09282","John Evans","Christopher Coley, Joseph Benzaken, John A. Evans","A geometric multigrid method for isogeometric compatible discretizations
  of the generalized Stokes and Oseen problems",,,,,"math.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we present a geometric multigrid methodology for the solution
of matrix systems associated with isogeometric compatible discretizations of
the generalized Stokes and Oseen problems. The methodology provably yields a
pointwise divergence-free velocity field independent of the number of
pre-smoothing steps, post-smoothing steps, grid levels, or cycles in a V-cycle
implementation. The methodology relies upon Scwharz-style smoothers in
conjunction with specially defined overlapping subdomains that respect the
underlying topological structure of the generalized Stokes and Oseen problems.
Numerical results in both two- and three-dimensions demonstrate the robustness
of the methodology through the invariance of convergence rates with respect to
grid resolution and flow parameters for the generalized Stokes problem as well
as the generalized Oseen problem provided it is not advection-dominated.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 17:56:46 GMT""}]","2017-05-26"
"1705.09283","Peng Jiao","Lei Deng, Peng Jiao, Jing Pei, Zhenzhi Wu and Guoqi Li","GXNOR-Net: Training deep neural networks with ternary weights and
  activations without full-precision memory under a unified discretization
  framework","11 pages, 13 figures","Neural Networks(Volume 100,April 2018)",,,"cs.LG cs.CV stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  There is a pressing need to build an architecture that could subsume these
networks under a unified framework that achieves both higher performance and
less overhead. To this end, two fundamental issues are yet to be addressed. The
first one is how to implement the back propagation when neuronal activations
are discrete. The second one is how to remove the full-precision hidden weights
in the training phase to break the bottlenecks of memory/computation
consumption. To address the first issue, we present a multi-step neuronal
activation discretization method and a derivative approximation technique that
enable the implementing the back propagation algorithm on discrete DNNs. While
for the second issue, we propose a discrete state transition (DST) methodology
to constrain the weights in a discrete space without saving the hidden weights.
Through this way, we build a unified framework that subsumes the binary or
ternary networks as its special cases, and under which a heuristic algorithm is
provided at the website https://github.com/AcrossV/Gated-XNOR. More
particularly, we find that when both the weights and activations become ternary
values, the DNNs can be reduced to sparse binary networks, termed as gated XNOR
networks (GXNOR-Nets) since only the event of non-zero weight and non-zero
activation enables the control gate to start the XNOR logic operations in the
original binary networks. This promises the event-driven hardware design for
efficient mobile intelligence. We achieve advanced performance compared with
state-of-the-art algorithms. Furthermore, the computational sparsity and the
number of states in the discrete space can be flexibly modified to make it
suitable for various hardware platforms.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 17:59:41 GMT""},{""version"":""v2"",""created"":""Mon, 17 Jul 2017 03:01:18 GMT""},{""version"":""v3"",""created"":""Fri, 18 Aug 2017 07:43:44 GMT""},{""version"":""v4"",""created"":""Mon, 9 Apr 2018 05:25:13 GMT""},{""version"":""v5"",""created"":""Wed, 2 May 2018 17:30:40 GMT""}]","2018-05-03"
"1705.09284","Luca Merlo Dr.","D.N. Dinh, L. Merlo, S.T. Petcov, R. Vega-Alvarez","Revisiting Minimal Lepton Flavour Violation in the Light of Leptonic CP
  Violation","36 pages, 4 figures. V2: References added; version accepted for
  publication on JHEP",,"10.1007/JHEP07(2017)089","FTUAM-17-8, IFT-UAM/CSIC-17-046, SISSA 24/2017/FISI","hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Minimal Lepton Flavour Violation (MLFV) framework is discussed after the
recent indication for CP violation in the leptonic sector. Among the three
distinct versions of MLFV, the one with degenerate right-handed neutrinos will
be disfavoured, if this indication is confirmed. The predictions for leptonic
radiative rare decays and muon conversion in nuclei are analysed, identifying
strategies to disentangle the different MLFV scenarios. The claim that the
present anomalies in the semi-leptonic $B$-meson decays can be explained within
the MLFV context is critically re-examined concluding that such an explanation
is not compatible with the present bounds from purely leptonic processes.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 17:59:57 GMT""},{""version"":""v2"",""created"":""Fri, 14 Jul 2017 20:37:27 GMT""}]","2017-09-13"
"1705.09289","Sri Harsha Dumpala Mr","Sri Harsha Dumpala, Ashish Panda, Sunil Kumar Kopparapu","Improved I-vector-based Speaker Recognition for Utterances with Speaker
  Generated Non-speech sounds",,,,,"cs.SD","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Conversational speech not only contains several variants of neutral speech
but is also prominently interlaced with several speaker generated non-speech
sounds such as laughter and breath. A robust speaker recognition system should
be capable of recognizing a speaker irrespective of these variations in his
speech. An understanding of whether the speaker-specific information
represented by these variations is similar or not helps build a good speaker
recognition system. In this paper, speaker variations captured by neutral
speech of a speaker is analyzed by considering speech-laugh (a variant of
neutral speech) and laughter (non-speech) sounds of the speaker. We study an
i-vector-based speaker recognition system trained only on neutral speech and
evaluate its performance on speech-laugh and laughter. Further, we analyze the
effect of including laughter sounds during training of an i-vector-basedspeaker
recognition system. Our experimental results show that the inclusion of
laughter sounds during training seem to provide complementary speaker-specific
information which results in an overall improved performance of the speaker
recognition system, especially on the utterances with speech-laugh segments.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 19:08:08 GMT""}]","2017-05-29"
"1705.09291","Jamie Lomax","Jamie R. Lomax, John P. Wisniewski, Aki Roberge, Jessica K. Donaldson,
  John H. Debes, Eliot M. Malumuth and Alycia J. Weinberger","Optical Coronagraphic Spectroscopy of AU Mic: Evidence of Time Variable
  Colors?","Accepted by AJ, 13 pages, 8 figures, 1 table",,"10.3847/1538-3881/aaa1a7",,"astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present coronagraphic long slit spectra of AU Mic's debris disk taken with
the STIS instrument aboard the Hubble Space Telescope (HST). Our spectra are
the first spatially resolved, scattered light spectra of the system's disk,
which we detect at projected distances between approximately 10 and 45 AU. Our
spectra cover a wavelength range between 5200 and 10200 angstroms. We find that
the color of AU Mic's debris disk is bluest at small (12-35 AU) projected
separations. These results both confirm and quantify the findings qualitatively
noted by Krist et al. (2005), and are different than IR observations that
suggested a uniform blue or gray color as a function of projected separation in
this region of the disk. Unlike previous literature that reported the color of
AU Mic's disk became increasingly more blue as a function of projected
separation beyond approximately 30 AU, we find the disk's optical color between
35-45 AU to be uniformly blue on the southeast side of the disk and
decreasingly blue on the northwest side. We note that this apparent change in
disk color at larger projected separations coincides with several fast, outward
moving ""features"" that are passing through this region of the southeast side of
the disk. We speculate that these phenomenon might be related, and that the
fast moving features could be changing the localized distribution of sub-micron
sized grains as they pass by, thereby reducing the blue color of the disk in
the process. We encourage follow-up optical spectroscopic observations of the
AU Mic to both confirm this result, and search for further modifications of the
disk color caused by additional fast moving features propagating through the
disk.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 18:00:00 GMT""},{""version"":""v2"",""created"":""Fri, 15 Dec 2017 19:00:03 GMT""}]","2018-01-31"
"1705.09292","Jan Heisig","Mathias Garny, Jan Heisig, Benedikt L\""ulf, Stefan Vogl","Coannihilation without chemical equilibrium","12 pages + references, 10 figures; v2: Discussion of kinetic
  equilibrium extended, matches published version","Phys. Rev. D 96, 103521 (2017)","10.1103/PhysRevD.96.103521","TUM-HEP 1085/17, TTK-17-18","hep-ph astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Chemical equilibrium is a commonly made assumption in the freeze-out
calculation of coannihilating dark matter. We explore the possible failure of
this assumption and find a new conversion-driven freeze-out mechanism.
Considering a representative simplified model inspired by supersymmetry with a
neutralino- and sbottom-like particle we find regions in parameter space with
very small couplings accommodating the measured relic density. In this region
freeze-out takes place out of chemical equilibrium and dark matter
self-annihilation is thoroughly inefficient. The relic density is governed
primarily by the size of the conversion terms in the Boltzmann equations. Due
to the small dark matter coupling the parameter region is immune to direct
detection but predicts an interesting signature of disappearing tracks or
displaced vertices at the LHC. Unlike freeze-in or superWIMP scenarios,
conversion-driven freeze-out is not sensitive to the initial conditions at the
end of reheating.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 18:00:01 GMT""},{""version"":""v2"",""created"":""Fri, 17 Nov 2017 13:49:14 GMT""}]","2017-11-20"
"1705.09293","Dan Hooper","Dan Hooper, Ilias Cholis and Tim Linden","TeV Gamma Rays From Galactic Center Pulsars","13 pages, 2 figure",,,"FERMILAB-PUB-17-173-A","astro-ph.HE astro-ph.GA hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Measurements of the nearby pulsars Geminga and B0656+14 by the HAWC and
Milagro telescopes have revealed the presence of bright TeV-emitting halos
surrounding these objects. If young and middle-aged pulsars near the Galactic
Center transfer a similar fraction of their energy into TeV photons, then these
sources could plausibly dominate the emission that is observed by HESS and
other ground-based telescopes from the innermost $\sim$$10^2$ parsecs of the
Milky Way. In particular, both the spectral shape and the angular extent of
this emission is consistent with TeV halos produced by a population of pulsars,
although the reported correlation of this emission with the distribution of
molecular gas suggests that diffuse hadronic processes also must contribute.
The overall flux of this emission requires a birth rate of ~100-1000 neutron
stars per Myr near the Galactic Center, in good agreement with recent
estimates.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 18:00:01 GMT""},{""version"":""v2"",""created"":""Mon, 11 Dec 2017 15:48:00 GMT""}]","2017-12-12"
"1705.09294","Tyler Corbett","Tyler Corbett, O. J. P. \'Eboli, and M. C. Gonzalez-Garcia","Unitarity Constraints on Dimension-six Operators II: Including Fermionic
  Operators","17 Pages, 8 Tables",,"10.1103/PhysRevD.96.035006",,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We analyze the scattering of fermions, Higgs and electroweak gauge bosons in
order to obtain the partial-wave unitarity bounds on dimension-six effective
operators, including those involving fermions. We also quantify whether, at the
LHC energies, the dimension-six operators lead to unitarity violation after
taking into account the presently available constraints on their Wilson
coefficients. Our results show that for most dimension-six operators relevant
for the LHC physics there is no unitarity violation at the LHC energies, and
consequently, there is no need for the introduction of form factors in the
experimental and phenomenological analyses, making them model independent. We
also identify two operators for which unitarity violation is still an issue at
the LHC Run-II.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 18:00:02 GMT""}]","2017-09-13"
"1705.09295","Shaouly Bar-Shalom","Jonathan Cohen, Shaouly Bar-Shalom, Gad Eilam, Amarjit Soni","Light-quarks Yukawa couplings and new physics in exclusive high-$p_T$
  Higgs + jet and Higgs + $b$-jet events","19 pages, 17 figures, 3 tables. Version as published in PRD","Phys. Rev. D 97, 055014 (2018)","10.1103/PhysRevD.97.055014",,"hep-ph hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We suggest that the exclusive Higgs + light (or b)-jet production at the LHC,
$pp \to h+j(j_b)$, is a rather sensitive probe of the light-quarks Yukawa
couplings and of other forms of new physics (NP) in the Higgs-gluon $hgg$ and
quark-gluon $qqg$ interactions. We study the Higgs $p_T$-distribution in $pp
\to h+j(j_b) \to \gamma \gamma + j(j_b)$, i.e., in $h+j(j_b)$ production
followed by the Higgs decay $h \to \gamma \gamma$, employing the
($p_T$-dependent) signal strength formalism to probe various types of NP which
are relevant to these processes and which we parameterize either as scaled
Standard Model (SM) couplings (the kappa-framework) and/or through new higher
dimensional effective operators (the SMEFT framework). We find that the
exclusive $h+j(j_b)$ production at the 13 TeV LHC is sensitive to various NP
scenarios, with typical scales ranging from a few TeV to ${\cal O}(10)$ TeV,
depending on the flavor, chirality and Lorentz structure of the underlying
physics.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 18:00:02 GMT""},{""version"":""v2"",""created"":""Sat, 10 Jun 2017 19:04:52 GMT""},{""version"":""v3"",""created"":""Wed, 4 Oct 2017 11:11:35 GMT""},{""version"":""v4"",""created"":""Sat, 31 Mar 2018 16:01:03 GMT""}]","2018-04-03"
"1705.09296","Dallas Card","Dallas Card and Chenhao Tan and Noah A. Smith","Neural Models for Documents with Metadata","13 pages, 3 figures, 6 tables; updating to version published at ACL
  2018","Dallas Card, Chenhao Tan, and Noah A. Smith. (2018). Neural Models
  for Documents with Metadata. In Proceedings of the 56th Annual Meeting of the
  Association for Computational Linguistics (Volume 1: Long Papers)","10.18653/v1/P18-1189",,"stat.ML cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Most real-world document collections involve various types of metadata, such
as author, source, and date, and yet the most commonly-used approaches to
modeling text corpora ignore this information. While specialized models have
been developed for particular applications, few are widely used in practice, as
customization typically requires derivation of a custom inference algorithm. In
this paper, we build on recent advances in variational inference methods and
propose a general neural framework, based on topic models, to enable flexible
incorporation of metadata and allow for rapid exploration of alternative
models. Our approach achieves strong performance, with a manageable tradeoff
between perplexity, coherence, and sparsity. Finally, we demonstrate the
potential of our framework through an exploration of a corpus of articles about
US immigration.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 18:00:03 GMT""},{""version"":""v2"",""created"":""Tue, 23 Oct 2018 20:26:37 GMT""}]","2018-10-25"
"1705.09297","Domenico Orlando","Antonio Amariti and Domenico Orlando and Susanne Reffert","Monopole Quivers and new 3D N=2 dualities","27 pages, 4 figures",,"10.1016/j.nuclphysb.2017.09.008",,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a new family of dualities for three-dimensional gauge theories,
motivated by the brane realization of the reduction of four-dimensional
dualities on a circle. This family can be understood as a generalization of
Aharony duality to quiver gauge theories whose nodes interact via monopole
terms in the superpotential. We refer to this family of theories as monopole
quivers. We corroborate the new dualities by checking the equivalence of the
three-sphere partition functions, obtained from the standard circle reduction
of the four-dimensional superconformal index. As a special case, we recover
some dualities recently discussed in the literature.}
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 18:00:03 GMT""}]","2018-03-14"
"1705.09298","Yuan-Ming Lu","Yuan-Ming Lu and Ying Ran and Masaki Oshikawa","Filling-enforced constraint on the quantized Hall conductivity on a
  periodic lattice","17+5 pages, 4 figures, published version","Annals of Physics, Volume 413, February 2020, 168060","10.1016/j.aop.2019.168060",,"cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We discuss quantum Hall effects in a gapped insulator on a periodic
two-dimensional lattice. We derive a universal relation among the the quantized
Hall conductivity, and charge and flux densities per physical unit cell. This
follows from the magnetic translation symmetry and the large gauge invariance,
and holds for a very general class of interacting many-body systems. It can be
understood as a combination of Laughlin's gauge invariance argument and
Lieb-Schultz-Mattis-type theorem. A variety of complementary arguments, based
on a cut-and-glue procedure, the many-body electric polarization, and a
fractionalization algebra of magnetic translation symmetry, are given. Our
universal relation is applied to several examples to show nontrivial
constraints. In particular, a gapped ground state at a fractional charge
filling per physical unit cell must have either a nonvanishing Hall
conductivity or anyon excitations, excluding a trivial Mott insulator.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 18:00:03 GMT""},{""version"":""v2"",""created"":""Sat, 1 Feb 2020 02:50:54 GMT""}]","2020-02-04"
"1705.09299","Jeremy Sanders","J. S. Sanders (1), A. C. Fabian (2), H. R. Russell (2) and S. A.
  Walker (3) ((1) MPE, (2) IoA, (3) NASA/GSFC)","Hydrostatic Chandra X-ray analysis of SPT-selected galaxy clusters - I.
  Evolution of profiles and core properties","Accepted by MNRAS, 19 pages, 13 figures and appendices. Source code
  available at https://github.com/jeremysanders/mbproj2. This version now
  assumes positive K0 in the entropy analysis and includes discussion of the
  inner profile slopes",,"10.1093/mnras/stx2796",,"astro-ph.CO astro-ph.GA astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We analyse Chandra X-ray Observatory observations of a set of galaxy clusters
selected by the South Pole Telescope using a new publicly-available
forward-modelling projection code, MBProj2, assuming hydrostatic equilibrium.
By fitting a powerlaw plus constant entropy model we find no evidence for a
central entropy floor in the lowest-entropy systems. A model of the underlying
central entropy distribution shows a narrow peak close to zero entropy which
accounts for 60 per cent of the systems, and a second broader peak around 130
keV cm^2. We look for evolution over the 0.28 to 1.2 redshift range of the
sample in density, pressure, entropy and cooling time at 0.015 R_500 and at 10
kpc radius. By modelling the evolution of the central quantities with a simple
model, we find no evidence for a non-zero slope with redshift. In addition, a
non-parametric sliding median shows no significant change. The fraction of
cool-core clusters with central cooling times below 2 Gyr is consistent above
and below z=0.6 (~30-40 per cent). Both by comparing the median thermodynamic
profiles, centrally biased towards cool cores, in two redshift bins, and by
modelling the evolution of the unbiased average profile as a function of
redshift, we find no significant evolution beyond self-similar scaling in any
of our examined quantities. Our average modelled radial density, entropy and
cooling-time profiles appear as powerlaws with breaks around 0.2 R_500. The
dispersion in these quantities rises inwards of this radius to around 0.4 dex,
although some of this scatter can be fit by a bimodal model.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 18:00:06 GMT""},{""version"":""v2"",""created"":""Wed, 25 Oct 2017 13:22:27 GMT""}]","2017-12-20"
"1705.09300","Bowen Shi","Bowen Shi and Yuan-Ming Lu","Deciphering the nonlocal entanglement entropy of fracton topological
  orders","13 pages, 14 figures. Modified in accordance to the published version","Phys. Rev. B 97, 144106 (2018)","10.1103/PhysRevB.97.144106",,"cond-mat.str-el hep-th quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The ground states of topological orders condense extended objects and support
topological excitations. This nontrivial property leads to nonzero topological
entanglement entropy $S_{topo}$ for conventional topological orders. Fracton
topological order is an exotic class of models which is beyond the description
of TQFT. With some assumptions about the condensates and the topological
excitations, we derive a lower bound of the nonlocal entanglement entropy
$S_{nonlocal}$ (a generalization of $S_{topo}$). The lower bound applies to
Abelian stabilizer models including conventional topological orders as well as
type \Rom{1} and type \Rom{2} fracton models, and it could be used to
distinguish them. For fracton models, the lower bound shows that $S_{nonlocal}$
could obtain geometry-dependent values, and $S_{nonlocal}$ is extensive for
certain choices of subsystems, including some choices which always give zero
for TQFT. The stability of the lower bound under local perturbations is
discussed.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 18:00:08 GMT""},{""version"":""v2"",""created"":""Sun, 15 Apr 2018 20:21:41 GMT""}]","2018-04-18"
"1705.09301","Lionel Haemmerl\'e","Lionel Haemmerl\'e, Tyrone E. Woods, Ralf S. Klessen, Alexander Heger,
  Daniel J. Whalen","The Evolution of Supermassive Population III Stars",,,"10.1093/mnras/stx2919",,"astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Supermassive primordial stars forming in atomically-cooled halos at $z
\sim15-20$ are currently thought to be the progenitors of the earliest quasars
in the Universe. In this picture, the star evolves under accretion rates of
$0.1 - 1$ $M_\odot$ yr$^{-1}$ until the general relativistic instability
triggers its collapse to a black hole at masses of $\sim10^5$ $M_\odot$.
However, the ability of the accretion flow to sustain such high rates depends
crucially on the photospheric properties of the accreting star, because its
ionising radiation could reduce or even halt accretion. Here we present new
models of supermassive Population III protostars accreting at rates $0.001 -
10$ $M_\odot$ yr$^{-1}$, computed with the GENEVA stellar evolution code
including general relativistic corrections to the internal structure. We use
the polytropic stability criterion to estimate the mass at which the collapse
occurs, which has been shown to give a lower limit of the actual mass at
collapse in recent hydrodynamic simulations. We find that at accretion rates
higher than $0.001$ $M_\odot$ yr$^{-1}$ the stars evolve as red, cool
supergiants with surface temperatures below $10^4$ K towards masses $>10^5$
$M_\odot$, and become blue and hot, with surface temperatures above $10^5$ K,
only for rates $\lesssim0.001$ $M_\odot$ yr$^{-1}$. Compared to previous
studies, our results extend the range of masses and accretion rates at which
the ionising feedback remains weak, reinforcing the case for direct collapse as
the origin of the first quasars.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 18:00:09 GMT""}]","2017-12-27"
"1705.09302","Naveen Reddy","Naveen A. Reddy, Pascal A. Oesch, Rychard J. Bouwens, Mireia Montes,
  Garth D. Illingworth, Charles C. Steidel, Pieter G. van Dokkum, Hakim Atek,
  Marcella C. Carollo, Anna Cibinel, Brad Holden, Ivo Labbe, Dan Magee, Laura
  Morselli, Erica J. Nelson, and Steve Wilkins","The HDUV Survey: A Revised Assessment of the Relationship between UV
  Slope and Dust Attenuation for High-Redshift Galaxies","22 pages, 3 tables, 11 figures, submitted to the Astrophysical
  Journal",,"10.3847/1538-4357/aaa3e7",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We use a newly assembled large sample of 3,545 star-forming galaxies with
secure spectroscopic, grism, and photometric redshifts at z=1.5-2.5 to
constrain the relationship between UV slope (beta) and dust attenuation
(L(IR)/L(UV)=IRX). Our sample benefits from the combination of deep Hubble
WFC3/UVIS photometry from the Hubble Deep UV (HDUV) Legacy survey and existing
photometric data compiled in the 3D-HST survey, and extends the range of UV
luminosity and beta probed in previous UV-selected samples. IRX is measured
using stacks of deep Herschel/PACS 100 and 160 micron data, and the results are
compared with predictions of the IRX-beta relation for different assumptions of
the stellar population model and obscuration curve. We find that z=1.5-2.5
galaxies have an IRX-beta relation that is consistent with the predictions for
an SMC extinction curve if we invoke sub-solar metallicity models that are
currently favored for high-redshift galaxies, while the commonly assumed
starburst attenuation curve over-predicts the IRX at a given beta by a factor
of ~3. The IRX of high-mass (M*>10^9.75 Msun) galaxies is a factor of >4 larger
than that of low-mass galaxies, lending support for the use of stellar mass as
a proxy for attenuation. The commonly observed trend of fainter galaxies having
bluer beta may simply reflect bluer intrinsic UV slopes for such galaxies,
rather than lower obscurations. The IRX-beta for young/low-mass galaxies
implies a dust curve that is steeper than the SMC, suggesting a lower
attenuation at a given beta relative to older/more massive galaxies. The lower
attenuations and higher ionizing photon output implied by low metallicity
stellar population models point to Lyman continuum production efficiencies,
xi_ion, that may be elevated by a factor of ~2 relative to the canonical value
for L* galaxies, aiding in their ability to keep the universe ionized at z~2.
[Abridged]
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 18:00:11 GMT""}]","2018-02-07"
"1705.09303","Matt Feiszli","Matt Feiszli","Latent Geometry and Memorization in Generative Models",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It can be difficult to tell whether a trained generative model has learned to
generate novel examples or has simply memorized a specific set of outputs. In
published work, it is common to attempt to address this visually, for example
by displaying a generated example and its nearest neighbor(s) in the training
set (in, for example, the L2 metric). As any generative model induces a
probability density on its output domain, we propose studying this density
directly. We first study the geometry of the latent representation and
generator, relate this to the output density, and then develop techniques to
compute and inspect the output density. As an application, we demonstrate that
""memorization"" tends to a density made of delta functions concentrated on the
memorized examples. We note that without first understanding the geometry, the
measurement would be essentially impossible to make.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 18:00:19 GMT""}]","2017-05-29"
"1705.09304","Falk Hassler","Pascal du Bosque, Falk Hassler, Dieter Lust","Generalized Parallelizable Spaces from Exceptional Field Theory","63 pages, 1 figure, 1 table, comments welcome",,"10.1007/JHEP01(2018)117","LMU-ASC 32/17, MPP-2017-105","hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Generalized parallelizable spaces allow a unified treatment of consistent
maximally supersymmetric truncations of ten- and eleven-dimensional
supergravity in generalized geometry. Known examples are spheres, twisted tori
and hyperboloides. They admit a generalized frame field over the coset space
$M$=$G/H$ which reproduces the Lie algebra $\mathfrak{g}$ of $G$ under the
generalized Lie derivative. An open problem is a systematic construction of
these spaces and especially their generalized frames fields. We present a
technique which applies to $\dim M$=4 for SL(5) exceptional field theory. In
this paper the group manifold $G$ is identified with the extended space of the
exceptional field theory. Subsequently, the section condition is solved to
remove unphysical directions from the extended space. Finally, a SL(5)
generalized frame field is constructed from parts of the left-invariant
Maurer-Cartan form on $G$. All these steps impose conditions on $G$ and $H$.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 18:00:26 GMT""}]","2018-03-14"
"1705.09305","Diptimoy Ghosh","Debjyoti Bardhan, Pritibhajan Byakti, Diptimoy Ghosh","Role of Tensor operators in $R_K$ and $R_{K^*}$","Version to appear in PLB",,"10.1016/j.physletb.2017.08.062",,"hep-ph hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The recent LHCb measurement of $R_{K^*}$ in two $q^2$ bins, when combined
with the earlier measurement of $R_K$, strongly suggests lepton flavour
non-universal new physics in semi-leptonic $B$ meson decays. Motivated by these
intriguing hints of new physics, several authors have considered vector, axial
vector, scalar and pseudo scalar operators as possible explanations of these
measurements. However, tensor operators have widely been neglected in this
context. In this paper, we consider the effect of tensor operators in $R_K$ and
$R_{K^*}$. We find that, unlike other local operators, tensor operators can
comfortably produce both of $R_{K^*} ^{\rm low}$ and $R_{K^*} ^{\rm central}$
close to their experimental central values. However, a simultaneous explanation
of $R_K$ is not possible with only Tensor operators, and other vector or axial
vector operators are needed. In fact, we find that combination of vector and
tensor operators can provide simultaneous explanations of all the anomalies
comfortably at the $1 \sigma$ level, a scenario which is hard to achieve with
only vector or axial vector operators. We also comment on the compatibility of
the various new physics solutions with the measurements of the inclusive decay
$B_d \to X_s \ell^+ \ell^-$.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 18:00:34 GMT""},{""version"":""v2"",""created"":""Wed, 28 Jun 2017 12:51:48 GMT""},{""version"":""v3"",""created"":""Sat, 16 Sep 2017 19:13:20 GMT""}]","2017-10-11"
"1705.09306","Daniele Bertacca DR.","Daniele Bertacca, Alvise Raccanelli, Nicola Bartolo, Michele Liguori,
  Sabino Matarrese, Licia Verde","Relativistic wide-angle galaxy bispectrum on the light-cone","68 pages, no figures. Typos corrected; Added References; Minor
  corrections. Version accepted by Physical Review D","Phys. Rev. D 97, 023531 (2018)","10.1103/PhysRevD.97.023531",,"astro-ph.CO gr-qc hep-ph hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Given the important role that the galaxy bispectrum has recently acquired in
cosmology and the scale and precision of forthcoming galaxy clustering
observations, it is timely to derive the full expression of the large-scale
bispectrum going beyond approximated treatments which neglect integrated terms
or higher-order bias terms or use the Limber approximation. On cosmological
scales, relativistic effects that arise from observing on the past light-cone
alter the observed galaxy number counts, therefore leaving their imprints on
N-point correlators at all orders. In this paper we compute for the first time
the bispectrum including all general relativistic, local and integrated,
effects at second order, the tracers' bias at second order, geometric effects
as well as the primordial non-Gaussianity contribution. This is timely
considering that future surveys will probe scales comparable to the horizon
where approximations widely used currently may not hold; neglecting these
effects may introduce biases in estimation of cosmological parameters as well
as primordial non-Gaussianity.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 18:01:07 GMT""},{""version"":""v2"",""created"":""Mon, 5 Jun 2017 10:29:31 GMT""},{""version"":""v3"",""created"":""Sat, 27 Jan 2018 13:41:07 GMT""}]","2018-01-31"
"1705.09307","Wufeng Xue","Wufeng Xue, Ali Islam, Mousumi Bhaduri and Shuo Li","Direct Multitype Cardiac Indices Estimation via Joint Representation and
  Regression Learning","accepted by IEEE Transactions on Medical Imaging",,"10.1109/TMI.2017.2709251",,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Cardiac indices estimation is of great importance during identification and
diagnosis of cardiac disease in clinical routine. However, estimation of
multitype cardiac indices with consistently reliable and high accuracy is still
a great challenge due to the high variability of cardiac structures and
complexity of temporal dynamics in cardiac MR sequences. While efforts have
been devoted into cardiac volumes estimation through feature engineering
followed by a independent regression model, these methods suffer from the
vulnerable feature representation and incompatible regression model. In this
paper, we propose a semi-automated method for multitype cardiac indices
estimation. After manual labelling of two landmarks for ROI cropping, an
integrated deep neural network Indices-Net is designed to jointly learn the
representation and regression models. It comprises two tightly-coupled
networks: a deep convolution autoencoder (DCAE) for cardiac image
representation, and a multiple output convolution neural network (CNN) for
indices regression. Joint learning of the two networks effectively enhances the
expressiveness of image representation with respect to cardiac indices, and the
compatibility between image representation and indices regression, thus leading
to accurate and reliable estimations for all the cardiac indices.
  When applied with five-fold cross validation on MR images of 145 subjects,
Indices-Net achieves consistently low estimation error for LV wall thicknesses
(1.44$\pm$0.71mm) and areas of cavity and myocardium (204$\pm$133mm$^2$). It
outperforms, with significant error reductions, segmentation method (55.1% and
17.4%) and two-phase direct volume-only methods (12.7% and 14.6%) for wall
thicknesses and areas, respectively. These advantages endow the proposed method
a great potential in clinical cardiac function assessment.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 18:01:41 GMT""}]","2017-05-29"
"1705.09308","Sumanta Tewari","S. Nandy, Girish Sharma, A. Taraphder, Sumanta Tewari","Chiral anomaly as origin of planar Hall effect in Weyl semimetals","4+ pages; Version accepted in Phys. Rev. Lett","Phys. Rev. Lett. 119, 176804 (2017)","10.1103/PhysRevLett.119.176804",,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In condensed matter physics, the term ""chiral anomaly"" implies the violation
of the separate number conservation laws of Weyl fermions of different
chiralities in the presence of parallel electric and magnetic fields. One
effect of chiral anomaly in the recently discovered Dirac and Weyl semimetals
is a positive longitudinal magnetoconductance (LMC). Here we show that chiral
anomaly and non-trivial Berry curvature effects engender another striking
effect in WSMs, the planar Hall effect (PHE). Remarkably, PHE manifests itself
when the applied current, magnetic field, and the induced transverse ""Hall""
voltage all lie in the same plane, precisely in a configuration in which the
conventional Hall effect vanishes. In this work we treat PHE quasi-classically,
and predict specific experimental signatures for type-I and type-II Weyl
semimetals that can be directly checked in experiments.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 18:03:49 GMT""},{""version"":""v2"",""created"":""Wed, 27 Sep 2017 05:16:24 GMT""}]","2017-11-01"
"1705.09309","Vyacheslav Yukalov","V.I. Yukalov and E.P. Yukalova","Bose-Einstein condensation temperature of weakly interacting atoms","Latex file, 28 pages, 2 figures","Laser Phys. Lett. 14 (2017) 073001","10.1088/1612-202X/aa6eed",,"cond-mat.quant-gas","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The critical temperature of Bose-Einstein condensation essentially depends on
internal properties of the system as well as on the geometry of a trapping
potential. The peculiarities of defining the phase transition temperature of
Bose-Einstein condensation for different systems are reviewed, including
homogenous Bose gas, trapped Bose atoms, and bosons in optical lattices. The
method of self-similar approximants, convenient for calculating critical
temperature, is briefly delineated.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 18:04:38 GMT""}]","2017-05-31"
"1705.09310","Alexandros Gezerlis","Alexander Galea, Tash Zielinski, Stefano Gandolfi, Alexandros Gezerlis","Fermions in Two Dimensions: Scattering and Many-Body Properties","20 pages, 6 figures, 1 table; v2 corresponds to published version","Low Temp Phys (2017) 189: 451","10.1007/s10909-017-1803-1","LA-UR-17-24235","cond-mat.quant-gas nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Ultracold atomic Fermi gases in two-dimensions (2D) are an increasingly
popular topic of research. The interaction strength between spin-up and
spin-down particles in two-component Fermi gases can be tuned in experiments,
allowing for a strongly interacting regime where the gas properties are yet to
be fully understood. We have probed this regime for 2D Fermi gases by
performing T=0 ab initio diffusion Monte Carlo calculations. The many-body
dynamics are largely dependent on the two-body interactions, therefore we start
with an in-depth look at scattering theory in 2D. We show the partial-wave
expansion and its relation to the scattering length and effective range. Then
we discuss our numerical methods for determining these scattering parameters.
We close out this discussion by illustrating the details of bound states in 2D.
Transitioning to the many-body system, we use variationally optimized wave
functions to calculate ground-state properties of the gas over a range of
interaction strengths. We show results for the energy per particle and
parametrize an equation of state. We then proceed to determine the chemical
potential for the strongly interacting gas.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 18:04:57 GMT""},{""version"":""v2"",""created"":""Fri, 11 Aug 2017 14:45:07 GMT""}]","2017-10-31"
"1705.09311","Nissim Fraija","N. Fraija, P. Veres, B. B. Zhang, R. Barniol Duran, R. L. Becerra, B.
  Zhang, W. H. Lee, A. M. Watson, C. Ordaz-Salazar and A. Galvan-Gamez","Theoretical Description Of GRB 160625B with Wind-to-ISM Transition and
  Implications for a Magnetized Outflow","9 pages, 2 figure and 3 tables. References were added. Accepted for
  publication in ApJ",,"10.3847/1538-4357/aa8a72",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  GRB 160625B, one of the brightest bursts in recent years, was simultaneously
observed by Fermi and Swift satellites, and ground-based optical telescopes in
three different events separated by long periods of time. In this paper the
non-thermal multiwavelength observations of GRB 160625B are described and a
transition phase from wind-type-like medium to interstellar medium between the
early (event II) and the late (event III) afterglow is found. The
multiwavelength observations of the early afterglow are consistent with the
afterglow evolution starting at $\sim$ 150 s in a stellar wind medium whereas
the observations of the late afterglow are consistent with the afterglow
evolution in interstellar medium (ISM). The wind-to-ISM transition is
calculated to be at $\sim 8\times 10^3$ s when the jet has decelerated, at a
distance of $\sim$ 1 pc from the progenitor. Using the standard external shock
model, the synchrotron and synchrotron self-Compton emission from reverse shock
is required to model the GeV $\gamma$-ray and optical observations in the early
afterglow, and synchrotron radiation from the adiabatic forward shock to
describe the X-ray and optical observations in the late afterglow. The derived
values of the magnetization parameter, the slope of the fast decay of the
optical flash and the inferred magnetic fields suggest that Poynting
flux-dominated jet models with arbitrary magnetization could account for the
spectral properties exhibited by GRB 160625B.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 18:06:52 GMT""},{""version"":""v2"",""created"":""Wed, 30 Aug 2017 05:51:20 GMT""},{""version"":""v3"",""created"":""Sat, 9 Sep 2017 04:59:05 GMT""}]","2017-10-11"
"1705.09312","Rui Soares Barbosa","Samson Abramsky, Rui Soares Barbosa, Giovanni Car\`u, Nadish de Silva,
  Kohei Kishida, Shane Mansfield","Minimum quantum resources for strong non-locality","20 pages, 5 figures","Proc. TQC 2017, Leibniz International Proceedings in Informatics
  (LIPIcs), 9:1--9:20","10.4230/LIPIcs.TQC.2017.9",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We analyse the minimum quantum resources needed to realise strong
non-locality, as exemplified e.g. by the classical GHZ construction. It was
already known that no two-qubit system, with any finite number of local
measurements, can realise strong non-locality. For three-qubit systems, we show
that strong non-locality can only be realised in the GHZ SLOCC class, and with
equatorial measurements. However, we show that in this class there is an
infinite family of states which are pairwise non-LU-equivalent that realise
strong non-locality with finitely many measurements. These states have
decreasing entanglement between one qubit and the other two, necessitating an
increasing number of local measurements on the latter.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 18:08:34 GMT""}]","2018-09-10"
"1705.09313","Yi-Zhuang You","Yi-Zhuang You, Yin-Chen He, Cenke Xu, Ashvin Vishwanath","Symmetric Fermion Mass Generation as Deconfined Quantum Criticality","12 papers, 4 figures, 3 appendices","Phys. Rev. X 8, 011026 (2018)","10.1103/PhysRevX.8.011026",,"cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Massless 2+1D Dirac fermions arise in a variety of systems from graphene to
the surfaces of topological insulators, where generating a mass is typically
associated with breaking a symmetry. However, with strong interactions, a
symmetric gapped phase can arise for multiples of eight Dirac fermions. A
continuous quantum phase transition from the massless Dirac phase to this
massive phase, which we term Symmetric Mass Generation (SMG), is necessarily
beyond the Landau paradigm and is hard to describe even at the conceptual
level. Nevertheless, such transition has been consistently observed in several
numerical studies recently. Here, we propose a theory for the SMG transition
which is reminiscent of deconfined criticality and involves emergent
non-Abelian gauge fields coupled both to Dirac fermions and to critical Higgs
bosons. We motivate the theory using an explicit parton construction and
discuss predictions for numerics. Additionally, we show that the fermion
Green's function is expected to undergo a zero to pole transition across the
critical point.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 18:12:16 GMT""},{""version"":""v2"",""created"":""Thu, 9 Nov 2017 07:26:34 GMT""}]","2018-02-21"
"1705.09314","Benjamin Hepp","Benjamin Hepp, Matthias Nie{\ss}ner, Otmar Hilliges","Plan3D: Viewpoint and Trajectory Optimization for Aerial Multi-View
  Stereo Reconstruction","31 pages, 12 figures, 9 tables",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce a new method that efficiently computes a set of viewpoints and
trajectories for high-quality 3D reconstructions in outdoor environments. Our
goal is to automatically explore an unknown area, and obtain a complete 3D scan
of a region of interest (e.g., a large building). Images from a commodity RGB
camera, mounted on an autonomously navigated quadcopter, are fed into a
multi-view stereo reconstruction pipeline that produces high-quality results
but is computationally expensive. In this setting, the scanning result is
constrained by the restricted flight time of quadcopters. To this end, we
introduce a novel optimization strategy that respects these constraints by
maximizing the information gain from sparsely-sampled view points while
limiting the total travel distance of the quadcopter. At the core of our method
lies a hierarchical volumetric representation that allows the algorithm to
distinguish between unknown, free, and occupied space. Furthermore, our
information gain based formulation leverages this representation to handle
occlusions in an efficient manner. In addition to the surface geometry, we
utilize the free-space information to avoid obstacles and determine
collision-free flight paths. Our tool can be used to specify the region of
interest and to plan trajectories. We demonstrate our method by obtaining a
number of compelling 3D reconstructions, and provide a thorough quantitative
evaluation showing improvement over previous state-of-the-art and regular
patterns.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 18:13:43 GMT""},{""version"":""v2"",""created"":""Tue, 18 Sep 2018 17:43:04 GMT""}]","2018-09-19"
"1705.09315","Kai Roehrig","Kai A. Roehrig","Chiral Splitting and $\mathcal N = 4$ Einstein--Yang--Mills Tree
  Amplitudes in 4d","21 pages",,"10.1007/JHEP08(2017)033",,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a world-sheet formula for all tree level scattering amplitudes, in
all trace sectors, of four dimensional $\mathcal{N} \leq 4$ supersymmetric
Einstein-Yang-Mills theory, based on the refined scattering equations. This
generalizes previously known formulas for all-trace purely bosonic, or
supersymmetric single-trace amplitudes. We find this formula by applying a new
chiral splitting formula for all CHY Pfaffians in 4d, into two determinants, of
positive and negative helicity respectively. The splitting of CHY Pfaffians is
shown to be a special case of the splitting of $T\mathbb{M}$ valued fermion
correlators on the sphere, which does not require the scattering equations to
hold, and is a consequence of the isomorphism $T\mathbb{M} \simeq \mathbb{S}^+
\otimes \mathbb{S}^-$ between the tangent bundle of Minkowski space and the
left- and right-handed spin bundles. We present and prove this general
splitting formula.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 18:19:58 GMT""},{""version"":""v2"",""created"":""Sun, 11 Jun 2017 15:24:32 GMT""}]","2017-09-13"
"1705.09316","Pierluigi Nuzzo","Jiwei Li, Pierluigi Nuzzo, Alberto Sangiovanni-Vincentelli, Yugeng Xi,
  Dewei Li","Stochastic Assume-Guarantee Contracts for Cyber-Physical System Design
  Under Probabilistic Requirements","Extended version of conference paper submission",,,,"cs.SY cs.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We develop an assume-guarantee contract framework for the design of
cyber-physical systems, modeled as closed-loop control systems, under
probabilistic requirements. We use a variant of signal temporal logic, namely,
Stochastic Signal Temporal Logic (StSTL) to specify system behaviors as well as
contract assumptions and guarantees, thus enabling automatic reasoning about
requirements of stochastic systems. Given a stochastic linear system
representation and a set of requirements captured by bounded StSTL contracts,
we propose algorithms that can check contract compatibility, consistency, and
refinement, and generate a controller to guarantee that a contract is
satisfied, following a stochastic model predictive control approach. Our
algorithms leverage encodings of the verification and control synthesis tasks
into mixed integer optimization problems, and conservative approximations of
probabilistic constraints that produce both sound and tractable problem
formulations. We illustrate the effectiveness of our approach on a few
examples, including the design of embedded controllers for aircraft power
distribution networks.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 18:24:51 GMT""},{""version"":""v2"",""created"":""Fri, 30 Jun 2017 03:59:52 GMT""}]","2017-07-03"
"1705.09317","Giuseppe Puglisi","G. Puglisi, D. De Tommasi, M.F. Pantano, N. Pugno, G. Saccomandi","A predictive model for protein materials: from macromolecules to
  macroscopic fibers",,"Phys. Rev. E 96, 042407 (2017)","10.1103/PhysRevE.96.042407",,"physics.bio-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a model for the mechanical behavior of protein materials. Based on
a limited number of experimental macromolecular parameters (persistence and
contour lengths, rate of unfolding dissipation) we obtain the macroscopic
behavior of keratin fibers (human, cow, and rabbit hair), taking into account
the damage and residual stretches effects which are fundamental in many
functions of life. We support our theoretical results by showing that our model
is robust and able to reproduce with high quantitive accuracy the cyclic
experimental behavior of different keratinous protein materials we tested. We
also show the capability of describing, even if with lower precision, the
dissipation and permanent strain effects in spider silks.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 18:31:09 GMT""}]","2017-10-18"
"1705.09318","Alexey Kudrin V.","A.V. Kudrin, Yu.A. Danilov, V.P. Lesnikov, O.V. Vikhrova, D.A. Pavlov,
  Yu.V. Usov, I.N. Antonov, R.N. Krukov and N. A. Sobolev","High-temperature intrinsic ferromagnetism in the (In,Fe)Sb semiconductor",,,"10.1063/1.5010191",,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The (In,Fe)Sb layers with the Fe content up to 13 at. % have been grown on
(001) GaAs substrates using the pulsed laser deposition. The TEM investigations
show that the (In,Fe)Sb layers are epitaxial and free of the inclusions of a
second phase. The observation of the hysteretic magnetoresistance curves at
temperatures up to 300 K reveals that the Curie point is above room
temperature. The resonant character of magnetic circular dichroism confirms the
intrinsic ferromagnetism in the (In,Fe)Sb layers. We suggest that the
ferromagnetism of the (In,Fe)Sb matrix is not carrier-mediated and apparently
is determined by the mechanism of superexchange interaction between Fe atoms
(This work was presented at the XXI Symposium Nanophysics and Nanoelectronics,
Nizhny Novgorod, March, 13-16, 2017 (book of proceedings v.1, p. 195),
http://nanosymp.ru/UserFiles/Symp/2017_v1.pdf).
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 18:32:59 GMT""},{""version"":""v2"",""created"":""Fri, 4 Aug 2017 14:45:35 GMT""},{""version"":""v3"",""created"":""Fri, 22 Sep 2017 19:15:04 GMT""}]","2017-11-10"
"1705.09319","L\'eon Bottou","Jean Lafond, Nicolas Vasilache, L\'eon Bottou","Diagonal Rescaling For Neural Networks",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We define a second-order neural network stochastic gradient training
algorithm whose block-diagonal structure effectively amounts to normalizing the
unit activations. Investigating why this algorithm lacks in robustness then
reveals two interesting insights. The first insight suggests a new way to scale
the stepsizes, clarifying popular algorithms such as RMSProp as well as old
neural network tricks such as fanin stepsize scaling. The second insight
stresses the practical importance of dealing with fast changes of the curvature
of the cost.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 18:33:24 GMT""}]","2017-05-29"
"1705.09320","Ravit Helled","Ravit Helled and Tristan Guillot","Internal Structure of Giant and Icy Planets: Importance of Heavy
  Elements and Mixing","Invited review chapter, accepted for publication in ""Handbook of
  Exoplanets""",,"10.1007/978-3-319-55333-7_44",,"astro-ph.EP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this chapter we summarize current knowledge of the internal structure of
giant planets. We concentrate on the importance of heavy elements and their
role in determining the planetary composition and internal structure, in planet
formation, and during the planetary long-term evolution. We briefly discuss how
internal structure models are derived, present the possible structures of the
outer planets in the Solar System, and summarise giant planet formation and
evolution. Finally, we introduce giant exoplanets and discuss how they can be
used to better understand giant planets as a class of planetary objects.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 18:33:28 GMT""},{""version"":""v2"",""created"":""Thu, 7 Jun 2018 06:25:34 GMT""}]","2019-02-06"
"1705.09321","Rajesh Menon","Peng Wang and Rajesh Menon","Computational multi-spectral video imaging",,"J. Opt. Soc. Am. A 35(1), 189-199 (2018)","10.1364/JOSAA.35.000189",,"physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Multi-spectral imagers reveal information unperceivable to humans and
conventional cameras. Here, we demonstrate a compact single-shot multi-spectral
video-imaging camera by placing a micro-structured diffractive filter in close
proximity to the image sensor. The diffractive filter converts spectral
information to a spatial code on the sensor pixels. Following a calibration
step, this code can be inverted via regularization-based linear algebra, to
compute the multi-spectral image. We experimentally demonstrated spectral
resolution of 9.6nm within the visible band (430nm to 718nm). We further show
that the spatial resolution is enhanced by over 30% compared to the case
without the diffractive filter. We also demonstrate Vis-IR imaging with the
same sensor. Furthermore, our camera is able to computationally trade-off
spectral resolution against the field of view in software without any change in
hardware as long as sufficient sensor pixels are utilized for information
encoding. Since no absorptive color filters are utilized, sensitivity is
preserved as well. Finally, the diffractive filters can be easily manufactured
using optical lithography and replication techniques.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 18:33:45 GMT""},{""version"":""v2"",""created"":""Mon, 20 Nov 2017 04:53:08 GMT""}]","2018-02-14"
"1705.09322","Ahmed Touati","Ahmed Touati, Pierre-Luc Bacon, Doina Precup, Pascal Vincent","Convergent Tree Backup and Retrace with Function Approximation",,"ICML 2018, Proceedings of the 35th International Conference on
  Machine Learning, PMLR 80:4955-4964, 2018",,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Off-policy learning is key to scaling up reinforcement learning as it allows
to learn about a target policy from the experience generated by a different
behavior policy. Unfortunately, it has been challenging to combine off-policy
learning with function approximation and multi-step bootstrapping in a way that
leads to both stable and efficient algorithms. In this work, we show that the
\textsc{Tree Backup} and \textsc{Retrace} algorithms are unstable with linear
function approximation, both in theory and in practice with specific examples.
Based on our analysis, we then derive stable and efficient gradient-based
algorithms using a quadratic convex-concave saddle-point formulation. By
exploiting the problem structure proper to these algorithms, we are able to
provide convergence guarantees and finite-sample bounds. The applicability of
our new analysis also goes beyond \textsc{Tree Backup} and \textsc{Retrace} and
allows us to provide new convergence rates for the GTD and GTD2 algorithms
without having recourse to projections or Polyak averaging.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 18:37:55 GMT""},{""version"":""v2"",""created"":""Fri, 17 Nov 2017 20:44:47 GMT""},{""version"":""v3"",""created"":""Fri, 23 Feb 2018 15:25:32 GMT""},{""version"":""v4"",""created"":""Mon, 22 Oct 2018 21:34:58 GMT""}]","2019-01-04"
"1705.09323","Laurence Boxer","Laurence Boxer","Shy Maps in Topology",,,,,"math.GT math.GN","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  There is a concept in digital topology of a shy map. We define an analogous
concept for topological spaces: We say a function is shy if it is continuous
and the inverse image of every path-connected subset of its image is
path-connected. Some basic properties of such maps are presented. For example,
every shy map onto a semilocally simply connected space induces a surjection of
fundamental groups (but a shy map onto a space that is not semilocally simply
connected need not do so).
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 18:45:26 GMT""},{""version"":""v2"",""created"":""Fri, 10 Nov 2017 19:48:58 GMT""},{""version"":""v3"",""created"":""Tue, 23 Jan 2018 18:08:27 GMT""},{""version"":""v4"",""created"":""Mon, 30 Apr 2018 19:10:15 GMT""}]","2018-05-02"
"1705.09324","Florian Kassel","Florian Kassel and Moritz Guthoff and Anne Dabrowski and Wim de Boer","Description of radiation damage in diamond sensors using an effective
  defect model",,,"10.1002/pssa.201700162",,"physics.ins-det","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The BCML system is a beam monitoring device in the CMS experiment at the LHC.
As detectors poly-crystalline diamond sensors are used. Here high particle
rates occur from the colliding beams scattering particles outside the beam
pipe. These particles cause defects, which act as traps for the ionization,
thus reducing the CCE. However, the loss in CCE was much more severe than
expected. The reason why in real experiments the CCE is so much worse than in
laboratory experiments is related to the rate of incident particles. At high
particle rates the trapping rate of the ionization is so high compared with the
detrapping rate, that space charge builds up. This space charge reduces locally
the internal electric field, which in turn increases the trapping rate and
hence reduces the CCE even further. In order to connect these macroscopic
measurements with the microscopic defects acting as traps for the ionization
charge the TCAD simulation program SILVACO was used. Two effective acceptor and
donor levels were needed to fit the data. Using this effective defect model the
highly non- linear rate dependent diamond polarization as function of the
particle rate environment and the resulting signal loss could be simulated.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 18:46:32 GMT""}]","2018-02-14"
"1705.09325","Utkir A. Rozikov","U. A. Rozikov, G.I. Botirov","Non-translation-invariant Gibbs Measures for Models With Uncountable Set
  of Spin Values on a Cayley Tree","10 pages",,,,"math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider models with nearest-neighbor interactions and with the set
$[0,1]$ of spin values, on a Cayley tree of order $k\geq 1$.
  It is known that the ""splitting Gibbs measures"" of the model can be described
by solutions of a nonlinear integral equation. Recently, solving this integral
equation some periodic (in particular translation-invariant) splitting Gibbs
measures were found. In this paper we give three constructions of new sets of
non-translation-invariant splitting Gibbs measures. Our constructions are based
on known solutions of the integral equation.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 18:52:24 GMT""},{""version"":""v2"",""created"":""Fri, 29 Dec 2017 07:53:52 GMT""}]","2018-01-01"
"1705.09326","Gabriele Farina","Christian Kroer and Gabriele Farina and Tuomas Sandholm","Smoothing Method for Approximate Extensive-Form Perfect Equilibrium","Published at IJCAI 17",,,,"cs.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Nash equilibrium is a popular solution concept for solving
imperfect-information games in practice. However, it has a major drawback: it
does not preclude suboptimal play in branches of the game tree that are not
reached in equilibrium. Equilibrium refinements can mend this issue, but have
experienced little practical adoption. This is largely due to a lack of
scalable algorithms.
  Sparse iterative methods, in particular first-order methods, are known to be
among the most effective algorithms for computing Nash equilibria in
large-scale two-player zero-sum extensive-form games. In this paper, we
provide, to our knowledge, the first extension of these methods to equilibrium
refinements. We develop a smoothing approach for behavioral perturbations of
the convex polytope that encompasses the strategy spaces of players in an
extensive-form game. This enables one to compute an approximate variant of
extensive-form perfect equilibria. Experiments show that our smoothing approach
leads to solutions with dramatically stronger strategies at information sets
that are reached with low probability in approximate Nash equilibria, while
retaining the overall convergence rate associated with fast algorithms for Nash
equilibrium. This has benefits both in approximate equilibrium finding (such
approximation is necessary in practice in large games) where some probabilities
are low while possibly heading toward zero in the limit, and exact equilibrium
computation where the low probabilities are actually zero.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 18:53:47 GMT""}]","2017-05-29"
"1705.09327","George Tynan","George R. Tynan, Russell P. Doerner, J. Barton, R. Chen, S. Cui, M.
  Simmonds, Y. Wang, J.S. Weaver, N. Mara, S. Pathak","Deuterium retention and thermal conductivity in ion-beam
  displacement-damaged tungsten","Accepted, Nuclear Materials and Energy, Feb 2017",,,,"physics.plasm-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Retention of plasma-implanted D is studied in W targets damaged by a Cu ion
beam at up to 0.2 dpa with sample temperatures between 300 K and 1200 K. At a D
plasma ion fluence of $10^{24}/m^2$ on samples damaged to 0.2 dpa at 300 K, the
retained D retention inventory is $4.6x10^{20} D/m^2$, about ~5.5 times higher
than in undamaged samples. The retained inventory drops to $9x10^{19} D/m^2$
for samples damaged to 0.2 dpa at 1000 K, consistent with onset of vacancy
annealing at a rate sufficient to overcome the elevated rate of ion beam
damage; at a damage temperature of 1200 K retention is nearly equal to values
seen in undamaged materials. A nano-scale technique provides thermal
conductivity measurements from the Cu- ion beam displacement damaged region. We
find the thermal conductivity of W damaged to 0.2 dpa at room temperature drops
from the un-irradiated value of 182 +/- 3.3 W/m-K to 53 +/- 8 W/m-K.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 18:58:39 GMT""}]","2017-05-29"
"1705.09328","Gabriele Farina","Gabriele Farina and John P. Dickerson and Tuomas Sandholm","Operation Frames and Clubs in Kidney Exchange","Published at IJCAI-17",,,,"cs.GT cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A kidney exchange is a centrally-administered barter market where patients
swap their willing yet incompatible donors. Modern kidney exchanges use
2-cycles, 3-cycles, and chains initiated by non-directed donors (altruists who
are willing to give a kidney to anyone) as the means for swapping.
  We propose significant generalizations to kidney exchange. We allow more than
one donor to donate in exchange for their desired patient receiving a kidney.
We also allow for the possibility of a donor willing to donate if any of a
number of patients receive kidneys. Furthermore, we combine these notions and
generalize them. The generalization is to exchange among organ clubs, where a
club is willing to donate organs outside the club if and only if the club
receives organs from outside the club according to given specifications. We
prove that unlike in the standard model, the uncapped clearing problem is
NP-complete.
  We also present the notion of operation frames that can be used to sequence
the operations across batches, and present integer programming formulations for
the market clearing problems for these new types of organ exchanges.
  Experiments show that in the single-donation setting, operation frames
improve planning by 34%--51%. Allowing up to two donors to donate in exchange
for one kidney donated to their designated patient yields a further increase in
social welfare.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 18:58:58 GMT""}]","2017-05-29"
"1705.09329","Adam Mantz","Adam B. Mantz (1), Steven W. Allen (1), R. Glenn Morris (1), Anja von
  der Linden (2) ((1) KIPAC Stanford/SLAC, (2) SUNY Stony Brook)","Center-Excised X-ray Luminosity as an Efficient Mass Proxy for Future
  Galaxy Cluster Surveys","9 pages. Accepted version","Mon. Not. Roy. Astron. Soc. 473:3072-3079, 2018","10.1093/mnras/stx2554",,"astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The cosmological constraining power of modern galaxy cluster catalogs can be
improved by obtaining low-scatter mass proxy measurements for even a small
fraction of sources. In the context of large upcoming surveys that will reveal
the cluster population down to the group scale and out to high redshifts,
efficient strategies for obtaining such mass proxies will be valuable. In this
work, we use high-quality weak lensing and X-ray mass estimates for massive
clusters in current X-ray selected catalogs to revisit the scaling relations of
the projected, center-excised X-ray luminosity ($L_{ce}$), which previous work
suggests correlates tightly with total mass. Our data confirm that this is the
case, with $L_{ce}$ having an intrinsic scatter at fixed mass comparable to
that of gas mass, temperature or $Y_X$. Compared to these other proxies,
however, $L_{ce}$ is less susceptible to systematic uncertainties due to
background modeling, and can be measured precisely with shorter exposures. This
opens up the possibility of using $L_{ce}$ to estimate masses for large numbers
of clusters discovered by new X-ray surveys (e.g. eROSITA) directly from the
survey data, as well as for clusters discovered at other wavelengths, with
relatively short follow-up observations. We describe a simple procedure for
making such estimates from X-ray surface brightness data, and comment on the
spatial resolution required to apply this method as a function of cluster mass
and redshift. We also explore the potential impact of Chandra and XMM-Newton
follow-up observations over the next decade on dark energy constraints from new
cluster surveys.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 18:59:47 GMT""},{""version"":""v2"",""created"":""Thu, 26 Oct 2017 22:55:24 GMT""}]","2017-12-04"
"1705.09331","G. Alencar","G. Alencar","Hidden Conformal Symmetry in Randall-Sundrum 2 Model: Universal Fermion
  Localization by Torsion","Published version","Phys.Lett. B773 (2017) 601-603","10.1016/j.physletb.2017.09.014",,"hep-th gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this manuscript we describe a hidden conformal symmetry of the second
Randall-Sundrum model (RS2). We show how this can be used to localize fermions
of both chiralities. The conformal symmetry leaves few free dimensionless
constants and constrains the allowed interactions. In this formulation the
warping of the extra dimension emerges from a partial breaking of the conformal
symmetry in five dimensions. The solution of the system can be described in two
alternative gauges: by the metric or by the conformon. By considering this as a
fundamental symmetry we construct a conformally invariant action for a vector
field which provides a massless photon localized over a Minkowski brane. This
is obtained by a conformal non-minimal coupling that breaks the gauge symmetry
in five dimensions. We further consider a generalization of the model by
including conformally invariant torsion. By coupling torsion non-minimally to
fermions we obtain a localized zero mode of both chiralities completing the
consistence of the model. The inclusion of torsion introduces a fermion quartic
interaction that can be used to probe the existence of large extra dimensions
and the validity of the model. This seems to point to the fact that conformal
symmetry may be more fundamental than gauge symmetry and that this is the
missing ingredient for the full consistence of RS scenarios.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 19:04:15 GMT""},{""version"":""v2"",""created"":""Wed, 26 Jul 2017 13:24:17 GMT""},{""version"":""v3"",""created"":""Thu, 27 Jul 2017 15:42:21 GMT""},{""version"":""v4"",""created"":""Tue, 19 Sep 2017 16:25:47 GMT""}]","2017-09-20"
"1705.09332","Linda Schmidtobreick","Linda Schmidtobreick","SW Sex Stars Then and Now: A Review","14 pages, 12 figures, conference proceedings",,,,"astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  SW Sextantis stars are a class of cataclysmic variables originally defined
via certain peculiar properties that they all have in common. In this article,
I review our knowledge of these stars and show the way from a phenomenological
classification to a physical understanding of these systems. The fact that SW
Sex stars accumulate at the upper edge of the period gap is discussed with
respect to the secular evolution of cataclysmic variables.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 19:05:38 GMT""}]","2017-05-29"
"1705.09333","Andrew O'Desky","John F. R. Duncan and Andrew O'Desky","Super Vertex Algebras, Meromorphic Jacobi Forms and Umbral Moonshine","25 pages","J. Algebra. 515 (2018) 389-407","10.1016/j.jalgebra.2018.08.017",,"math.RT hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The vector-valued mock modular forms of umbral moonshine may be repackaged
into meromorphic Jacobi forms of weight one. In this work we constructively
solve two cases of the meromorphic module problem for umbral moonshine.
Specifically, for the type A Niemeier root systems with Coxeter numbers seven
and thirteen, we construct corresponding bigraded super vertex operator
algebras, equip them with actions of the corresponding umbral groups, and
verify that the resulting trace functions on canonically twisted modules
recover the meromorphic Jacobi forms that are specified by umbral moonshine. We
also obtain partial solutions to the meromorphic module problem for the type A
Niemeier root systems with Coxeter numbers four and five, by constructing super
vertex operator algebras that recover the meromorphic Jacobi forms attached to
maximal subgroups of the corresponding umbral groups.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 19:06:08 GMT""},{""version"":""v2"",""created"":""Thu, 4 Apr 2019 22:02:13 GMT""}]","2019-04-08"
"1705.09334","Stefan Krastanov","Stefan Krastanov, Liang Jiang","Deep Neural Network Probabilistic Decoder for Stabilizer Codes",,"Scientific Reports 7, Article number: 11003 (2017)","10.1038/s41598-017-11266-1",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Neural networks can efficiently encode the probability distribution of errors
in an error correcting code. Moreover, these distributions can be conditioned
on the syndromes of the corresponding errors. This paves a path forward for a
decoder that employs a neural network to calculate the conditional
distribution, then sample from the distribution - the sample will be the
predicted error for the given syndrome. We present an implementation of such an
algorithm that can be applied to any stabilizer code. Testing it on the toric
code, it has higher threshold than a number of known decoders thanks to
naturally finding the most probable error and accounting for correlations
between errors.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 19:13:35 GMT""},{""version"":""v2"",""created"":""Thu, 15 Jun 2017 19:32:11 GMT""},{""version"":""v3"",""created"":""Fri, 8 Sep 2017 20:31:10 GMT""}]","2017-09-12"
"1705.09335","Morteza Zadimoghaddam","Maxime C. Cohen, Philipp W. Keller, Vahab Mirrokni and Morteza
  Zadimoghaddam","Overcommitment in Cloud Services -- Bin packing with Chance Constraints",,,,,"cs.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper considers a traditional problem of resource allocation, scheduling
jobs on machines. One such recent application is cloud computing, where jobs
arrive in an online fashion with capacity requirements and need to be
immediately scheduled on physical machines in data centers. It is often
observed that the requested capacities are not fully utilized, hence offering
an opportunity to employ an overcommitment policy, i.e., selling resources
beyond capacity. Setting the right overcommitment level can induce a
significant cost reduction for the cloud provider, while only inducing a very
low risk of violating capacity constraints. We introduce and study a model that
quantifies the value of overcommitment by modeling the problem as a bin packing
with chance constraints. We then propose an alternative formulation that
transforms each chance constraint into a submodular function. We show that our
model captures the risk pooling effect and can guide scheduling and
overcommitment decisions. We also develop a family of online algorithms that
are intuitive, easy to implement and provide a constant factor guarantee from
optimal. Finally, we calibrate our model using realistic workload data, and
test our approach in a practical setting. Our analysis and experiments
illustrate the benefit of overcommitment in cloud services, and suggest a cost
reduction of 1.5% to 17% depending on the provider's risk tolerance.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 19:21:09 GMT""}]","2017-05-29"
"1705.09336","Sebastian Siebertz","Micha{\l} Pilipczuk, Sebastian Siebertz, Szymon Toru\'nczyk","On the number of types in sparse graphs",,,,,"cs.DM math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove that for every class of graphs $\mathcal{C}$ which is nowhere dense,
as defined by Nesetril and Ossona de Mendez, and for every first order formula
$\phi(\bar x,\bar y)$, whenever one draws a graph $G\in \mathcal{C}$ and a
subset of its nodes $A$, the number of subsets of $A^{|\bar y|}$ which are of
the form $\{\bar v\in A^{|\bar y|}\, \colon\, G\models\phi(\bar u,\bar v)\}$
for some valuation $\bar u$ of $\bar x$ in $G$ is bounded by
$\mathcal{O}(|A|^{|\bar x|+\epsilon})$, for every $\epsilon>0$. This provides
optimal bounds on the VC-density of first-order definable set systems in
nowhere dense graph classes.
  We also give two new proofs of upper bounds on quantities in nowhere dense
classes which are relevant for their logical treatment. Firstly, we provide a
new proof of the fact that nowhere dense classes are uniformly quasi-wide,
implying explicit, polynomial upper bounds on the functions relating the two
notions. Secondly, we give a new combinatorial proof of the result of Adler and
Adler stating that every nowhere dense class of graphs is stable. In contrast
to the previous proofs of the above results, our proofs are completely
finitistic and constructive, and yield explicit and computable upper bounds on
quantities related to uniform quasi-wideness (margins) and stability (ladder
indices).
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 19:22:25 GMT""},{""version"":""v2"",""created"":""Mon, 6 Nov 2017 18:45:10 GMT""}]","2017-11-07"
"1705.09337","Ruben Hidalgo","Ruben A. Hidalgo","Hyperelliptic quotients of generalized Humbert curves",,,,,"math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A group $H \cong {\mathbb Z}_{2}^{n}$, $n \geq 3$, of conformal automorphisms
of a closed Riemann surface $S$ such that $S/H$ has genus zero and exactly
$(n+1)$ cone points is called a generalized Humbert group of type $n$, in which
case, $S$ is called a generalized Humbert curve of type $n$. It is known that a
generalized Humbert curve $S$ of type $n \geq 4$ is non-hyperelliptic and that
it admits a unique generalized Humbert group $H$ of type $n$. We describe those
subgroups $K$ of $H$, acting freely on $S$, such that $S/K$ is hyperelliptic.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 19:30:17 GMT""},{""version"":""v2"",""created"":""Tue, 5 Nov 2019 20:38:28 GMT""},{""version"":""v3"",""created"":""Sat, 16 Nov 2019 14:41:02 GMT""},{""version"":""v4"",""created"":""Tue, 3 Dec 2019 12:41:14 GMT""},{""version"":""v5"",""created"":""Tue, 31 Dec 2019 13:47:02 GMT""}]","2020-01-01"
"1705.09338","Luca Brandt","Arash Alizad Banaei, Jean-Christophe Loiseau, Iman Lashgari and Luca
  Brandt","Numerical simulations of elastic capsules with nucleus in shear flow",,,"10.1080/17797179.2017.1294828",,"physics.flu-dyn physics.comp-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The shear-induced deformation of a capsule with a stiff nucleus, a model of
eukaryotic cells, is studied numerically. The membrane of the cell and of its
nucleus are modelled as a thin and impermeable elastic material obeying a
Neo-Hookean constitutive law. The membranes are discretised by a Lagrangian
mesh and their governing equations are solved in spectral space using spherical
harmonics, while the fluid equations are solved on a staggered grid using a
second-order finite differences scheme. The fluid-structure coupling is
obtained using an immersed boundary method. The numerical approach is presented
and validated for the case of a single capsule in a shear flow. The variations
induced by the presence of the nucleus on the cell deformation are investigated
when varying the viscosity ratio between the inner and outer fluids, the
membrane elasticity and its bending stiffness. The deformation of the
eukaryotic cell is smaller than that of the prokaryotic one. The reduction in
deformation increases for larger values of the capillary number. The eukaryotic
cell remains thicker in its middle part compared to the prokaryotic one, thus
making it less flexible to pass through narrow capillaries. For a viscosity
ratio of 5, the deformation of the cell is smaller than in the case of uniform
viscosity. In addition, for non-zero bending stiffness of the membrane, the
deformation decreases and the shape is closer to an ellipsoid. Finally, we
compare the results obtained modeling the nucleus as an inner stiffer membrane
with those obtained using a rigid particle.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 19:39:40 GMT""}]","2017-05-29"
"1705.09339","Senthil Yogamani","B Ravi Kiran, Arindam Das and Senthil Yogamani","Rejection-Cascade of Gaussians: Real-time adaptive background
  subtraction framework","Accepted for National Conference on Computer Vision, Pattern
  Recognition, Image Processing and Graphics (NCVPRIPG 2019)",,,,"stat.ML cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Background-Foreground classification is a well-studied problem in computer
vision. Due to the pixel-wise nature of modeling and processing in the
algorithm, it is usually difficult to satisfy real-time constraints. There is a
trade-off between the speed (because of model complexity) and accuracy.
Inspired by the rejection cascade of Viola-Jones classifier, we decompose the
Gaussian Mixture Model (GMM) into an adaptive cascade of Gaussians(CoG). We
achieve a good improvement in speed without compromising the accuracy with
respect to the baseline GMM model. We demonstrate a speed-up factor of 4-5x and
17 percent average improvement in accuracy over Wallflowers surveillance
datasets. The CoG is then demonstrated to over the latent space representation
of images of a convolutional variational autoencoder(VAE). We provide initial
results over CDW-2014 dataset, which could speed up background subtraction for
deep architectures.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 19:50:45 GMT""},{""version"":""v2"",""created"":""Sat, 16 Nov 2019 16:51:04 GMT""}]","2019-11-19"
"1705.09340","Roberto Cominetti","Mario Bravo, Roberto Cominetti, Mat\'ias Pavez-Sign\'e","Rates of convergence for inexact Krasnosel'skii-Mann iterations in
  Banach spaces",,,,,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the convergence of an inexact version of the classical
Krasnosel'skii-Mann iteration for computing fixed points of nonexpansive maps.
Our main result establishes a new metric bound for the fixed-point residuals,
from which we derive their rate of convergence as well as the convergence of
the iterates towards a fixed point. The results are applied to three variants
of the basic iteration: infeasible iterations with approximate projections, the
Ishikawa iteration, and diagonal Krasnosels'kii-Mann schemes. The results are
also extended to continuous time in order to study the asymptotics of
nonautonomous evolution equations governed by nonexpansive operators.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 19:56:17 GMT""},{""version"":""v2"",""created"":""Thu, 1 Jun 2017 20:18:09 GMT""}]","2017-06-05"
"1705.09341","Anna Morozovska Nickolaevna","Anna N. Morozovska, Eugene A. Eliseev, N. Borodinov, O. Ovchinnikova,
  Nicholas V. Morozovsky and Sergei V. Kalinin","Thermal Contrast in Nanoscale Infrared Spectroscopy (AFM-IR): Low
  Frequency Limit","24 pages (including supplementary materials), 3 figues, 1 table",,,,"cond-mat.mtrl-sci cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The contrast formation mechanism in Nanoscale Infrared Spectroscopy (Nano-IR
or AFM-IR) is analyzed for the boundary between two layers with different light
absorption, thermal and elastic parameters. Analytical results derived in the
decoupling approximation for low frequency limit show that the response
amplitude is linearly proportional to the intensity of the illuminating light
and thermal expansion coefficient. The spatial resolution between two
dissimilar materials is linearly proportional to the sum of inverse light
adsorption coefficients and to the effective thermal transfer length. The
difference of displacements height across the T-shape boundary (""thermo-elastic
step"") is proportional to the difference of the adsorption coefficients and
inversely proportional to the heat transfer coefficient. The step height
becomes thickness-independent for thick films and proportional to h^2 in a very
thin film
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 20:02:06 GMT""}]","2017-05-29"
"1705.09342","Arvind Saibaba","Julianne Chung, Arvind K. Saibaba, Matthew Brown, Erik Westman","Efficient generalized Golub-Kahan based methods for dynamic inverse
  problems","27 pages, 12 figures",,"10.1088/1361-6420/aaa0e1",,"math.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider efficient methods for computing solutions to and estimating
uncertainties in dynamic inverse problems, where the parameters of interest may
change during the measurement procedure. Compared to static inverse problems,
incorporating prior information in both space and time in a Bayesian framework
can become computationally intensive, in part, due to the large number of
unknown parameters. In these problems, explicit computation of the square root
and/or inverse of the prior covariance matrix is not possible. In this work, we
develop efficient, iterative, matrix-free methods based on the generalized
Golub-Kahan bidiagonalization that allow automatic regularization parameter and
variance estimation. We demonstrate that these methods can be more flexible
than standard methods and develop efficient implementations that can exploit
structure in the prior, as well as possible structure in the forward model.
Numerical examples from photoacoustic tomography, deblurring, and passive
seismic tomography demonstrate the range of applicability and effectiveness of
the described approaches. Specifically, in passive seismic tomography, we
demonstrate our approach on both synthetic and real data. To demonstrate the
scalability of our algorithm, we solve a dynamic inverse problem with
approximately $43,000$ measurements and $7.8$ million unknowns in under $40$
seconds on a standard desktop.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 20:04:03 GMT""}]","2018-02-14"
"1705.09343","Masha Chernyakova","M. Chernyakova, Iu. Babyk, D. Malyshev, Ie. Vovk, S. Tsygankov, H.
  Takahashi, Ya. Fukazawa","Study of orbital and superorbital variability of LSI +61 303 with X-ray
  data","accepted to MNRAS",,"10.1093/mnras/stx1335",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  LSI +61 303 is one of the few X-ray binaries with a Be star companion from
which radio, X-rays and high-energy gamma-ray (GeV and TeV) emission have been
observed. The nature of the high energy activity of the system is not yet fully
understood, but it is widely believed that it is generated due to the
interaction of the relativistic electrons leaving the compact object with the
photons and non-relativistic wind of the Be star. The superorbital variability
of the system has been observed in the radio, optical and X-ray domains and
could be due to the cyclic change of the Be star disk size. In this paper we
systematically review all publicly available data from Suzaku, XMM-Newton,
Chandra and Swift observatories in order to measure the absorption profile of
the circumstellar Be disk as a function of orbital and superorbital phases. We
also discuss short-term variability of the system, found during the analysis
and its implications for the understanding of the physical processes in this
system.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 20:04:36 GMT""}]","2017-07-19"
"1705.09344","Svetlana Varchenko","R. Rim\'anyi, V. Tarasov, A. Varchenko","Elliptic and K-theoretic stable envelopes and Newton polytopes","Latex, 37 pages; v.2: Appendix and Figure 1 added; v.3: missing shift
  in Theorem 2.9 added and a proof of Theorem 2.9 added",,,,"math.AG math-ph math.AT math.MP math.RT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we consider the cotangent bundles of partial flag varieties. We
construct the $K$-theoretic stable envelopes for them and also define a version
of the elliptic stable envelopes. We expect that our elliptic stable envelopes
coincide with the elliptic stable envelopes defined by M. Aganagic and A.
Okounkov. We give formulas for the $K$-theoretic stable envelopes and our
elliptic stable envelopes. We show that the $K$-theoretic stable envelopes are
suitable limits of our elliptic stable envelopes. That phenomenon was predicted
by M. Aganagic and A. Okounkov. Our stable envelopes are constructed in terms
of the elliptic and trigonometric weight functions which originally appeared in
the theory of integral representations of solutions of qKZ equations twenty
years ago. (More precisely, the elliptic weight functions had appeared earlier
only for the $\frak{gl}_2$ case.) We prove new properties of the trigonometric
weight functions. Namely, we consider certain evaluations of the trigonometric
weight functions, which are multivariable Laurent polynomials, and show that
the Newton polytopes of the evaluations are embedded in the Newton polytopes of
the corresponding diagonal evaluations. That property implies the fact that the
trigonometric weight functions project to the $K$-theoretic stable envelopes.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 20:06:23 GMT""},{""version"":""v2"",""created"":""Mon, 12 Jun 2017 19:40:40 GMT""},{""version"":""v3"",""created"":""Thu, 28 Jun 2018 18:06:25 GMT""}]","2018-07-02"
"1705.09345","Felipe Crasto de Lima","F. Crasto de Lima, Gerson J. Ferreira, and R. H. Miwa","Tuning the topological states in metal-organic bilayers",,"Phys. Rev. B 96, 115426 (2017)","10.1103/PhysRevB.96.115426",,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We have investigated the energetic stability and the electronic properties of
metal-organic topological insulators bilayers (BLs), $(MC_4S_4)_3$-BL, with
M=Ni and Pt, using first-principles calculations and tight-binding model. Our
findings show that $(MC_4S_4)_3$-BL is an appealing platform to perform
electronic band structure engineering, based on the topologically protected
chiral edge states. The energetic stability of the BLs is ruled by van der
Waals interactions; being the AA stacking the energetically most stable one.
The electronic band structure is characterized by a combination of bonding and
anti-bonding kagome band sets (KBSs), revealing that $(NiC_4S_4)_3$-BL presents
a Z$_2$-metallic phase, whereas $(PtC_4S_4)_3$-BL may present both
Z$_2$-metallic phase or quantum spin Hall phase. Those non-trivial topological
states were confirmed by the formation of chiral edge states in
$(MC_4S_4)_3$-BL nanoribbons. We show that the localization of the edge states
can be controlled with a normal external electric field, breaking the mirror
symmetry. Hence, the sign of electric field selects in which layer each set of
edge states are located. Such a control on the (layer) localization, of the
topological edge states, bring us an additional and interesting degree of
freedom to control the transport properties in layered metal-organic
topological insulator.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 20:08:51 GMT""},{""version"":""v2"",""created"":""Sat, 30 Sep 2017 12:51:50 GMT""}]","2017-10-03"
"1705.09346","Minati De","Ankush Acharyya, Minati De, Subhas C. Nandy and Bodhayan Roy","Range Assignment of Base-Stations Maximizing Coverage Area without
  Interference","27 pages, 15 figures",,"10.1016/j.tcs.2019.10.044",,"cs.CG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the problem of assigning non-overlapping geometric objects centered
at a given set of points such that the sum of area covered by them is
maximized. If the points are placed on a straight-line and the objects are
disks, then the problem is solvable in polynomial time. However, we show that
the problem is NP-hard even for simplest objects like disks or squares in
${\mathbb{R}}^2$. Eppstein [CCCG, pages 260--265, 2016] proposed a polynomial
time algorithm for maximizing the sum of radii (or perimeter) of
non-overlapping balls or disks when the points are arbitrarily placed on a
plane. We show that Eppstein's algorithm for maximizing sum of perimeter of the
disks in ${\mathbb{R}}^2$ gives a $2$-approximation solution for the sum of
area maximization problem. We propose a PTAS for our problem. These
approximation results are extendible to higher dimensions. All these
approximation results hold for the area maximization problem by regular convex
polygons with even number of edges centered at the given points.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 20:10:55 GMT""},{""version"":""v2"",""created"":""Wed, 26 Jul 2017 16:33:13 GMT""},{""version"":""v3"",""created"":""Thu, 14 Sep 2017 09:57:52 GMT""}]","2022-02-22"
"1705.09347","Michael Margaliot","Yoram Zarai and Michael Margaliot and Tamir Tuller","Ribosome Flow Model with Extended Objects",,,,,"q-bio.SC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study a deterministic mechanistic model for the flow of ribosomes along
the mRNA molecule, called the ribosome flow model with extended objects
(RFMEO). This model encapsulates many realistic features of translation
including non-homogeneous transition rates along the mRNA, the fact that every
ribosome covers several codons, and the fact that ribosomes cannot overtake one
another.
  The RFMEO is a mean-field approximation of an important model from
statistical mechanics called the totally asymmetric simple exclusion process
with extended objects (TASEPEO). We demonstrate that the RFMEO describes
biophysical aspects of translation better than previous mean-field
approximations, and that its predictions correlate well with those of TASEPEO.
However, unlike TASEPEO, the RFMEO is amenable to rigorous analysis using tools
from systems and control theory. We show that the ribosome density profile
along the mRNA in the RFMEO converges to a unique steady-state density that
depends on the length of the mRNA, the transition rates along it, and the
number of codons covered by every ribosome, but not on the initial density of
ribosomes along the mRNA. In particular, the protein production rate also
converges to a unique steady-state. Furthermore, if the transition rates along
the mRNA are periodic with a common period T then the ribosome density along
the mRNA and the protein production rate converge to a unique periodic pattern
with period T, that is, the model entrains to periodic excitations in the
transition rates.
  We believe that the RFMEO could be useful for modeling, understanding, and
re-engineering translation as well as other important biological processes.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 20:12:50 GMT""}]","2017-05-29"
"1705.09348","Giles Gardam","Giles Gardam","Detecting laws in power subgroups","20 pages, 1 figure; v1 attached code performs non-essential
  computation referred to in the article; v2 improved exposition","Comm. Algebra 47 (2019) 1699-1707","10.1080/00927872.2018.1513019",,"math.GR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A group law is said to be detectable in power subgroups if, for all coprime
$m$ and $n$, a group $G$ satisfies the law if and only if the power subgroups
$G^m$ and $G^n$ both satisfy the law. We prove that for all positive integers
$c$, nilpotency of class at most $c$ is detectable in power subgroups, as is
the $k$-Engel law for $k$ at most 4. In contrast, detectability in power
subgroups fails for solvability of given derived length: we construct a finite
group $W$ such that $W^2$ and $W^3$ are metabelian but $W$ has derived length
$3$. We analyse the complexity of the detectability of commutativity in power
subgroups, in terms of finite presentations that encode a proof of the result.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 20:20:20 GMT""},{""version"":""v2"",""created"":""Fri, 20 Oct 2017 17:59:57 GMT""}]","2021-03-09"
"1705.09349","Pavel Naumov","Pavel Naumov and Jia Tao","Together We Know How to Achieve: An Epistemic Logic of Know-How","An extended abstract of this paper will appear in Proceedings of 16th
  conference on Theoretical Aspects of Rationality and Knowledge (TARK-17),
  Liverpool, United Kingdom, July 24-26, 2017",,,,"cs.AI cs.GT cs.LO cs.MA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The existence of a coalition strategy to achieve a goal does not necessarily
mean that the coalition has enough information to know how to follow the
strategy. Neither does it mean that the coalition knows that such a strategy
exists. The article studies an interplay between the distributed knowledge,
coalition strategies, and coalition ""know-how"" strategies. The main technical
result is a sound and complete trimodal logical system that describes the
properties of this interplay.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 20:22:16 GMT""},{""version"":""v2"",""created"":""Thu, 15 Jun 2017 18:59:15 GMT""}]","2017-06-19"
"1705.09350","Nan Jiang","Max Gunzburger, Nan Jiang, Zhu Wang","An efficient algorithm for simulating ensembles of parameterized flow
  problems","20 pages, 3 figures",,,,"math.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Many applications of computational fluid dynamics require multiple
simulations of a flow under different input conditions. In this paper, a
numerical algorithm is developed to efficiently determine a set of such
simulations in which the individually independent members of the set are
subject to different viscosity coefficients, initial conditions, and/or body
forces. The proposed scheme applied to the flow ensemble leads to need to solve
a single linear system with multiple right-hand sides, and thus is
computationally more efficient than solving for all the simulations separately.
We show that the scheme is nonlinearly and long-term stable under certain
conditions on the time-step size and a parameter deviation ratio. Rigorous
numerical error estimate shows the scheme is of first-order accuracy in time
and optimally accurate in space. Several numerical experiments are presented to
illustrate the theoretical results.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 20:23:57 GMT""}]","2017-05-29"
"1705.09351","Madappa Prakash","A. A. Mamun, C. Constantinou, M. Prakash","Pairing properties from random distributions of single-particle energy
  levels","8 pages and 12 figures added in new sections","Phys. Rev. C 97, 064324 (2018)","10.1103/PhysRevC.97.064324",,"nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Exploiting the similarity between the bunched single-particle energy levels
of nuclei and of random distributions around the Fermi surface, pairing
properties of the latter are calculated to establish statistically-based bounds
on the basic characteristics of the pairing phenomenon. When the most probable
values for the pairing gaps germane to the BCS formalism are used to calculate
thermodynamic quantities, we find that while the ratio of the critical
temperature Tc to the zero-temperature pairing gap is close to its BCS Fermi
gas value, the ratio of the superfluid to the normal phase specific heats at Tc
differs significantly from its Fermi gas counterpart. The largest deviations
occur when a few levels lie closely on either side of the Fermi energy but
other levels are far away from it. The influence of thermal fluctuations,
expected to be large for systems of finite number of particles, were also
investigated using a semiclassical treatment of fluctuations. When the average
pairing gaps along with those differing by one standard deviations are used,
the characteristic discontinuity of the specific heat at Tc in the BCS
formalism was transformed to a shoulder-like structure indicating the
suppression of a second order phase transition as experimentally observed in
nano-particles and several nuclei. Contrasting semiclassical and quantum
treatments of fluctuations for the random spacing model is currently underway.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 20:24:10 GMT""},{""version"":""v2"",""created"":""Thu, 7 Dec 2017 17:02:15 GMT""}]","2018-07-04"
"1705.09352","Zhiyong Zhang","Zhiyong Zhang and Lucio Frydman","Partial Fourier techniques in single-shot cross-term spatiotemporal
  encoded MRI","Running Title: Partial Fourier methods in single-shot xSPEN MRI. Word
  count: Figures and Tables: 5 Figures, 0 Tables Equations count: 8 References
  count: 25",,,,"physics.med-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Purpose: Cross-term spatiotemporal encoding-xSPEN-is a single-shot imaging
approach with exceptional resilience to field heterogeneities: its images do
not require a priori information nor use post-acquisition corrections, to
deliver faithfully the spatial distribution. xSPEN, however, suffers from SNR
penalties due to its non-Fourier nature and due to diffusion losses- specially
when desiring high resolution. This study explores partial Fourier transform
approaches that acting along either the readout or the spatiotemporally-encoded
dimensions, reduce these penalties.
  Methods: xSPEN uses an orthogonal gradient to read, in direct space, the
lowbandwidth dimension. This changes substantially the nature of partial
Fourier acquisitions vis-a-vis conventional imaging counterparts. A suitable
theoretical analysis, however, allows one to implement these procedures along
either the low-bandwidth or readout axes.
  Results: Partial Fourier single-shot xSPEN methods are illustrated on
preclinical and human scanners. Owing to their reduction in the experimental
acquisition times, these methods provide substantial sensitivity gains
vis-a-vis previous implementations for a given targeted in-plane resolution.
The magnitude of these gains is as expected.
  Conclusion: Partial Fourier approaches, particularly when implemented along
the xSPEN axis, can provide substantial sensitivity advantages at minimal costs
in the operation of the single-shot experiments.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 20:37:34 GMT""}]","2017-05-29"
"1705.09353","Carlton Macdonald Downey","Carlton Downey, Ahmed Hefny, Boyue Li, Byron Boots, Geoffrey Gordon","Predictive State Recurrent Neural Networks",,,,,"stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a new model, Predictive State Recurrent Neural Networks (PSRNNs),
for filtering and prediction in dynamical systems. PSRNNs draw on insights from
both Recurrent Neural Networks (RNNs) and Predictive State Representations
(PSRs), and inherit advantages from both types of models. Like many successful
RNN architectures, PSRNNs use (potentially deeply composed) bilinear transfer
functions to combine information from multiple sources. We show that such
bilinear functions arise naturally from state updates in Bayes filters like
PSRs, in which observations can be viewed as gating belief states. We also show
that PSRNNs can be learned effectively by combining Backpropogation Through
Time (BPTT) with an initialization derived from a statistically consistent
learning algorithm for PSRs called two-stage regression (2SR). Finally, we show
that PSRNNs can be factorized using tensor decomposition, reducing model size
and suggesting interesting connections to existing multiplicative architectures
such as LSTMs. We applied PSRNNs to 4 datasets, and showed that we outperform
several popular alternative approaches to modeling dynamical systems in all
cases.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 20:40:13 GMT""},{""version"":""v2"",""created"":""Sun, 18 Jun 2017 00:01:46 GMT""}]","2017-06-20"
"1705.09354","Dominic Verdon","Dominic Verdon","Coherence for braided and symmetric pseudomonoids","Linked Globular workspace at http://globular.science/1705.001v2",,,,"math.CT cs.FL math.QA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Presentations for unbraided, braided and symmetric pseudomonoids are defined.
Biequivalences characterising the semistrict bicategories generated by these
presentations are proven. It is shown that these biequivalences categorify
results in the theory of monoids and commutative monoids, and generalise
standard coherence theorems for braided and symmetric monoidal categories.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 20:45:37 GMT""},{""version"":""v2"",""created"":""Mon, 29 May 2017 22:20:58 GMT""},{""version"":""v3"",""created"":""Mon, 3 Dec 2018 17:16:55 GMT""}]","2018-12-04"
"1705.09355","Avanti Athreya","Keith Levin, Avanti Athreya, Minh Tang, Vince Lyzinski, Youngser Park,
  Carey E. Priebe","A central limit theorem for an omnibus embedding of multiple random
  graphs and implications for multiscale network inference",,,,,"stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Performing statistical analyses on collections of graphs is of import to many
disciplines, but principled, scalable methods for multi-sample graph inference
are few. Here we describe an ""omnibus"" embedding in which multiple graphs on
the same vertex set are jointly embedded into a single space with a distinct
representation for each graph. We prove a central limit theorem for this
embedding and demonstrate how it streamlines graph comparison, obviating the
need for pairwise subspace alignments. The omnibus embedding achieves
near-optimal inference accuracy when graphs arise from a common distribution
and yet retains discriminatory power as a test procedure for the comparison of
different graphs. Moreover, this joint embedding and the accompanying central
limit theorem are important for answering multiscale graph inference questions,
such as the identification of specific subgraphs or vertices responsible for
similarity or difference across networks. We illustrate this with a pair of
analyses of connectome data derived from dMRI and fMRI scans of human subjects.
In particular, we show that this embedding allows the identification of
specific brain regions associated with population-level differences. Finally,
we sketch how the omnibus embedding can be used to address pressing open
problems, both theoretical and practical, in multisample graph inference.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 20:48:15 GMT""},{""version"":""v2"",""created"":""Wed, 14 Jun 2017 17:56:17 GMT""},{""version"":""v3"",""created"":""Tue, 18 Jul 2017 02:48:14 GMT""},{""version"":""v4"",""created"":""Fri, 15 Feb 2019 14:15:27 GMT""},{""version"":""v5"",""created"":""Wed, 26 Jun 2019 01:49:26 GMT""}]","2019-06-27"
"1705.09356","Dimitris Christodoulou","Dimitris M. Christodoulou and Demosthenes Kazanas","A Physical Interpretation of the Titius-Bode Rule and its Connection to
  the Closed Orbits of Bertrand's Theorem","Final version, issues resolved, submitted to RAA",,"10.1088/1674-4527/17/12/129",,"astro-ph.EP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the geometric Titius-Bode rule for the semimajor axes of
planetary orbits. We derive an equivalent rule for the midpoints of the
segments between consecutive orbits along the radial direction and we interpret
it physically in terms of the work done in the gravitational field of the Sun
by particles whose orbits are perturbed around each planetary orbit. On such
energetic grounds, it is not surprising that some exoplanets in multiple-planet
extrasolar systems obey the same relation. But it is surprising that this
simple interpretation of the Titius-Bode rule also reveals new properties of
the bound closed orbits predicted by Bertrand's theorem and known since 1873.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 20:49:28 GMT""},{""version"":""v2"",""created"":""Wed, 7 Jun 2017 19:38:36 GMT""},{""version"":""v3"",""created"":""Thu, 15 Jun 2017 02:32:45 GMT""},{""version"":""v4"",""created"":""Sun, 16 Jul 2017 19:30:39 GMT""},{""version"":""v5"",""created"":""Sun, 27 Aug 2017 07:49:23 GMT""},{""version"":""v6"",""created"":""Mon, 11 Sep 2017 23:38:27 GMT""}]","2017-12-20"
"1705.09357","Hanna Furmanczyk","Hanna Furma\'nczyk, Kowsalya V, Vernold Vivin J","On Star Coloring of Splitting Graphs",,,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we consider the problem of a star coloring. In general case
the problems in NP-complete. We establish the star chromatic number for
splitting graph of complete and complete bipartite graphs, as well of paths and
cycles. Our proofs are constructive, so they lead to appropriate star colorings
of graphs under consideration.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 20:49:31 GMT""}]","2017-05-29"
"1705.09358","Darren Strash","Raphael Kimmig and Henning Meyerhenke and Darren Strash","Shared Memory Parallel Subgraph Enumeration","18 pages, 12 figures, To appear at the 7th IEEE Workshop on Parallel
  / Distributed Computing and Optimization (PDCO 2017)",,,,"cs.DC cs.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The subgraph enumeration problem asks us to find all subgraphs of a target
graph that are isomorphic to a given pattern graph. Determining whether even
one such isomorphic subgraph exists is NP-complete---and therefore finding all
such subgraphs (if they exist) is a time-consuming task. Subgraph enumeration
has applications in many fields, including biochemistry and social networks,
and interestingly the fastest algorithms for solving the problem for
biochemical inputs are sequential. Since they depend on depth-first tree
traversal, an efficient parallelization is far from trivial. Nevertheless,
since important applications produce data sets with increasing difficulty,
parallelism seems beneficial.
  We thus present here a shared-memory parallelization of the state-of-the-art
subgraph enumeration algorithms RI and RI-DS (a variant of RI for dense graphs)
by Bonnici et al. [BMC Bioinformatics, 2013]. Our strategy uses work stealing
and our implementation demonstrates a significant speedup on real-world
biochemical data---despite a highly irregular data access pattern. We also
improve RI-DS by pruning the search space better; this further improves the
empirical running times compared to the already highly tuned RI-DS.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 20:52:48 GMT""}]","2017-05-29"
"1705.09359","Niek Tax","Niek Tax, Emin Alasgarov, Natalia Sidorova, Wil M.P. van der Aalst,
  Reinder Haakma","Generating Time-Based Label Refinements to Discover More Precise Process
  Models",,,,,"cs.LG cs.AI cs.DB","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Process mining is a research field focused on the analysis of event data with
the aim of extracting insights related to dynamic behavior. Applying process
mining techniques on data from smart home environments has the potential to
provide valuable insights in (un)healthy habits and to contribute to ambient
assisted living solutions. Finding the right event labels to enable the
application of process mining techniques is however far from trivial, as simply
using the triggering sensor as the label for sensor events results in
uninformative models that allow for too much behavior (overgeneralizing).
Refinements of sensor level event labels suggested by domain experts have been
shown to enable discovery of more precise and insightful process models.
However, there exists no automated approach to generate refinements of event
labels in the context of process mining. In this paper we propose a framework
for the automated generation of label refinements based on the time attribute
of events, allowing us to distinguish behaviourally different instances of the
same event type based on their time attribute. We show on a case study with
real life smart home event data that using automatically generated refined
labels in process discovery, we can find more specific, and therefore more
insightful, process models. We observe that one label refinement could have an
effect on the usefulness of other label refinements when used together.
Therefore, we explore four strategies to generate useful combinations of
multiple label refinements and evaluate those on three real life smart home
event logs.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 21:01:20 GMT""},{""version"":""v2"",""created"":""Tue, 31 Oct 2017 16:22:43 GMT""}]","2017-11-01"
"1705.09360","Sarah Chastain","J.T. Schmelz, G.M. Christian, R.A. Chastain","The Coronal Loop Inventory Project: Expanded Analysis and Results",,"ApJ, 831, 199 (2016)","10.3847/0004-637X/831/2/199",,"astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We have expanded upon earlier work that investigates the relative importance
of coronal loops with isothermal $versus$ multithermal cross-field temperature
distributions. These results are important for determining if loops have
substructure in the form of unresolved magnetic strands. We have increased the
number of loops targeted for temperature analysis from 19 to 207 with the
addition of 188 new loops from multiple regions. We selected all loop segments
visible in the 171-\AA\ images of the Atmospheric Imaging Assembly (AIA) that
had a clean background. 86 of the new loops were rejected because they could
not be reliably separated from the background in other AIA filters. 61 loops
required multithermal models to reproduce the observations. 28 loops were
effectively isothermal, that is, the plasma emission to which AIA is sensitive
could not be distinguished from isothermal emission, within uncertainties. 10
loops were isothermal. Also part of our inventory were one small flaring loop,
one very cool loop whose temperature distribution could not be constrained by
the AIA data, and one loop with inconclusive results. Our survey can confirm an
unexpected result from the pilot study: we found no isothermal loop segments
where we could properly use the 171-to-193 ratio method, which would be similar
to the analysis done for many loops observed with TRACE and EIT. We recommend
caution to observers who assume the loop plasma is isothermal, and hope that
these results will influence the direction of coronal heating models and the
efforts modelers spend on various heating scenarios.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 21:02:19 GMT""}]","2017-05-29"
"1705.09361","Francois Fillion-Gourdeau","F. Fillion-Gourdeau and E. Lorin","Simple digital quantum algorithm for symmetric first order linear
  hyperbolic systems","28 pages, 12 figures, major rewriting of the section describing the
  numerical method, simplified the presentation and notation, reorganized the
  sections, comments are welcomed",,,,"quant-ph math.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper is devoted to the derivation of a digital quantum algorithm for
the Cauchy problem for symmetric first order linear hyperbolic systems, thanks
to the reservoir technique. The reservoir technique is a method designed to
avoid artificial diffusion generated by first order finite volume methods
approximating hyperbolic systems of conservation laws. For some class of
hyperbolic systems, namely those with constant matrices in several dimensions,
we show that the combination of i) the reservoir method and ii) the alternate
direction iteration operator splitting approximation, allows for the derivation
of algorithms only based on simple unitary transformations, thus perfectly
suitable for an implementation on a quantum computer. The same approach can
also be adapted to scalar one-dimensional systems with non-constant velocity by
combining with a non-uniform mesh. The asymptotic computational complexity for
the time evolution is determined and it is demonstrated that the quantum
algorithm is more efficient than the classical version. However, in the quantum
case, the solution is encoded in probability amplitudes of the quantum
register. As a consequence, as with other similar quantum algorithms, a
post-processing mechanism has to be used to obtain general properties of the
solution because a direct reading cannot be performed as efficiently as the
time evolution.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 21:05:25 GMT""},{""version"":""v2"",""created"":""Fri, 6 Apr 2018 18:29:46 GMT""}]","2018-04-10"
"1705.09362","Mustapha Hached","M. Hached and K. Jbilou","Numerical solutions to large-scale differential Lyapunov matrix
  equations",,,,,"math.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the present paper, we consider large-scale differential Lyapunov matrix
equations having a low rank constant term. We present two new approaches for
the numerical resolution of such differential matrix equations. The first
approach is based on the integral expression of the exact solution and an
approximation method for the computation of the exponential of a matrix times a
block of vectors. In the second approach, we first project the initial problem
onto a block (or extended block) Krylov subspace and get a low-dimensional
differential Lyapunov matrix equation. The latter differential matrix problem
is then solved by the Backward Differentiation Formula method (BDF) and the
obtained solution is used to build the low rank approximate solution of the
original problem. The process being repeated until some prescribed accuracy is
achieved. We give some new theoretical results and present some numerical
experiments.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 21:07:51 GMT""},{""version"":""v2"",""created"":""Mon, 29 May 2017 12:05:25 GMT""}]","2017-05-30"
"1705.09363","Till Mossakowski","Till Mossakowski, Florian Rabe, Mihai Codescu","Canonical Selection of Colimits",,,,,"cs.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Colimits are a powerful tool for the combination of objects in a category. In
the context of modeling and specification, they are used in the
institution-independent semantics (1) of instantiations of parameterised
specifications (e.g. in the specification language CASL), and (2) of
combinations of networks of specifications (in the OMG standardised language
DOL).
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 21:09:11 GMT""}]","2017-05-29"
"1705.09364","Constantin Schrade","Constantin Schrade, Manisha Thakurathi, Christopher Reeg, Silas
  Hoffman, Jelena Klinovaja, and Daniel Loss","Low-field Topological Threshold in Majorana Double Nanowires",,"Phys. Rev. B 96, 035306 (2017)","10.1103/PhysRevB.96.035306",,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A hard proximity-induced superconducting gap has recently been observed in
semiconductor nanowire systems at low magnetic fields. However, in the
topological regime at high magnetic fields, a soft gap emerges and represents a
fundamental obstacle to topologically protected quantum information processing
with Majorana bound states. Here we show that in a setup of double Rashba
nanowires that are coupled to an s-wave superconductor and subjected to an
external magnetic field along the wires, the topological threshold can be
significantly reduced by the destructive interference of direct and
crossed-Andreev pairing in this setup, precisely down to the magnetic field
regime in which current experimental technology allows for a hard
superconducting gap. We also show that the resulting Majorana bound states
exhibit sufficiently short localization lengths, which makes them ideal
candidates for future braiding experiments.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 21:09:34 GMT""},{""version"":""v2"",""created"":""Sun, 10 Sep 2017 17:07:28 GMT""}]","2017-09-12"
"1705.09365","John Greenlees","J.P.C. Greenlees","Four approaches to cohomology theories with reality",,,,,"math.AT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We give an account of well known calculations of the RO(Q)-graded coefficient
rings of some of the most basic Q-equivariant cohomology theories, where Q is a
group of order 2. One purpose is to advertise the effectiveness of the Tate
square, showing it has advantages over the slice spectral sequences in
algebraically simple cases. A second purpose is to give a single account
showing how to translate between the languages of different approaches. [v2
corrects some typos and adds some thanks and references, v3 corrects a few more
typos].
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 21:13:42 GMT""},{""version"":""v2"",""created"":""Thu, 8 Jun 2017 07:41:55 GMT""},{""version"":""v3"",""created"":""Sun, 22 Oct 2017 12:04:02 GMT""}]","2017-10-24"
"1705.09366","Erik Saule","Erik Saule, Dinesh Panchananam, Alexander Hohl, Wenwu Tang, Eric
  Delmelle","Parallel Space-Time Kernel Density Estimation",,,,,"cs.DC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The exponential growth of available data has increased the need for
interactive exploratory analysis. Dataset can no longer be understood through
manual crawling and simple statistics. In Geographical Information Systems
(GIS), the dataset is often composed of events localized in space and time; and
visualizing such a dataset involves building a map of where the events
occurred.
  We focus in this paper on events that are localized among three dimensions
(latitude, longitude, and time), and on computing the first step of the
visualization pipeline, space-time kernel density estimation (STKDE), which is
most computationally expensive. Starting from a gold standard implementation,
we show how algorithm design and engineering, parallel decomposition, and
scheduling can be applied to bring near real-time computing to space-time
kernel density estimation. We validate our techniques on real world datasets
extracted from infectious disease, social media, and ornithology.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 21:16:37 GMT""}]","2017-05-29"
"1705.09367","Kevin Roth","Kevin Roth, Aurelien Lucchi, Sebastian Nowozin, Thomas Hofmann","Stabilizing Training of Generative Adversarial Networks through
  Regularization",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deep generative models based on Generative Adversarial Networks (GANs) have
demonstrated impressive sample quality but in order to work they require a
careful choice of architecture, parameter initialization, and selection of
hyper-parameters. This fragility is in part due to a dimensional mismatch or
non-overlapping support between the model distribution and the data
distribution, causing their density ratio and the associated f-divergence to be
undefined. We overcome this fundamental limitation and propose a new
regularization approach with low computational cost that yields a stable GAN
training procedure. We demonstrate the effectiveness of this regularizer across
several architectures trained on common benchmark image generation tasks. Our
regularization turns GAN models into reliable building blocks for deep
learning.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 21:17:50 GMT""},{""version"":""v2"",""created"":""Tue, 7 Nov 2017 11:17:04 GMT""}]","2017-11-08"
"1705.09368","Liqian Ma","Liqian Ma, Xu Jia, Qianru Sun, Bernt Schiele, Tinne Tuytelaars, Luc
  Van Gool","Pose Guided Person Image Generation","Xu Jia and Qianru Sun contribute equally. Accepted in Proceedings of
  31st Conference on Neural Information Processing Systems (NIPS 2017)",,,,"cs.CV","http://creativecommons.org/licenses/by-nc-sa/4.0/","  This paper proposes the novel Pose Guided Person Generation Network (PG$^2$)
that allows to synthesize person images in arbitrary poses, based on an image
of that person and a novel pose. Our generation framework PG$^2$ utilizes the
pose information explicitly and consists of two key stages: pose integration
and image refinement. In the first stage the condition image and the target
pose are fed into a U-Net-like network to generate an initial but coarse image
of the person with the target pose. The second stage then refines the initial
and blurry result by training a U-Net-like generator in an adversarial way.
Extensive experimental results on both 128$\times$64 re-identification images
and 256$\times$256 fashion photos show that our model generates high-quality
person images with convincing details.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 21:29:07 GMT""},{""version"":""v2"",""created"":""Thu, 1 Jun 2017 11:56:51 GMT""},{""version"":""v3"",""created"":""Mon, 19 Jun 2017 13:41:32 GMT""},{""version"":""v4"",""created"":""Tue, 5 Sep 2017 07:43:06 GMT""},{""version"":""v5"",""created"":""Fri, 3 Nov 2017 20:43:15 GMT""},{""version"":""v6"",""created"":""Sun, 28 Jan 2018 09:25:08 GMT""}]","2018-01-30"
"1705.09369","Vincent Christlein","Vincent Christlein, Martin Gropp, Stefan Fiel, Andreas Maier","Unsupervised Feature Learning for Writer Identification and Writer
  Retrieval","ICDAR2017 camera ready (fixed p@2 values, missing table references)",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deep Convolutional Neural Networks (CNN) have shown great success in
supervised classification tasks such as character classification or dating.
Deep learning methods typically need a lot of annotated training data, which is
not available in many scenarios. In these cases, traditional methods are often
better than or equivalent to deep learning methods. In this paper, we propose a
simple, yet effective, way to learn CNN activation features in an unsupervised
manner. Therefore, we train a deep residual network using surrogate classes.
The surrogate classes are created by clustering the training dataset, where
each cluster index represents one surrogate class. The activations from the
penultimate CNN layer serve as features for subsequent classification tasks. We
evaluate the feature representations on two publicly available datasets. The
focus lies on the ICDAR17 competition dataset on historical document writer
identification (Historical-WI). We show that the activation features trained
without supervision are superior to descriptors of state-of-the-art writer
identification methods. Additionally, we achieve comparable results in the case
of handwriting classification using the ICFHR16 competition dataset on
historical Latin script types (CLaMM16).
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 21:30:40 GMT""},{""version"":""v2"",""created"":""Mon, 3 Jul 2017 11:26:08 GMT""},{""version"":""v3"",""created"":""Fri, 18 Aug 2017 09:04:49 GMT""}]","2017-08-21"
"1705.09370","Luka Mili\'cevi\'c","Luka Mili\'cevi\'c","Covering complete graphs by monochromatically bounded sets",,,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Given a $k$-colouring of the edges of the complete graph $K_n$, are there
$k-1$ monochromatic components that cover its vertices? This important special
case of the well-known Lov\'asz-Ryser conjecture is still open. In this paper
we consider a strengthening of this question, where we insist that the covering
sets are not merely connected but have bounded diameter. In particular, we
prove that for any colouring of $E(K_n)$ with 4 colours, there is a choice of
sets $A_1, A_2, A_3$ that cover all vertices, and colours $c_1, c_2, c_3$, such
that for each $i = 1,2,3$ the monochromatic subgraph induced by the set $A_i$
and the colour $c_i$ has diameter at most 160.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 21:31:46 GMT""}]","2017-05-29"
"1705.09371","Roland Kawakami","Yunqiu (Kelly) Luo, Jinsong Xu, Tiancong Zhu, Guanzhong Wu, Elizabeth
  J. McCormick, Wenbo Zhan, Mahesh R. Neupane, Roland K. Kawakami","Opto-Valleytronic Spin Injection in Monolayer MoS2/Few-Layer Graphene
  Hybrid Spin Valves","Nano Letters, in press","Nano Letters 17, 3877-3883 (2017)","10.1021/acs.nanolett.7b01393",,"cond-mat.mes-hall cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Two dimensional (2D) materials provide a unique platform for spintronics and
valleytronics due to the ability to combine vastly different functionalities
into one vertically-stacked heterostructure, where the strengths of each of the
constituent materials can compensate for the weaknesses of the others. Graphene
has been demonstrated to be an exceptional material for spin transport at room
temperature, however it lacks a coupling of the spin and optical degrees of
freedom. In contrast, spin/valley polarization can be efficiently generated in
monolayer transition metal dichalcogenides (TMD) such as MoS2 via absorption of
circularly-polarized photons, but lateral spin or valley transport has not been
realized at room temperature. In this letter, we fabricate monolayer
MoS2/few-layer graphene hybrid spin valves and demonstrate, for the first time,
the opto-valleytronic spin injection across a TMD/graphene interface. We
observe that the magnitude and direction of spin polarization is controlled by
both helicity and photon energy. In addition, Hanle spin precession
measurements confirm optical spin injection, spin transport, and electrical
detection up to room temperature. Finally, analysis by a one-dimensional
drift-diffusion model quantifies the optically injected spin current and the
spin transport parameters. Our results demonstrate a 2D spintronic/valleytronic
system that achieves optical spin injection and lateral spin transport at room
temperature in a single device, which paves the way for multifunctional 2D
spintronic devices for memory and logic applications.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 21:36:48 GMT""}]","2017-06-27"
"1705.09372","Salman Salamatian","Salman Salamatian, Ahmad Beirami, Asaf Cohen, Muriel M\'edard","Centralized vs Decentralized Multi-Agent Guesswork","Accepted at IEEE International Symposium on Information Theory (ISIT)
  2017",,,,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study a notion of guesswork, where multiple agents intend to launch a
coordinated brute-force attack to find a single binary secret string, and each
agent has access to side information generated through either a BEC or a BSC.
The average number of trials required to find the secret string grows
exponentially with the length of the string, and the rate of the growth is
called the guesswork exponent. We compute the guesswork exponent for several
multi-agent attacks. We show that a multi-agent attack reduces the guesswork
exponent compared to a single agent, even when the agents do not exchange
information to coordinate their attack, and try to individually guess the
secret string using a predetermined scheme in a decentralized fashion. Further,
we show that the guesswork exponent of two agents who do coordinate their
attack is strictly smaller than that of any finite number of agents
individually performing decentralized guesswork.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 21:38:29 GMT""}]","2017-05-29"
"1705.09373","Felipe G\'omez-Cuba","Felipe G\'omez-Cuba, Elza Erkip, Sundeep Rangan, Francisco J.
  Gonz\'alez-Casta\~no","Capacity Scaling of Cellular Networks: Impact of Bandwidth,
  Infrastructure Density and Number of Antennas","30 pages, 4 figures, 1 table. Published in IEEE Transactions on
  Wireless Communications",,,,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The availability of very wide spectrum in millimeter wave bands combined with
large antenna arrays and ultra dense networks raises two basic questions: What
is the true value of overly abundant degrees of freedom and how can networks be
designed to fully exploit them? This paper determines the capacity scaling of
large cellular networks as a function of bandwidth, area, number of antennas
and base station density. It is found that the network capacity has a
fundamental bandwidth scaling limit, beyond which the network becomes
power-limited. An infrastructure multi-hop protocol achieves the optimal
network capacity scaling for all network parameters. In contrast, current
protocols that use only single-hop direct transmissions can not achieve the
capacity scaling in wideband regimes except in the special case when the
density of base stations is taken to impractical extremes. This finding
suggests that multi-hop communication will be important to fully realize the
potential of next-generation cellular networks. Dedicated relays, if
sufficiently dense, can also perform this task, relieving user nodes from the
battery drain of cooperation. On the other hand, more sophisticated strategies
such as hierarchical cooperation, that are essential for achieving capacity
scaling in ad hoc networks, are unnecessary in the cellular context.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 21:39:12 GMT""},{""version"":""v2"",""created"":""Tue, 7 Nov 2017 03:48:13 GMT""},{""version"":""v3"",""created"":""Fri, 25 Jan 2019 15:19:29 GMT""},{""version"":""v4"",""created"":""Thu, 20 Feb 2020 12:41:40 GMT""}]","2020-02-21"
"1705.09374","Michael Margaliot","Yoram Zarai and Alexander Ovseevich and Michael Margaliot","Optimal Translation Along a Circular mRNA",,,,,"q-bio.SC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The ribosome flow model on a ring (RFMR) is a deterministic model for
translation of a circularized mRNA. We derive a new spectral representation for
the optimal steady-state production rate and the corresponding optimal
steady-state ribosomal density in the RFMR. This representation has several
important advantages. First, it provides a simple and numerically stable
algorithm for determining the optimal values even in very long rings. Second,
it enables efficient computation of the sensitivity of the optimal production
rate to small changes in the transition rates along the mRNA. Third, it implies
that the optimal steady-state production rate is a strictly concave function of
the transition rates. Thus maximizing the optimal steady-state production rate
with respect to the rates, under an affine constraint on the rates becomes a
convex optimization problem that admits a unique solution, which can be
determined numerically using highly efficient algorithms. This optimization
problem is important, for example, when re-engineering heterologous genes in a
host organism. We describe the implications of our results to this and other
aspects of translation.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 21:43:50 GMT""}]","2017-05-29"
"1705.09375","Michael T. Lacey","Michael T. Lacey, Dar\'io Mena, Maria Carmen Reguera","Sparse Bounds for Bochner-Riesz Multipliers","15 pages, 2 figures","J. Fourier Anal. Appl., 25 (2019) 523--537","10.1007/s00041-017-9590-2",,"math.CA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Bochner-Riesz multipliers $ B_{\delta }$ on $ \mathbb R ^{n}$ are shown
to satisfy a range of sparse bounds, for all $0< \delta < \frac {n-1}2 $. The
range of sparse bounds increases to the optimal range, as $ \delta $ increases
to the critical value, $ \delta =\frac {n-1}2$, even assuming only partial
information on the Bochner-Riesz conjecture in dimensions $ n \geq 3$. In
dimension $n=2$, we prove a sharp range of sparse bounds. The method of proof
is based upon a `single scale' analysis, and yields the sharpest known weighted
estimates for the Bochner-Riesz multipliers in the category of Muckenhoupt
weights.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 21:48:01 GMT""},{""version"":""v2"",""created"":""Wed, 31 May 2017 18:51:18 GMT""},{""version"":""v3"",""created"":""Fri, 13 Oct 2017 04:09:55 GMT""},{""version"":""v4"",""created"":""Thu, 9 Nov 2017 02:24:16 GMT""}]","2019-05-17"
"1705.09376","Jonathon Coleman","O. Burrow, A. Carroll, S. Chattopadhyay, J. Coleman, G. Elertas, J.
  Heffer, C.Metelko, R. Moore, D. Morris, M. Perl, J. Ralph, J. Tinsley","Atom Interferometry for Dark Contents of the Vacuum Searches","5 pages, 3 figures",,,,"physics.ins-det physics.atom-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A cold atom interferometer is being developed using 85Rb atoms towards a
search for the dark contents of the vacuum, and as a test stand for inertial
sensing applications. Here we outline the current status of the experiment and
report the observation of Ramsey interference fringes in the apparatus.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 21:50:49 GMT""}]","2017-05-29"
"1705.09377","Michael Magee","Michael Magee","Counting one sided simple closed geodesics on Fuchsian thrice punctured
  projective planes","16 pages, 2 figures, small tidy up before submission",,,,"math.GT math.DG math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove that there is a true asymptotic formula for the number of one sided
simple closed curves of length $\leq L$ on any Fuchsian real projective plane
with three points removed. The exponent of growth is independent of the
hyperbolic structure, and it is noninteger, in contrast to counting results of
Mirzakhani for simple closed curves on orientable Fuchsian surfaces.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 21:51:55 GMT""},{""version"":""v2"",""created"":""Fri, 8 Sep 2017 16:07:26 GMT""}]","2017-09-11"
"1705.09378","Jiahui Li","Jiahui Li, Yin Sun, Limin Xiao, Shidong Zhou, C. Emre Koksal","Analog Beam Tracking in Linear Antenna Arrays: Convergence, Optimality,
  and Performance","6 pages, 8 figures, Asilomar conference 2017",,,,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The directionality of millimeter-wave (mmWave) communications creates a
significant challenge in serving fast-moving mobile terminals on, e.g.,
high-speed vehicles, trains, and UAVs. This challenge is exacerbated in mmWave
systems using analog antenna arrays, because of the inherent non-convexity in
the control of the phase shifters. In this paper, we develop a recursive beam
tracking algorithm which can simultaneously achieve fast tracking speed, high
tracking accuracy, low complexity, and low pilot overhead. In static scenarios,
this algorithm converges to the minimum Cram\'er-Rao lower bound (CRLB) of beam
tracking with high probability. In dynamic scenarios, even at SNRs as low as
0dB, our algorithm is capable of tracking a mobile moving randomly at an
absolute angular velocity of 10-20 degrees per second, using only 5 pilot
symbols per second. If combining with a simple TDMA pilot pattern, this
algorithm can track hundreds of high-speed mobiles in 5G configurations. Our
simulations show that the tracking performance of this algorithm is much better
than several state-of-the-art algorithms.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 21:52:21 GMT""},{""version"":""v2"",""created"":""Sun, 19 Nov 2017 12:30:51 GMT""},{""version"":""v3"",""created"":""Wed, 29 Nov 2017 08:56:28 GMT""}]","2017-11-30"
"1705.09379","Jeroen Zuiddam","Matthias Christandl, Asger Kj{\ae}rulff Jensen, Jeroen Zuiddam","Tensor rank is not multiplicative under the tensor product","Fixed a typo in Remark 9","Linear Algebra Appl. 543 (2018) 125-139","10.1016/j.laa.2017.12.020",,"math.AC cs.CC quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The tensor rank of a tensor t is the smallest number r such that t can be
decomposed as a sum of r simple tensors. Let s be a k-tensor and let t be an
l-tensor. The tensor product of s and t is a (k + l)-tensor. Tensor rank is
sub-multiplicative under the tensor product. We revisit the connection between
restrictions and degenerations. A result of our study is that tensor rank is
not in general multiplicative under the tensor product. This answers a question
of Draisma and Saptharishi. Specifically, if a tensor t has border rank
strictly smaller than its rank, then the tensor rank of t is not multiplicative
under taking a sufficiently hight tensor product power. The ""tensor Kronecker
product"" from algebraic complexity theory is related to our tensor product but
different, namely it multiplies two k-tensors to get a k-tensor.
Nonmultiplicativity of the tensor Kronecker product has been known since the
work of Strassen.
  It remains an open question whether border rank and asymptotic rank are
multiplicative under the tensor product. Interestingly, lower bounds on border
rank obtained from generalised flattenings (including Young flattenings)
multiply under the tensor product.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 21:55:17 GMT""},{""version"":""v2"",""created"":""Tue, 29 Aug 2017 20:12:25 GMT""},{""version"":""v3"",""created"":""Fri, 26 Jan 2018 10:17:09 GMT""},{""version"":""v4"",""created"":""Thu, 29 Sep 2022 14:26:10 GMT""}]","2022-09-30"
"1705.09380","Miguel Bandres","Miguel A. Bandres, Mikael C. Rechtsman, and Mordechai Segev","Topological Photonic Quasicrystals: Fractal Topological Spectrum and
  Protected Transport","12 pages, 8 figures","Physical Review X 6, 011016 (2016)","10.1103/PhysRevX.6.011016",,"cond-mat.mes-hall physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show that it is possible to have a topological phase in two-dimensional
quasicrystals without any magnetic field applied, but instead introducing an
artificial gauge field via dynamic modulation. This topological quasicrystal
exhibits scatter-free unidirectional edge states that are extended along the
system's perimeter, contrary to the states of an ordinary quasicrystal system,
which are characterized by power-law decay. We find that the spectrum of this
Floquet topological quasicrystal exhibits a rich fractal (self-similar)
structure of topological ""minigaps,"" manifesting an entirely new phenomenon:
fractal topological systems. These topological minigaps form only when the
system size is sufficiently large because their gapless edge states penetrate
deep into the bulk. Hence, the topological structure emerges as a function of
the system size, contrary to periodic systems where the topological phase can
be completely characterized by the unit cell. We demonstrate the existence of
this topological phase both by using a topological index (Bott index) and by
studying the unidirectional transport of the gapless edge states and its
robustness in the presence of defects. Our specific model is a Penrose lattice
of helical optical waveguides - a photonic Floquet quasicrystal; however, we
expect this new topological quasicrystal phase to be universal.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 21:59:13 GMT""}]","2017-05-29"
"1705.09382","Vahan Huroyan","Vahan Huroyan and Gilad Lerman","Distributed Robust Subspace Recovery",,"SIAM J. Sci. Comput. 40 (2018) A3067-A3090","10.1137/17M1131659",,"math.NA cs.AI cs.DC cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose distributed solutions to the problem of Robust Subspace Recovery
(RSR). Our setting assumes a huge dataset in an ad hoc network without a
central processor, where each node has access only to one chunk of the dataset.
Furthermore, part of the whole dataset lies around a low-dimensional subspace
and the other part is composed of outliers that lie away from that subspace.
The goal is to recover the underlying subspace for the whole dataset, without
transferring the data itself between the nodes. We first apply the
Consensus-Based Gradient method to the Geometric Median Subspace algorithm for
RSR. For this purpose, we propose an iterative solution for the local dual
minimization problem and establish its r-linear convergence. We then explain
how to distributedly implement the Reaper and Fast Median Subspace algorithms
for RSR. The proposed algorithms display competitive performance on both
synthetic and real data.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 22:22:51 GMT""},{""version"":""v2"",""created"":""Sat, 3 Mar 2018 21:31:02 GMT""},{""version"":""v3"",""created"":""Wed, 4 Jul 2018 21:56:51 GMT""}]","2018-11-07"
"1705.09384","Alex McDaniel","Alex McDaniel, Tesla Jeltema, Stefano Profumo, Emma Storm","Multiwavelength Analysis of Dark Matter Annihilation and RX-DMFIT","21 pages, 9 figures, 2 tables, corrections to figures, additional
  text, accepted to JCAP","JCAP 1709:027,2017","10.1088/1475-7516/2017/09/027",,"astro-ph.HE astro-ph.CO hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Dark matter (DM) particles are predicted by several well motivated models to
yield Standard Model particles through self-annihilation that can potentially
be detected by astrophysical observations. In particular, the production of
charged particles from DM annihilation in astrophysical systems that contain
magnetic fields yields radio emission through synchrotron radiation and X-ray
emission through inverse Compton scattering of ambient photons. We introduce
RX-DMFIT, a tool used for calculating the expected secondary emission from DM
annihilation. RX-DMFIT includes a wide range of customizable astrophysical and
particle parameters and incorporates important astrophysics including the
diffusion of charged particles, relevant radiative energy losses, and magnetic
field modelling. We demonstrate the use and versatility of RX-DMFIT by
analyzing the potential radio and X-ray signals for a variety of DM particle
models and astrophysical environments including galaxy clusters, dwarf
spheroidal galaxies and normal galaxies. We then apply RX-DMFIT to a concrete
example using Segue I radio data to place constraints for a range of assumed DM
annihilation channels. For WIMP models with $M_{\chi} \leq 100$ GeV and
assuming weak diffusion, we find that the the leptonic $\mu^+\mu^-$ and
$\tau^+\tau^-$ final states provide the strongest constraints, placing limits
on the DM particle cross-section well below the thermal relic cross-section,
while even for the $b\bar{b}$ channel we find limits close to the thermal relic
cross-section. Our analysis shows that radio emission provides a highly
competitive avenue for dark matter searches.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 22:38:10 GMT""},{""version"":""v2"",""created"":""Fri, 25 Aug 2017 16:42:44 GMT""}]","2018-05-15"
"1705.09385","John Asplund","John Asplund and Kossi Edoh and Ruth Haas and Yulia Hristova and Beth
  Novick and Brett Werner","Reconfiguration graphs of shortest paths","16 pages, 6 figures",,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For a graph $G$ and $a,b\in V(G)$, the shortest path reconfiguration graph of
$G$ with respect to $a$ and $b$ is denoted by $S(G,a,b)$. The vertex set of
$S(G,a,b)$ is the set of all shortest paths between $a$ and $b$ in $G$. Two
vertices in $V(S(G,a,b))$ are adjacent, if their corresponding paths in $G$
differ by exactly one vertex. This paper examines the properties of shortest
path graphs. Results include establishing classes of graphs that appear as
shortest path graphs, decompositions and sums involving shortest path graphs,
and the complete classification of shortest path graphs with girth $5$ or
greater. We also show that the shortest path graph of a grid graph is an
induced subgraph of a lattice.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 22:54:15 GMT""}]","2017-05-29"
"1705.09386","H\'elder Lima","H\'elder Lima","On M\""untz-type formulas related to the Riemann zeta function","18 pages",,,,"math.CA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Mellin transform and several Dirichlet series related with the Riemann
zeta function are used to deduce some identities similar to the classical
M\""untz formula [4]. These formulas are derived in the critical strip and in
the half-plane $Re(s)<0$. As particular cases, integral representations for
products of the gamma and zeta functions are exhibited.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 22:59:10 GMT""}]","2017-05-29"
"1705.09391","Panagiotis Mandros","Panagiotis Mandros, Mario Boley, Jilles Vreeken","Discovering Reliable Approximate Functional Dependencies","Accepted: In Proceedings of the ACM SIGKDD Conference on Knowledge
  Discovery and Data Mining (KDD), August 13-17, 2017, Halifax, NS, Canada",,"10.1145/3097983.3098062",,"cs.DB cs.AI cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Given a database and a target attribute of interest, how can we tell whether
there exists a functional, or approximately functional dependence of the target
on any set of other attributes in the data? How can we reliably, without bias
to sample size or dimensionality, measure the strength of such a dependence?
And, how can we efficiently discover the optimal or $\alpha$-approximate
top-$k$ dependencies? These are exactly the questions we answer in this paper.
  As we want to be agnostic on the form of the dependence, we adopt an
information-theoretic approach, and construct a reliable, bias correcting score
that can be efficiently computed. Moreover, we give an effective optimistic
estimator of this score, by which for the first time we can mine the
approximate functional dependencies from data with guarantees of optimality.
Empirical evaluation shows that the derived score achieves a good bias for
variance trade-off, can be used within an efficient discovery algorithm, and
indeed discovers meaningful dependencies. Most important, it remains reliable
in the face of data sparsity.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 23:00:46 GMT""},{""version"":""v2"",""created"":""Sun, 18 Jun 2017 18:18:55 GMT""}]","2017-06-20"
"1705.09392","Tomislav Plesa Mr","Tomislav Plesa, Konstantinos C. Zygalakis, David F. Anderson, Radek
  Erban","Noise Control for DNA Computing",,,,,"q-bio.MN","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Synthetic biology is a growing interdisciplinary field, with far-reaching
applications, which aims to design biochemical systems that behave in a desired
manner. With the advancement of strand-displacement DNA computing, a large
class of abstract biochemical networks may be physically realized using DNA
molecules. Methods for systematic design of the abstract systems with
prescribed behaviors have been predominantly developed at the (less-detailed)
deterministic level. However, stochastic effects, neglected at the
deterministic level, are increasingly found to play an important role in
biochemistry. In such circumstances, methods for controlling the intrinsic
noise in the system are necessary for a successful network design at the
(more-detailed) stochastic level. To bridge the gap, the noise-control
algorithm for designing biochemical networks is developed in this paper. The
algorithm structurally modifies any given reaction network under mass-action
kinetics, in such a way that (i) controllable state-dependent noise is
introduced into the stochastic dynamics, while (ii) the deterministic dynamics
are preserved. The capabilities of the algorithm are demonstrated on a
production-decay reaction system, and on an exotic system displaying
bistability. For the production-decay system, it is shown that the algorithm
may be used to redesign the network to achieve noise-induced multistability.
For the exotic system, the algorithm is used to redesign the network to control
the stochastic switching, and achieve noise-induced oscillations.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 23:01:46 GMT""},{""version"":""v2"",""created"":""Mon, 29 May 2017 12:29:30 GMT""},{""version"":""v3"",""created"":""Sat, 3 Jun 2017 00:15:15 GMT""},{""version"":""v4"",""created"":""Sat, 17 Jun 2017 19:28:44 GMT""},{""version"":""v5"",""created"":""Tue, 20 Jun 2017 16:40:08 GMT""}]","2017-06-21"
"1705.09395","John Jakeman","Scott N. Walsh, Tim M. Wildey, John D. Jakeman","Optimal Experimental Design Using A Consistent Bayesian Approach",,,"10.1115/1.4037457",,"stat.CO math.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the utilization of a computational model to guide the optimal
acquisition of experimental data to inform the stochastic description of model
input parameters. Our formulation is based on the recently developed consistent
Bayesian approach for solving stochastic inverse problems which seeks a
posterior probability density that is consistent with the model and the data in
the sense that the push-forward of the posterior (through the computational
model) matches the observed density on the observations almost everywhere.
Given a set a potential observations, our optimal experimental design (OED)
seeks the observation, or set of observations, that maximizes the expected
information gain from the prior probability density on the model parameters. We
discuss the characterization of the space of observed densities and a
computationally efficient approach for rescaling observed densities to satisfy
the fundamental assumptions of the consistent Bayesian approach. Numerical
results are presented to compare our approach with existing OED methodologies
using the classical/statistical Bayesian approach and to demonstrate our OED on
a set of representative PDE-based models.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 23:24:11 GMT""}]","2021-05-04"
"1705.09396","Nan Ye","Nan Ye and Peter Bartlett","Approximate and Stochastic Greedy Optimization","15 pages",,,,"math.OC cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider two greedy algorithms for minimizing a convex function in a
bounded convex set: an algorithm by Jones [1992] and the Frank-Wolfe (FW)
algorithm. We first consider approximate versions of these algorithms. For
smooth convex functions, we give sufficient conditions for convergence, a
unified analysis for the well-known convergence rate of O(1/k) together with a
result showing that this rate is the best obtainable from the proof technique,
and an equivalence result for the two algorithms. We also consider approximate
stochastic greedy algorithms for minimizing expectations. We show that
replacing the full gradient by a single stochastic gradient can fail even on
smooth convex functions. We give a convergent approximate stochastic Jones
algorithm and a convergent approximate stochastic FW algorithm for smooth
convex functions. In addition, we give a convergent approximate stochastic FW
algorithm for nonsmooth convex functions. Convergence rates for these
algorithms are given and proved.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 23:24:21 GMT""}]","2018-11-19"
"1705.09397","Kunari Haris","K Haris and A Kramida","Radiative rates of transitions from the 2s2p$^{3}$ $^{5}$S{\deg}$_{2}$
  level of neutral carbon","7 pages, 2 figures and a table","Journal of Physics Communications, 2017","10.1088/2399-6528/aa8dac",,"physics.atom-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The measured radiative rates of the 2s22p2 3P1,2 - 2s2p3 5S{\deg}2
intercombination transitions in neutral carbon reported in the literature are
critically evaluated by comparing them with theoretical and semi-empirical
results. The experimental and theoretical values are compared for the carbon
isoelectronic sequence from neutral carbon to nine-times ionized phosphorous.
We find strong support for the currently recommended theoretical data on C I
and conclude that the published measurements for this transition in neutral
carbon cannot be trusted. The reasons for the discrepancies are not clear, and
new experiments are needed.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 23:52:05 GMT""},{""version"":""v2"",""created"":""Thu, 20 Dec 2018 11:13:08 GMT""}]","2018-12-21"
"1705.09398","Jerzy Szulga Dr.","Jerzy Szulga","On signed generators of groups and algebras",,,,,"math.RA math.OA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Operators acting on the discrete random chaos yield signed multiplicative
systems, extending the notion of spin matrices and quaternions. We investigate
signed groups through the associated sign matrices, focusing on generators and
their replacements. Of particular interest are anticommutative generators
leading to a complete classification of the generated groups. The
classification of finite groups of mixed commutativity is also obtained.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 23:55:10 GMT""}]","2017-05-29"
"1705.09399","Cong Xiao","Cong Xiao","Semiclassical Boltzmann theory of spin Hall effects in giant Rashba
  systems","6 pages, 1 figure, some more discussions added in this version,
  accepted by Frontiers of Physics","Front. Phys. 13(2), 137202 (2018)","10.1007/s11467-017-0720-8",,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For the spin Hall effect arising from strong band-structure spin-orbit
coupling, a semiclassical Boltzmann theory reasonably addressing the intriguing
disorder effect called side-jump is still absent. In this paper we describe
such a theory of which the key ingredient is the spin-current-counterpart of
the semiclassical side-jump velocity (introduced in the context of the
anomalous Hall effect). Applying this theory to spin Hall effects in a
two-dimensional electron gas with giant Rashba spin-orbit coupling, we find
largely enhanced spin Hall angle in the presence of magnetic impurities when
only the lower Rashba band is partially occupied.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 23:55:41 GMT""},{""version"":""v2"",""created"":""Tue, 6 Jun 2017 08:17:50 GMT""},{""version"":""v3"",""created"":""Fri, 21 Jul 2017 21:56:15 GMT""}]","2017-09-27"
"1705.09400","Weiwei Wan","Weiwei Wan and Kensuke Harada","Regrasp Planning using 10,000s of Grasps",,,,,"cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper develops intelligent algorithms for robots to reorient objects.
Given the initial and goal poses of an object, the proposed algorithms plan a
sequence of robot poses and grasp configurations that reorient the object from
its initial pose to the goal. While the topic has been studied extensively in
previous work, this paper makes important improvements in grasp planning by
using over-segmented meshes, in data storage by using relational database, and
in regrasp planning by mixing real-world roadmaps. The improvements enable
robots to do robust regrasp planning using 10,000s of grasps and their
relationships in interactive time. The proposed algorithms are validated using
various objects and robots.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 00:13:33 GMT""}]","2017-05-29"
"1705.09401","Z Yan","Zichao Wen and Zhenya Yan","Solitons and their stability in the nonlocal nonlinear Schroedinger
  equation with PT-symmetric potentials","11 pages, 5 figures","Chaos 27 (2017) 053105","10.1063/1.4982972",,"nlin.PS math-ph math.MP nlin.SI quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We report localized nonlinear modes of the self-focusing and defocusing
nonlocal nonlinear Schroedinger equation with the generalized PT-symmetric
Scarf-II, Rosen-Morse, and periodic potentials. Parameter regions are presented
for broken and unbroken PT-symmetric phases of linear bounded states and the
linear stability of the obtained solitons. Moreover, we numerically explore the
dynamical behaviors of solitons and find stable solitons for some given
parameters.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 00:20:47 GMT""}]","2017-05-31"
"1705.09402","Andrew Adamatzky","Andrew Adamatzky","On dynamics of excitation in F-actin: automaton model",,,,,"cs.ET","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We represent a filamentous actin molecule as a graph of finite-state machines
(F-actin automaton). Each node in the graph takes three states --- resting,
excited, refractory. All nodes update their states simultaneously and by the
same rule, in discrete time steps. Two rules are considered: threshold rule ---
a resting node is excited if it has at least one excited neighbour and narrow
excitation interval rule --- a resting node is excited if it has exactly one
excited neighbour. We analyse distributions of transient periods and lengths of
limit cycles in evolution of F-actin automaton, propose mechanisms for
formation of limit cycles and evaluate density of information storage in
F-actin automata.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 00:36:28 GMT""}]","2017-05-29"
"1705.09403","Gorazd Cvetic","Gorazd Cvetic and C.S. Kim","Sensitivity limits on heavy-light mixing $|U_{\mu N}|^2$ from lepton
  number violating $B$ meson decays","revtex, 20 pages, 6 figures; v4: typos in Eqs.(10), (11) and (17b)
  corrected; the correct expressions had been used in calculations, results
  unchanged","Phys. Rev. D 96, 035025 (2017)","10.1103/PhysRevD.96.035025","USM-TH-352","hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the lepton number violating decays $B \to \mu^{\pm} \mu^{\pm}
\pi^{\mp}$ and $B \to D^{(*)} \mu^{\pm} \mu^{\pm} \pi^{\mp}$ which may be
detected at LHCb and Belle-II experiments; and $B \to \mu^{\pm} \mu^{\pm}
e^{\mp} \nu$ and $B \to D^{(*)} \mu^{\pm} \mu^{\pm} e^{\mp} \nu$ decays which
may be detected at Belle-II experiment. The projected total number of produced
$B$ mesons is $4.8 \times 10^{12}$ at LHCb upgrade and $5 \times 10^{10}$ at
Belle-II. For the case that the above decays are not detected, we deduce the
new upper bounds (sensitivity limits) for the mixing parameter $|U_{\mu N}|^2$
of heavy sterile neutrino with sub-eV light neutrino, as a function of the
sterile neutrino mass in the interval $1.75 \ {\rm GeV} < M_N < 5.0 \ {\rm
GeV}$. We take into account the probability of decay of the sterile neutrino
$N$ within the detector, taking as the effective detector length $L=2.3 \ m$ at
LCHb upgrade and $L=1 \ m$ at Belle-II. In the interval $1.75 \ {\rm GeV} < M_N
< 3 \ {\rm GeV}$, the most stringent bounds can be obtained with the decays $B
\to \mu^{\pm} \mu^{\pm} \pi^{\mp}$ at LHCb upgrade. The sensitivity limits are
expected to be in general more stringent at LHCb upgrade than at Belle-II,
principally because the number of produced $B$ mesons in LHCb upgrade is
expected to be by about two orders of magnitude larger than at Belle-II. We
conclude that the LHCb upgrade and Belle-II experiments have the potential to
either find a new heavy Majorana neutrino $N$, or to improve significantly the
sensitivity limits (upper bounds) on the heavy-light mixing parameter $|U_{\mu
N}|^2$, particularly in the mass range $1.75 \ {\rm GeV} < M_N < 3 \ {\rm
GeV}$. This work is a continuation and refinement of our previous work [1] on
the subject.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 00:41:08 GMT""},{""version"":""v2"",""created"":""Thu, 1 Jun 2017 17:46:28 GMT""},{""version"":""v3"",""created"":""Thu, 22 Jun 2017 16:25:38 GMT""},{""version"":""v4"",""created"":""Sat, 11 Jul 2020 20:30:41 GMT""}]","2020-07-14"
"1705.09404","Emanuel Onica","Emanuel Onica, Pascal Felber, Hugues Mercier, Etienne Rivi\`ere","Confidentiality-Preserving Publish/Subscribe: A Survey",,"ACM Computing Surveys, Volume 49, Issue 2, November 2016","10.1145/2940296",,"cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Publish/subscribe (pub/sub) is an attractive communication paradigm for
large-scale distributed applications running across multiple administrative
domains. Pub/sub allows event-based information dissemination based on
constraints on the nature of the data rather than on pre-established
communication channels. It is a natural fit for deployment in untrusted
environments such as public clouds linking applications across multiple sites.
However, pub/sub in untrusted environments lead to major confidentiality
concerns stemming from the content-centric nature of the communications. This
survey classifies and analyzes different approaches to confidentiality
preservation for pub/sub, from applications of trust and access control models
to novel encryption techniques. It provides an overview of the current
challenges posed by confidentiality concerns and points to future research
directions in this promising field.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 01:01:49 GMT""}]","2017-05-29"
"1705.09405","Oscar Peralta","Oscar Peralta, Leonardo Rojas-Nandayapa, Wangyue Xie and Hui Yao","Approximation of Ruin Probabilities via Erlangized Scale Mixtures",,,,,"math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we extend an existing scheme for numerically calculating the
probability of ruin of a classical Cram\'er--Lundberg reserve process having
absolutely continuous but otherwise general claim size distributions. We employ
a dense class of distributions that we denominate Erlangized scale mixtures
(ESM) and correspond to nonnegative and absolutely continuous distributions
which can be written as a Mellin--Stieltjes convolution $\Pi\star G$ of a
nonnegative distribution $\Pi$ with an Erlang distribution $G$. A distinctive
feature of such a class is that it contains heavy-tailed distributions.
  We suggest a simple methodology for constructing a sequence of distributions
having the form $\Pi\star G$ to approximate the integrated tail distribution of
the claim sizes. Then we adapt a recent result which delivers an explicit
expression for the probability of ruin in the case that the claim size
distribution is modelled as an Erlangized scale mixture. We provide simplified
expressions for the approximation of the probability of ruin and construct
explicit bounds for the error of approximation. We complement our results with
a classical example where the claim sizes are heavy-tailed.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 01:22:48 GMT""}]","2017-05-29"
"1705.09406","Tadas Baltrusaitis","Tadas Baltru\v{s}aitis, Chaitanya Ahuja, Louis-Philippe Morency","Multimodal Machine Learning: A Survey and Taxonomy",,,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Our experience of the world is multimodal - we see objects, hear sounds, feel
texture, smell odors, and taste flavors. Modality refers to the way in which
something happens or is experienced and a research problem is characterized as
multimodal when it includes multiple such modalities. In order for Artificial
Intelligence to make progress in understanding the world around us, it needs to
be able to interpret such multimodal signals together. Multimodal machine
learning aims to build models that can process and relate information from
multiple modalities. It is a vibrant multi-disciplinary field of increasing
importance and with extraordinary potential. Instead of focusing on specific
multimodal applications, this paper surveys the recent advances in multimodal
machine learning itself and presents them in a common taxonomy. We go beyond
the typical early and late fusion categorization and identify broader
challenges that are faced by multimodal machine learning, namely:
representation, translation, alignment, fusion, and co-learning. This new
taxonomy will enable researchers to better understand the state of the field
and identify directions for future research.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 01:35:31 GMT""},{""version"":""v2"",""created"":""Tue, 1 Aug 2017 17:39:39 GMT""}]","2017-08-02"
"1705.09407","Giuseppe Nuti","Giuseppe Nuti","An Efficient Algorithm for Bayesian Nearest Neighbours",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  K-Nearest Neighbours (k-NN) is a popular classification and regression
algorithm, yet one of its main limitations is the difficulty in choosing the
number of neighbours. We present a Bayesian algorithm to compute the posterior
probability distribution for k given a target point within a data-set,
efficiently and without the use of Markov Chain Monte Carlo (MCMC) methods or
simulation - alongside an exact solution for distributions within the
exponential family. The central idea is that data points around our target are
generated by the same probability distribution, extending outwards over the
appropriate, though unknown, number of neighbours. Once the data is projected
onto a distance metric of choice, we can transform the choice of k into a
change-point detection problem, for which there is an efficient solution: we
recursively compute the probability of the last change-point as we move towards
our target, and thus de facto compute the posterior probability distribution
over k. Applying this approach to both a classification and a regression UCI
data-sets, we compare favourably and, most importantly, by removing the need
for simulation, we are able to compute the posterior probability of k exactly
and rapidly. As an example, the computational time for the Ripley data-set is a
few milliseconds compared to a few hours when using a MCMC approach.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 01:36:15 GMT""},{""version"":""v2"",""created"":""Fri, 2 Jun 2017 02:29:13 GMT""}]","2017-06-05"
"1705.09408","Carlos Eduardo Fontoura","C.E. Fontoura, J. Haidenbauer and G. Krein","SU(4) flavor symmetry breaking in D-meson couplings to light hadrons","5 pages, 3 figures","Eur. Phys. J. A (2017) 53: 92","10.1140/epja/i2017-12289-2",,"nucl-th hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The validity of SU(4)-flavor symmetry relations of couplings of charmed $D$
mesons to light mesons and baryons is examined with the use of $^3{\rm P}_0$
quark-pair creation model and nonrelativistic quark model wave functions. We
focus on the three-meson couplings $\pi\pi\rho$, $KK\rho$ and $DD\rho$ and
baryon-baryon-meson couplings $NN\pi$, $N\Lambda K$ and $N\Lambda_c D$. It is
found that SU(4)-flavor symmetry is broken at the level of 30% in the $DD\rho$
tree-meson couplings and 20% in the baryon-baryon-meson couplings. Consequences
of these findings for DN cross sections and existence of bound states D-mesons
in nuclei are discussed.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 01:40:26 GMT""}]","2017-05-29"
"1705.09409","Yuji Hirono","Yuji Hirono","Chiral magnetohydrodynamics for heavy-ion collisions","8 pages, 5 figures, Proceedings of the XXVIth International
  Conference on Ultrarelativistic Nucleus-Nucleus Collisions (Quark Matter
  2017) Chicago, February 6-11, 2017",,"10.1016/j.nuclphysa.2017.06.013",,"hep-ph nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The chiral magnetic effect (CME) is a macroscopic transport effect resulting
from the chiral anomaly. We review the recent progress in theoretical
understanding the properties of chiral plasmas, in which the CME and other
anomaly-induced transports take place. In particular, the nontrivial interplay
of anomalous currents and dynamical electromagnetic fields is discussed. We
also review the theoretical status of the modeling of anomalous transport
effects in heavy-ion collisions.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 01:42:13 GMT""}]","2018-03-14"
"1705.09410","Qing Zhang","Qing Zhang","A local converse theorem for $\textrm{U}_{2r+1}$","Accepted for publication in Transaction of the AMS",,,,"math.RT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $E/F$ be a quadratic extension of $p$-adic fields and $\textrm{U}_{2r+1}$
be the unitary group associated with $E/F$. We prove the following local
converse theorem for $\textrm{U}_{2r+1}$: given two irreducible generic
supercuspidal representations $\pi,\pi_0$ of $\textrm{U}_{2r+1}$ with the same
central character, if $\gamma(s,\pi\times \tau,\psi)=\gamma(s,\pi_0\times
\tau,\psi)$ for all irreducible generic representation $\tau$ of
$\textrm{GL}_n(E)$ and for all $n$ with $1\le n\le r$, then $\pi\cong \pi_0$.
The proof depends on analysis of the local integrals which define local gamma
factors and uses certain properties of partial Bessel functions developed by
Cogdell-Shahidi-Tsai recently.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 02:00:21 GMT""},{""version"":""v2"",""created"":""Mon, 20 Nov 2017 03:27:09 GMT""}]","2017-11-21"
"1705.09411","Hehong Zhang","Hehong Zhang, Chao Zhai, Gaoxi Xiao, Tso-Chien Pan","Identifying Critical Risks of Cascading Failures in Power Systems","22 pages, 4 figures",,,,"cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Potential critical risks of cascading failures in power systems can be
identified by exposing those critical electrical elements on which certain
initial disturbances may cause maximum disruption to power transmission
networks. In this work, we investigate cascading failures in power systems
described by the direct current (DC) power flow equations, while initial
disturbances take the form of altering admittance of elements. The disruption
is quantified with the remaining transmission power at the end of cascading
process. In particular, identifying the critical elements and the corresponding
initial disturbances causing the worst-case cascading blackout is formulated as
a dynamic optimization problem (DOP) in the framework of optimal control
theory, where the entire propagation process of cascading failures is put under
consideration. An Identifying Critical Risk Algorithm (ICRA) based on the
maximum principle is proposed to solve the DOP. Simulation results on the IEEE
9-Bus and the IEEE 14-Bus test systems are presented to demonstrate the
effectiveness of the algorithm.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 02:02:13 GMT""}]","2017-05-29"
"1705.09412","Haoran Sun","Haoran Sun, Xiangyi Chen, Qingjiang Shi, Mingyi Hong, Xiao Fu,
  Nicholas D. Sidiropoulos","Learning to Optimize: Training Deep Neural Networks for Wireless
  Resource Management","Submitted to TSP","IEEE Transactions on Signal Processing, vol. 66, no. 20, pp.
  5438-5453, 15 Oct.15, 2018","10.1109/TSP.2018.2866382",,"cs.IT eess.SP math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For the past couple of decades, numerical optimization has played a central
role in addressing wireless resource management problems such as power control
and beamformer design. However, optimization algorithms often entail
considerable complexity, which creates a serious gap between theoretical
design/analysis and real-time processing. To address this challenge, we propose
a new learning-based approach. The key idea is to treat the input and output of
a resource allocation algorithm as an unknown non-linear mapping and use a deep
neural network (DNN) to approximate it. If the non-linear mapping can be
learned accurately by a DNN of moderate size, then resource allocation can be
done in almost real time -- since passing the input through a DNN only requires
a small number of simple operations.
  In this work, we address both the thereotical and practical aspects of
DNN-based algorithm approximation with applications to wireless resource
management. We first pin down a class of optimization algorithms that are
`learnable' in theory by a fully connected DNN. Then, we focus on DNN-based
approximation to a popular power allocation algorithm named WMMSE (Shi {\it et
al} 2011). We show that using a DNN to approximate WMMSE can be fairly accurate
-- the approximation error $\epsilon$ depends mildly [in the order of
$\log(1/\epsilon)$] on the numbers of neurons and layers of the DNN. On the
implementation side, we use extensive numerical simulations to demonstrate that
DNNs can achieve orders of magnitude speedup in computational time compared to
state-of-the-art power allocation algorithms based on optimization.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 02:21:52 GMT""},{""version"":""v2"",""created"":""Wed, 25 Oct 2017 19:22:38 GMT""}]","2018-09-18"
"1705.09413","David Bau iii","David Bau, Jeff Gray, Caitlin Kelleher, Josh Sheldon, Franklyn Turbak","Learnable Programming: Blocks and Beyond",,"Communications of the ACM, June 2017, pp. 72-80","10.1145/3015455",,"cs.PL cs.CY cs.HC cs.SE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Blocks-based programming has become the lingua franca for introductory
coding. Studies have found that experience with blocks-based programming can
help beginners learn more traditional text-based languages. We explore how
blocks environments improve learnability for novices by 1) favoring recognition
over recall, 2) reducing cognitive load, and 3) preventing errors. Increased
usability of blocks programming has led to widespread adoption within
introductory programming contexts across a range of ages. Ongoing work explores
further reducing barriers to programming, supporting novice programmers in
expanding their programming skills, and transitioning to textual programming.
New blocks frameworks are making it easier to access a variety of APIs through
blocks environments, opening the doors to a greater diversity of programming
domains and supporting greater experimentation for novices and professionals
alike.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 02:25:19 GMT""}]","2018-06-27"
"1705.09414","Javier Monta\~no Dom\'inguez","E. C. F. S. Fortes, A. C. B. Machado, J. Monta\~no, V. Pleitez","Lepton masses and mixing in a scotogenic model","13 pages, 5 figures",,"10.1016/j.physletb.2020.135289",,"hep-ph","http://creativecommons.org/publicdomain/zero/1.0/","  We consider an extension of the standard model with three Higgs doublet model
and $S_3\times \mathbb{Z}_2$ discrete symmetries. Two of the scalar doublets
are inert due to the $\mathbb{Z}_2$ symmetry. We have calculated all the mass
spectra in the scalar and lepton sectors and accommodated the leptonic mixing
matrix as well. We also show that the model has scalar and pseudoscalar
candidates to dark matter. Constraints on the parameters of the model coming
from the decay $\mu\to e\gamma$ were considered and we found signals between
the current and the upcoming experimental limits, and from that decay we can
predict the one-loop $\mu\to ee\bar{e}$ channel.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 02:31:42 GMT""}]","2020-02-19"
"1705.09415","Mohammadhussein Rafieisakhaei","Mohammadhussein Rafieisakhaei, Suman Chakravorty and P. R. Kumar","Near-Optimal Belief Space Planning via T-LQG","3 pages, 3 figures, In Robotics: Science and Systems (RSS) 2017
  Workshop of ""POMDPs in Robotics: State of The Art, Challenges, and
  Opportunities""",,,,"cs.RO cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the problem of planning under observation and motion uncertainty
for nonlinear robotics systems. Determining the optimal solution to this
problem, generally formulated as a Partially Observed Markov Decision Process
(POMDP), is computationally intractable. We propose a Trajectory-optimized
Linear Quadratic Gaussian (T-LQG) approach that leads to quantifiably
near-optimal solutions for the POMDP problem. We provide a novel ""separation
principle"" for the design of an optimal nominal open-loop trajectory followed
by an optimal feedback control law, which provides a near-optimal feedback
control policy for belief space planning problems involving a polynomial order
of calculations of minimum order.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 02:31:44 GMT""},{""version"":""v2"",""created"":""Mon, 10 Jul 2017 10:12:30 GMT""}]","2017-07-11"
"1705.09416","Huahui Liu","Huahui Liu, Mingrui Zhu, Xiaonan Meng, Yi Hu and Hao Wang","Dual Based DSP Bidding Strategy and its Application",,,,,"stat.ML cs.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In recent years, RTB(Real Time Bidding) becomes a popular online
advertisement trading method. During the auction, each DSP(Demand Side
Platform) is supposed to evaluate current opportunity and respond with an ad
and corresponding bid price. It's essential for DSP to find an optimal ad
selection and bid price determination strategy which maximizes revenue or
performance under budget and ROI(Return On Investment) constraints in P4P(Pay
For Performance) or P4U(Pay For Usage) mode. We solve this problem by 1)
formalizing the DSP problem as a constrained optimization problem, 2) proposing
the augmented MMKP(Multi-choice Multi-dimensional Knapsack Problem) with
general solution, 3) and demonstrating the DSP problem is a special case of the
augmented MMKP and deriving specialized strategy. Our strategy is verified
through simulation and outperforms state-of-the-art strategies in real
application. To the best of our knowledge, our solution is the first dual based
DSP bidding framework that is derived from strict second price auction
assumption and generally applicable to the multiple ads scenario with various
objectives and constraints.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 02:43:08 GMT""},{""version"":""v2"",""created"":""Wed, 27 Dec 2017 11:10:13 GMT""}]","2017-12-29"
"1705.09417","Amit Meir","Amit Meir and Mathias Drton","Tractable Post-Selection Maximum Likelihood Inference for the Lasso",,,,,"stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Applying standard statistical methods after model selection may yield
inefficient estimators and hypothesis tests that fail to achieve nominal type-I
error rates. The main issue is the fact that the post-selection distribution of
the data differs from the original distribution. In particular, the observed
data is constrained to lie in a subset of the original sample space that is
determined by the selected model. This often makes the post-selection
likelihood of the observed data intractable and maximum likelihood inference
difficult. In this work, we get around the intractable likelihood by generating
noisy unbiased estimates of the post-selection score function and using them in
a stochastic ascent algorithm that yields correct post-selection maximum
likelihood estimates. We apply the proposed technique to the problem of
estimating linear models selected by the lasso. In an asymptotic analysis the
resulting estimates are shown to be consistent for the selected parameters and
to have a limiting truncated normal distribution. Confidence intervals
constructed based on the asymptotic distribution obtain close to nominal
coverage rates in all simulation settings considered, and the point estimates
are shown to be superior to the lasso estimates when the true model is sparse.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 02:45:59 GMT""},{""version"":""v2"",""created"":""Wed, 22 May 2019 15:57:21 GMT""}]","2019-05-23"
"1705.09418","Jau-Er Chen","Yan-Yu Chiou, Mei-Yuan Chen, Jau-er Chen","Nonparametric Regression with Multiple Thresholds: Estimation and
  Inference",,,,,"q-fin.EC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper examines nonparametric regression with an exogenous threshold
variable, allowing for an unknown number of thresholds. Given the number of
thresholds and corresponding threshold values, we first establish the
asymptotic properties of the local constant estimator for a nonparametric
regression with multiple thresholds. However, the number of thresholds and
corresponding threshold values are typically unknown in practice. We then use
our testing procedure to determine the unknown number of thresholds and derive
the limiting distribution of the proposed test. The Monte Carlo simulation
results indicate the adequacy of the modified test and accuracy of the
sequential estimation of the threshold values. We apply our testing procedure
to an empirical study of the 401(k) retirement savings plan with income
thresholds.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 02:47:31 GMT""},{""version"":""v2"",""created"":""Fri, 23 Feb 2018 15:26:14 GMT""}]","2018-02-26"
"1705.09419","Peter Hannaford","Yibo Wang, Tien Tran, Prince Surendran, Ivan Herrera, Armandas
  Balcytis, Dennis Nissen, Manfred Albrecht, Andrei Sidorov, Peter Hannaford","Trapping ultracold atoms at 100 nm from a chip surface in a
  0.7-micrometer-period magnetic lattice","11 pages, 7 figures","Phys. Rev. A 96, 013630 (2017)","10.1103/PhysRevA.96.013630",,"physics.atom-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We report the trapping of ultracold 87Rb atoms in a 0.7 micron-period 2D
triangular magnetic lattice on an atom chip. The magnetic lattice is created by
a lithographically patterned magnetic Co/Pd multilayer film plus bias fields.
Rubidium atoms in the F=1, mF=-1 low-field seeking state are trapped at
estimated distances down to about 100 nm from the chip surface and with
calculated mean trapping frequencies as high as 800 kHz. The measured lifetimes
of the atoms trapped in the magnetic lattice are in the range 0.4 - 1.7 ms,
depending on distance from the chip surface. Model calculations suggest the
trap lifetimes are currently limited mainly by losses due to surface-induced
thermal evaporation following loading of the atoms from the Z-wire trap into
the very tight magnetic lattice traps, rather than by fundamental loss
processes such as surface interactions, three-body recombination or spin flips
due to Johnson magnetic noise. The trapping of atoms in a 0.7 micrometer-period
magnetic lattice represents a significant step towards using magnetic lattices
for quantum tunneling experiments and to simulate condensed matter and
many-body phenomena in nontrivial lattice geometries.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 03:04:24 GMT""},{""version"":""v2"",""created"":""Wed, 9 Aug 2017 05:37:48 GMT""}]","2017-08-16"
"1705.09420","Maur\'icio Corr\^ea","Maur\'icio Corr\^ea Jr and Tatsuo Suwa","Localization of Bott-Chern classes and Hermitian residues","28 pages, to appear in Journal of the London Mathematical Society",,"10.1112/jlms.12273",,"math.CV math.AG math.DG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We develop a theory of Cech-Bott-Chern cohomology and in this context we
naturally come up with the relative Bott-Chern cohomology. In fact Bott-Chern
cohomology has two relatives and they all arise from a single complex. Thus we
study these three cohomologies in a unified way and obtain a long exact
sequence involving the three. We then study the localization problem of
characteristic classes in the relative Bott-Chern cohomology. For this we
define the cup product and integration in our framework and we discuss local
and global duality homomorphisms. After reviewing some materials on
connections, we give a vanishing theorem relevant to our localization. With
these, we prove a residue theorem for a vector bundle admitting a Hermitian
connection compatible with an action of the non-singular part of a singular
distribution. As a typical case, we discuss the action of a distribution on the
normal bundle of an invariant submanifold (so-called the Camacho-Sad action)
and give a specific example.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 03:16:54 GMT""},{""version"":""v2"",""created"":""Thu, 15 Aug 2019 11:30:24 GMT""}]","2019-09-11"
"1705.09421","Neil J. Cornish","Travis Robson and Neil Cornish","Global analysis for the LISA gravitational wave observatory","24 pages, 10 figures","Class.Quant.Grav. 34 (2017) no.24, 244002","10.1088/1361-6382/aa9601",,"gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Laser Interferometer Space Antenna (LISA) will explore the source-rich
milli-Hertz band of the gravitational wave spectrum. In contrast to ground
based detectors, where typical signals are short-lived and discrete, LISA
signals are typically long-lived and over-lapping, thus requiring a global data
analysis solution that is very different to the source-by-source analysis that
has been developed for ground based gravitational wave astronomy. Across the
LISA band, gravitational waves are both signals {\em and} noise. The dominant
contribution to this so-called confusion noise (better termed unresolved signal
noise) is expected to come from short period galactic white dwarf binaries, but
all sources, including massive black hole binaries and extreme mass ratio
captures will also contribute. Previous estimates for the galactic confusion
noise have assumed perfect signal subtraction. Here we provide analytic
estimates for the signal subtraction residuals and the impact they have on
parameter estimation while for the first time incorporating the effects of
noise modeling. The analytic estimates are found using a maximum likelihood
approximation to the full global Bayesian analysis. We find that while the
confusion noise is {\em lowered} in the global analysis, the waveform errors
for individual sources are {\em increased} relative to estimates for isolated
signals. We provide estimates for how parameter estimation errors are inflated
from various parts of a global analysis.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 03:18:14 GMT""}]","2018-08-09"
"1705.09422","Amirsina Torfi","Amirsina Torfi, Jeremy Dawson, Nasser M. Nasrabadi","Text-Independent Speaker Verification Using 3D Convolutional Neural
  Networks","Accepted to be published in IEEE International Conference on
  Multimedia and Expo (ICME) 2018",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, a novel method using 3D Convolutional Neural Network (3D-CNN)
architecture has been proposed for speaker verification in the text-independent
setting. One of the main challenges is the creation of the speaker models. Most
of the previously-reported approaches create speaker models based on averaging
the extracted features from utterances of the speaker, which is known as the
d-vector system. In our paper, we propose an adaptive feature learning by
utilizing the 3D-CNNs for direct speaker model creation in which, for both
development and enrollment phases, an identical number of spoken utterances per
speaker is fed to the network for representing the speakers' utterances and
creation of the speaker model. This leads to simultaneously capturing the
speaker-related information and building a more robust system to cope with
within-speaker variation. We demonstrate that the proposed method significantly
outperforms the traditional d-vector verification system. Moreover, the
proposed system can also be an alternative to the traditional d-vector system
which is a one-shot speaker modeling system by utilizing 3D-CNNs.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 03:19:08 GMT""},{""version"":""v2"",""created"":""Wed, 9 Aug 2017 22:36:24 GMT""},{""version"":""v3"",""created"":""Thu, 17 Aug 2017 17:01:26 GMT""},{""version"":""v4"",""created"":""Mon, 6 Nov 2017 23:11:13 GMT""},{""version"":""v5"",""created"":""Sun, 4 Feb 2018 05:38:16 GMT""},{""version"":""v6"",""created"":""Thu, 29 Mar 2018 02:19:13 GMT""},{""version"":""v7"",""created"":""Wed, 6 Jun 2018 21:22:54 GMT""}]","2018-06-08"
"1705.09423","Ziyan Luo","Ziyan Luo, Yumeng Yang, Yanjun Xu, Mengzhen Zhang, Baoxi Xu, Jingsheng
  Chen, and Yihong Wu","Static and Dynamic Magnetic Properties of FeMn/Pt Multilayers","30 pages, 8 figures",,"10.1063/1.4985119",,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recently we have demonstrated the presence of spin-orbit toque in FeMn/Pt
multilayers which, in combination with the anisotropy field, is able to rotate
its magnetization consecutively from 0o to 360o without any external field.
Here, we report on an investigation of static and dynamic magnetic properties
of FeMn/Pt multilayers using combined techniques of magnetometry, ferromagnetic
resonance, inverse spin Hall effect and spin Hall magnetoresistance
measurements. The FeMn/Pt multilayer was found to exhibit ferromagnetic
properties, and its temperature dependence of saturation magnetization can be
fitted well using a phenomenological model by including a finite distribution
in Curie temperature due to subtle thickness variations across the multilayer
samples. The non-uniformity in static magnetic properties is also manifested in
the ferromagnetic resonance spectra, which typically exhibit a broad resonance
peak. A damping parameter of around 0.106 is derived from the frequency
dependence of ferromagnetic resonance linewidth, which is comparable to the
reported values for other types of Pt-based multilayers. Clear inverse spin
Hall signals and spin Hall magnetoresistance have been observed in all samples
below the Curie temperature, which corroborate the strong spin-orbit torque
effect observed previously.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 03:25:12 GMT""}]","2017-06-28"
"1705.09424","Chris Fraser","Chris Fraser, Thomas Lam, Ian Le","From dimers to webs","fixed typos in bibliography",,,,"math.CO math.RT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We formulate a higher-rank version of the boundary measurement map for
weighted planar bipartite networks in the disk. It sends a network to a linear
combination of SL$_r$-webs, and is built upon the r-fold dimer model on the
network. When r equals 1, our map is a reformulation of Postnikov's boundary
measurement used to coordinatize positroid strata. When r equals 2 or 3, it is
a reformulation of the SL$_2$- and SL$_3$-web immanants defined by the second
author. The basic result is that the higher rank map factors through
Postnikov's map. As an application, we deduce generators and relations for the
space of SL$_r$-webs, reproving a result of Cautis-Kamnitzer-Morrison. We
establish compatibility between our map and restriction to positroid strata,
and thus between webs and total positivity.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 03:36:32 GMT""},{""version"":""v2"",""created"":""Sun, 4 Jun 2017 18:50:59 GMT""}]","2017-06-06"
"1705.09425","Yao Qin","Yao Qin, Mengyang Feng, Huchuan Lu, Garrison W. Cottrell","Hierarchical Cellular Automata for Visual Saliency",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Saliency detection, finding the most important parts of an image, has become
increasingly popular in computer vision. In this paper, we introduce
Hierarchical Cellular Automata (HCA) -- a temporally evolving model to
intelligently detect salient objects. HCA consists of two main components:
Single-layer Cellular Automata (SCA) and Cuboid Cellular Automata (CCA). As an
unsupervised propagation mechanism, Single-layer Cellular Automata can exploit
the intrinsic relevance of similar regions through interactions with neighbors.
Low-level image features as well as high-level semantic information extracted
from deep neural networks are incorporated into the SCA to measure the
correlation between different image patches. With these hierarchical deep
features, an impact factor matrix and a coherence matrix are constructed to
balance the influences on each cell's next state. The saliency values of all
cells are iteratively updated according to a well-defined update rule.
Furthermore, we propose CCA to integrate multiple saliency maps generated by
SCA at different scales in a Bayesian framework. Therefore, single-layer
propagation and multi-layer integration are jointly modeled in our unified HCA.
Surprisingly, we find that the SCA can improve all existing methods that we
applied it to, resulting in a similar precision level regardless of the
original results. The CCA can act as an efficient pixel-wise aggregation
algorithm that can integrate state-of-the-art methods, resulting in even better
results. Extensive experiments on four challenging datasets demonstrate that
the proposed algorithm outperforms state-of-the-art conventional methods and is
competitive with deep learning based approaches.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 03:43:16 GMT""}]","2017-05-29"
"1705.09426","Esteban Vargas Bernal","Camilo Sanabria Malagon and Esteban Vargas Bernal","Competent hosts and endemicity of multi-host diseases",,,,,"q-bio.PE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we propose a method to study a general vector-hosts
mathematical model in order to explain how the changes in biodiversity could
influence the dynamics of vector-borne diseases. We find that under the
assumption of frequency-dependent transmission, i.e. the assumption that the
number of contacts are diluted by the total population of hosts, the presence
of a competent host is a necessary condition for the existence of an endemic
state. In addition, we obtain that in the case of an endemic disease with a
unique competent and resilient host, an increase in its density amplifies the
disease.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 03:59:57 GMT""},{""version"":""v2"",""created"":""Tue, 27 Nov 2018 05:52:43 GMT""}]","2018-11-28"
"1705.09427","Yuliang Li","Yuliang Li, Alin Deutsch, and Victor Vianu","SpinArt: A Spin-based Verifier for Artifact Systems",,,,,"cs.DB cs.FL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Data-driven workflows, of which IBM's Business Artifacts are a prime
exponent, have been successfully deployed in practice, adopted in industrial
standards, and have spawned a rich body of research in academia, focused
primarily on static analysis. In previous work, we obtained theoretical results
on the verification of a rich model incorporating core elements of IBM's
successful Guard-Stage-Milestone (GSM) artifact model. The results showed
decidability of verification of temporal properties of a large class of GSM
workflows and established its complexity. Following up on these results, the
present paper reports on the implementation of SpinArt, a practical verifier
based on the classical model-checking tool Spin. The implementation includes
nontrivial optimizations and achieves good performance on real-world business
process examples. Our results shed light on the capabilities and limitations of
off-the-shelf verifiers in the context of data-driven workflows.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 04:13:17 GMT""},{""version"":""v2"",""created"":""Thu, 28 Sep 2017 17:35:37 GMT""},{""version"":""v3"",""created"":""Mon, 19 Mar 2018 23:21:27 GMT""}]","2018-03-21"
"1705.09428","Nishad Kothari","Cl\'audio L. Lucchesi, Marcelo H. de Carvalho, Nishad Kothari, U. S.
  R. Murty","On Two Unsolved Problems Concerning Matching Covered Graphs","Dedicated to the memory of Professor W. T. Tutte on the occasion of
  the centennial of his birth",,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A cut $C:=\partial(X)$ of a matching covered graph $G$ is a separating cut if
both its $C$-contractions $G/X$ and $G/\overline{X}$ are also matching covered.
A brick is solid if it is free of nontrivial separating cuts. In 2004, we
(Carvalho, Lucchesi and Murty) showed that the perfect matching polytope of a
brick may be described without recourse to odd set constraints if and only if
it is solid. In 2006, we proved that the only simple planar solid bricks are
the odd wheels. The problem of characterizing nonplanar solid bricks remains
unsolved.
  A bi-subdivision of a graph $J$ is a graph obtained from $J$ by replacing
each of its edges by paths of odd length. A matching covered graph $J$ is a
conformal minor of a matching covered graph $G$ if there exists a
bi-subdivision $H$ of $J$ which is a subgraph of $G$ such that $G-V(H)$ has a
perfect matching. For a fixed matching covered graph $J$, a matching covered
graph $G$ is $J$-based if $J$ is a conformal minor of $G$ and, otherwise, $G$
is $J$-free. A basic result due to Lov\'asz (1983) states that every
nonbipartite matching covered graph is either $K_4$-based or is
$\overline{C_6}$-based or both, where $\overline{C_6}$ is the triangular prism.
In 2016, we (Kothari and Murty) showed that, for any cubic brick $J$, a
matching covered graph $G$ is $J$-free if and only if each of its bricks is
$J$-free. We also found characterizations of planar bricks which are $K_4$-free
and those which are $\overline{C_6}$-free. Each of these problems remains
unsolved in the nonplanar case.
  In this paper we show that the seemingly unrelated problems of characterizing
nonplanar solid bricks and of characterizing nonplanar $\overline{C_6}$-free
bricks are essentially the same. We do this by establishing that a simple
nonplanar brick, other than the Petersen graph, is solid if and only if it is
$\overline{C_6}$-free.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 04:22:52 GMT""}]","2017-05-29"
"1705.09429","Jae-Won Kim","Jae-Won Kim and Jong-Seon No","Equivalences Between Network Codes With Link Errors and Index Codes With
  Side Information Errors",,,"10.1109/ACCESS.2019.2912990",,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, new equivalence relationships between a network code with link
errors (NCLE) and an index code with side information errors (ICSIE) are
studied. First, for a given network coding instance, the equivalent index
coding instance is derived, where an NCLE is converted to the corresponding
ICSIE and vice versa. Next, for a given index coding instance, the equivalent
network coding instance is also derived, where an ICSIE is converted to the
corresponding NCLE and vice versa if a pair of encoding functions of an
original link and the duplicated link are functionally related in the network
code. Finally, several properties of an NCLE are derived from those of the
equivalent ICSIE using the fact that the NCLE and the ICSIE are equivalent.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 04:29:44 GMT""}]","2019-09-19"
"1705.09430","Insun Jo","Insun Jo, M. A. Mueed, L. N. Pfeiffer, K. W. West, K. W. Baldwin, R.
  Winkler, Medini Padmanabhan, and M. Shayegan","Tuning of Fermi Contour Anisotropy in GaAs (001) 2D Holes via Strain","Accepted to Applied Physics Letters","Appl. Phys. Lett. 110, 252103 (2017)","10.1063/1.4984954",,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We demonstrate tuning of the Fermi contour anisotropy of two-dimensional (2D)
holes in a symmetric GaAs (001) quantum well via the application of in-plane
strain. The ballistic transport of high-mobility hole carriers allows us to
measure the Fermi wavevector of 2D holes via commensurability oscillations as a
function of strain. Our results show that a small amount of in-plane strain, on
the order of $10^{-4}$, can induce significant Fermi wavevector anisotropy as
large as 3.3, equivalent to a mass anisotropy of 11 in a parabolic band. Our
method to tune the anisotropy \textit{in situ} provides a platform to study the
role of anisotropy on phenomena such as the fractional quantum Hall effect and
composite fermions in interacting 2D systems.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 04:40:01 GMT""}]","2017-07-10"
"1705.09431","Shravan Hanasoge","Shravan M. Hanasoge","Seismic sensitivity of Normal-mode Coupling to Lorentz stresses in the
  Sun","18 pages, 4 figures; MNRAS",,"10.1093/mnras/stx1342",,"astro-ph.SR physics.geo-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Understanding the governing mechanism of solar magnetism remains an
outstanding challenge in astrophysics. Seismology is the most compelling
technique with which to infer the internal properties of the Sun and stars.
Waves in the Sun, nominally acoustic, are sensitive to the emergence and
cyclical strengthening of magnetic field, evidenced by measured changes in
resonant oscillation frequencies that are correlated with the solar cycle. The
inference of internal Lorentz stresses from these measurements has the
potential to significantly advance our appreciation of the dynamo. Indeed,
seismological inverse theory for the Sun is well understood for perturbations
in composition, thermal structure and flows but, is not fully developed for
magnetism, owing to the complexity of the ideal magnetohydrodynamic (MHD)
equation. Invoking first-Born perturbation theory to characterize departures
from spherically symmetric hydrostatic models of the Sun and applying the
notation of generalized spherical harmonics, we calculate sensitivity functions
of seismic measurements to the general time-varying Lorentz stress tensor. We
find that eigenstates of isotropic (i.e. acoustic only) background models are
dominantly sensitive to isotropic deviations in the stress tensor and much more
weakly so to anisotropic stresses (and therefore challenging to infer). The
apple cannot fall far from the tree.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 04:52:13 GMT""},{""version"":""v2"",""created"":""Fri, 28 Jul 2017 12:17:58 GMT""}]","2017-07-31"
"1705.09432","Samit Dasgupta","Samit Dasgupta, Michael Spiess","On the Characteristic Polynomial of the Gross Regulator Matrix","27 pages",,,,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a conjectural formula for the principal minors and the
characteristic polynomial of Gross's regulator matrix associated to a totally
odd character of a totally real field. The formula is given in terms of the
Eisenstein cocycle, which was defined and studied earlier by the authors and
collaborators. For the determinant of the regulator matrix, our conjecture
follows from recent work of Kakde, Ventullo and the first author. For the
diagonal entries, our conjecture overlaps with the conjectural formula
presented in our prior work. The intermediate cases are new and provide a
refinement of the Gross--Stark conjecture.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 05:02:16 GMT""}]","2017-05-29"
"1705.09433","Huanhuan Huang","Huanhuan Huang, Tong Ye, Tony T. Lee, and Weisheng Hu","Optimum Transmission Window for EPONs with Gated-Limited Service","14 pages, 10 figures, IEEE transaction on networking",,,,"cs.NI cs.PF","http://creativecommons.org/licenses/by-sa/4.0/","  This paper studies the Ethernet Passive Optical Network (EPON) with
gated-limited service. The transmission window (TW) is limited in this system
to guaranteeing a bounded delay experienced by disciplined users, and to
constrain malicious users from monopolizing the transmission channel. Thus,
selecting an appropriate TW size is critical to the performance of EPON with
gated-limited service discipline. To investigate the impact of TW size on
packet delay, we derive a generalized mean waiting time formula for M/G/1 queue
with vacation times and gated-limited service discipline. A distinguished
feature of this model is that there are two queues in the buffer of each
optical network unit (ONU): one queue is inside the gate and the other one is
outside the gate. Furthermore, based on the Chernoff bound of queue length, we
provide a simple rule to determine an optimum TW size for gated-limited service
EPONs. Analytic results reported in this paper are all verified by simulations.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 05:16:55 GMT""}]","2017-05-29"
"1705.09434","Guillaume Mention","G. Mention, M. Vivier, J. Gaffiot, T. Lasserre, A. Letourneau, T.
  Materna","Reactor antineutrino shoulder explained by energy scale nonlinearities?",,"Physics Letters B (2017)","10.1016/j.physletb.2017.08.035",,"hep-ex physics.ins-det","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Daya Bay, Double Chooz and RENO experiments recently observed a
significant distortion in their detected reactor antineutrino spectra, being at
odds with the current predictions. Although such a result suggests to revisit
the current reactor antineutrino spectra modeling, an alternative scenario,
which could potentially explain this anomaly, is explored in this letter. Using
an appropriate statistical method, a study of the Daya Bay experiment energy
scale is performed. While still being in agreement with the {\gamma}
calibration data and Boron 12 measured spectrum, it is shown that a O(1%)
deviation of the energy scale reproduces the distortion observed in the Daya
Bay spectrum, remaining within the quoted calibration uncertainties. Potential
origins of such a deviation, which challenge the energy calibration of these
detectors, are finally discussed.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 05:32:52 GMT""}]","2017-09-01"
"1705.09435","Kingsley Kuan","Kingsley Kuan, Mathieu Ravaut, Gaurav Manek, Huiling Chen, Jie Lin,
  Babar Nazir, Cen Chen, Tse Chiang Howe, Zeng Zeng, Vijay Chandrasekhar","Deep Learning for Lung Cancer Detection: Tackling the Kaggle Data
  Science Bowl 2017 Challenge",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a deep learning framework for computer-aided lung cancer
diagnosis. Our multi-stage framework detects nodules in 3D lung CAT scans,
determines if each nodule is malignant, and finally assigns a cancer
probability based on these results. We discuss the challenges and advantages of
our framework. In the Kaggle Data Science Bowl 2017, our framework ranked 41st
out of 1972 teams.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 05:36:29 GMT""}]","2017-05-29"
"1705.09436","Daksh Varshneya","Daksh Varshneya, G. Srinivasaraghavan","Human Trajectory Prediction using Spatially aware Deep Attention Models","10 pages, 5 figures, Submitted to 31st Conference on Neural
  Information Processing Systems (NIPS 2017)",,,,"cs.LG cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Trajectory Prediction of dynamic objects is a widely studied topic in the
field of artificial intelligence. Thanks to a large number of applications like
predicting abnormal events, navigation system for the blind, etc. there have
been many approaches to attempt learning patterns of motion directly from data
using a wide variety of techniques ranging from hand-crafted features to
sophisticated deep learning models for unsupervised feature learning. All these
approaches have been limited by problems like inefficient features in the case
of hand crafted features, large error propagation across the predicted
trajectory and no information of static artefacts around the dynamic moving
objects. We propose an end to end deep learning model to learn the motion
patterns of humans using different navigational modes directly from data using
the much popular sequence to sequence model coupled with a soft attention
mechanism. We also propose a novel approach to model the static artefacts in a
scene and using these to predict the dynamic trajectories. The proposed method,
tested on trajectories of pedestrians, consistently outperforms previously
proposed state of the art approaches on a variety of large scale data sets. We
also show how our architecture can be naturally extended to handle multiple
modes of movement (say pedestrians, skaters, bikers and buses) simultaneously.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 05:37:36 GMT""}]","2017-05-29"
"1705.09437","Ruwan Tennakoon","Ruwan Tennakoon and Alireza Sadri and Reza Hoseinnezhad and Alireza
  Bab-Hadiashar","Effective Sampling: Fast Segmentation Using Robust Geometric Model
  Fitting",,,"10.1109/TIP.2018.2834821",,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Identifying the underlying models in a set of data points contaminated by
noise and outliers, leads to a highly complex multi-model fitting problem. This
problem can be posed as a clustering problem by the projection of higher order
affinities between data points into a graph, which can then be clustered using
spectral clustering. Calculating all possible higher order affinities is
computationally expensive. Hence in most cases only a subset is used. In this
paper, we propose an effective sampling method to obtain a highly accurate
approximation of the full graph required to solve multi-structural model
fitting problems in computer vision. The proposed method is based on the
observation that the usefulness of a graph for segmentation improves as the
distribution of hypotheses (used to build the graph) approaches the
distribution of actual parameters for the given data. In this paper, we
approximate this actual parameter distribution using a k-th order statistics
based cost function and the samples are generated using a greedy algorithm
coupled with a data sub-sampling strategy. The experimental analysis shows that
the proposed method is both accurate and computationally efficient compared to
the state-of-the-art robust multi-model fitting techniques. The code is
publicly available from https://github.com/RuwanT/model-fitting-cbs.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 05:39:07 GMT""}]","2018-08-01"
"1705.09438","Diptarama","Davaajav Jargalsaikhan and Diptarama and Ryo Yoshinaka and Ayumi
  Shinohara","Duel and sweep algorithm for order-preserving pattern matching","13 pages, 5 figures",,,,"cs.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Given a text $T$ and a pattern $P$ over alphabet $\Sigma$, the classic exact
matching problem searches for all occurrences of pattern $P$ in text $T$.
Unlike exact matching problem, order-preserving pattern matching (OPPM)
considers the relative order of elements, rather than their real values. In
this paper, we propose an efficient algorithm for OPPM problem using the
""duel-and-sweep"" paradigm. Our algorithm runs in $O(n + m\log m)$ time in
general and $O(n + m)$ time under an assumption that the characters in a string
can be sorted in linear time with respect to the string size. We also perform
experiments and show that our algorithm is faster that KMP-based algorithm.
Last, we introduce the two-dimensional order preserved pattern matching and
give a duel and sweep algorithm that runs in $O(n^2)$ time for duel stage and
$O(n^2 m)$ time for sweeping time with $O(m^3)$ preprocessing time.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 05:40:54 GMT""}]","2017-05-29"
"1705.09439","Kosetsu Tsukuda","Kosetsu Tsukuda, Masataka Goto","Taste or Addiction?: Using Play Logs to Infer Song Selection Motivation","Accepted by The 21st Pacific-Asia Conference on Knowledge Discovery
  and Data Mining (PAKDD 2017)",,,,"cs.AI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Online music services are increasing in popularity. They enable us to analyze
people's music listening behavior based on play logs. Although it is known that
people listen to music based on topic (e.g., rock or jazz), we assume that when
a user is addicted to an artist, s/he chooses the artist's songs regardless of
topic. Based on this assumption, in this paper, we propose a probabilistic
model to analyze people's music listening behavior. Our main contributions are
three-fold. First, to the best of our knowledge, this is the first study
modeling music listening behavior by taking into account the influence of
addiction to artists. Second, by using real-world datasets of play logs, we
showed the effectiveness of our proposed model. Third, we carried out
qualitative experiments and showed that taking addiction into account enables
us to analyze music listening behavior from a new viewpoint in terms of how
people listen to music according to the time of day, how an artist's songs are
listened to by people, etc. We also discuss the possibility of applying the
analysis results to applications such as artist similarity computation and song
recommendation.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 05:54:20 GMT""}]","2017-05-29"
"1705.09440","Youlin Li","Youlin Li, Zhongtao Wu","A bound for rational Thurston-Bennequin invariants","16 pages, 2 figures",,,,"math.GT math.SG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we introduce a rational $\tau$ invariant for rationally
null-homologous knots in contact 3-manifolds with nontrivial
Ozsv\'{a}th-Szab\'{o} contact invariants. Such an invariant is an upper bound
for the sum of rational Thurston-Bennequin invariant and the rational rotation
number of the Legendrian representatives of the knot. In the special case of
Floer simple knots in L-spaces, we can compute the rational $\tau$ invariants
by correction terms.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 05:56:08 GMT""},{""version"":""v2"",""created"":""Fri, 11 Aug 2017 06:56:26 GMT""}]","2017-08-14"
"1705.09441","Kisoo Park","Kisoo Park, Hasung Sim, Jonathan C. Leiner, Yoshiyuki Yoshida, Jaehong
  Jeong, Shin-ichiro Yano, Jason Gardner, Philippe Bourges, Milan Klicpera,
  Vladim\'ir Sechovsk\'y, Martin Boehm, Je-Geun Park","Low-energy spin dynamics of orthoferrites AFeO$_3$ (A = Y, La, Bi)","7 pages, 4 figures",,"10.1088/1361-648X/aac06b",,"cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  YFeO$_3$ and LaFeO$_3$ are members of the rare-earth orthoferrites family
with \textit{Pbnm} space group. Using inelastic neutron scattering, the
low-energy spin excitations have been measured around magnetic Brillouin zone
center. Splitting of magnon branches and non-zero magnon gap is observed for
both compounds, which is similar to the behavior observed in multiferroic
BiFeO$_3$. Spin wave calculations which include both Dzyaloshinsky-Moriya
interactions and single-ion anisotropy in the spin-Hamiltonian comprehensively
accounts for all the experimentally observed features. Our results offer
insight into the unifying physics underlying the Fe$^{3+}$-based perovskites as
well as their distinguishing characteristics.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 06:13:24 GMT""},{""version"":""v2"",""created"":""Mon, 29 May 2017 04:55:05 GMT""},{""version"":""v3"",""created"":""Fri, 11 May 2018 07:47:01 GMT""}]","2018-06-13"
"1705.09442","Eemeli Bl{\aa}sten","Eemeli Bl{\aa}sten","Well-posedness of the Goursat problem and stability for point source
  inverse backscattering","24 pages, 2 figures",,"10.1088/1361-6420/aa941f",,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show logarithmic stability for the point source inverse backscattering
problem under the assumption of angularly controlled potentials. Radial
symmetry implies H\""older stability. Importantly, we also show that the point
source equation is well-posed and also that the associated characteristic
initial value problem, or Goursat problem, is well-posed. These latter results
are difficult to find in the literature in the form required by the stability
proof.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 06:17:13 GMT""},{""version"":""v2"",""created"":""Thu, 19 Oct 2017 02:38:02 GMT""}]","2017-10-20"
"1705.09443","Fei Liu","Fei Liu and Lexing Ying","Sparsify and sweep: an efficient preconditioner for the
  Lippmann-Schwinger equation",,,,,"math.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper presents an efficient preconditioner for the Lippmann-Schwinger
equation that combines the ideas of the sparsifying and the sweeping
preconditioners. Following first the idea of the sparsifying preconditioner,
this new preconditioner starts by transforming the dense linear system of the
Lippmann-Schwinger equation into a nearly sparse system. The key novelty is a
newly designed perfectly matched layer (PML) stencil for the boundary degrees
of freedoms. The resulting sparse system gives rise to fairly accurate
solutions and hence can be viewed as an accurate discretization of the
Helmholtz equation. This new PML stencil also paves the way for applying the
moving PML sweeping preconditioner to invert the resulting sparse system
approximately. When combined with the standard GMRES solver, this new
preconditioner for the Lippmann-Schwinger equation takes only a few iterations
to converge for both 2D and 3D problems, where the iteration numbers are almost
independent of the frequency. To the best of our knowledge, this is the first
method that achieves near-linear cost to solve the 3D Lippmann-Schwinger
equation in high frequency cases.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 06:23:29 GMT""},{""version"":""v2"",""created"":""Thu, 30 Nov 2017 17:45:15 GMT""}]","2017-12-01"
"1705.09444","Haris Aziz","Haris Aziz and Paul Goldberg and Toby Walsh","Equilibria in Sequential Allocation",,,,,"cs.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Sequential allocation is a simple mechanism for sharing multiple indivisible
items. We study strategic behavior in sequential allocation. In particular, we
consider Nash dynamics, as well as the computation and Pareto optimality of
pure equilibria, and Stackelberg strategies. We first demonstrate that, even
for two agents, better responses can cycle. We then present a linear-time
algorithm that returns a profile (which we call the ""bluff profile"") that is in
pure Nash equilibrium. Interestingly, the outcome of the bluff profile is the
same as that of the truthful profile and the profile is in pure Nash
equilibrium for \emph{all} cardinal utilities consistent with the ordinal
preferences. We show that the outcome of the bluff profile is Pareto optimal
with respect to pairwise comparisons. In contrast, we show that an assignment
may not be Pareto optimal with respect to pairwise comparisons even if it is a
result of a preference profile that is in pure Nash equilibrium for all
utilities consistent with ordinal preferences. Finally, we present a dynamic
program to compute an optimal Stackelberg strategy for two agents, where the
second agent has a constant number of distinct values for the items.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 06:31:57 GMT""}]","2017-05-29"
"1705.09445","Scientific Information Service CERN","P. Baudrenghien, G. Burt, R. Calaga, O. Capatina, W. Hofle, E. Jensen,
  A. Macpherson, E. Montesinos, A. Ratti and E. Shaposhnikova","RF Systems","27 pages, Chapter 4 in High-Luminosity Large Hadron Collider (HL-LHC)","CERN Yellow report CERN-2015-005, pp.81-107","10.5170/CERN-2015-005.81",,"physics.acc-ph","http://creativecommons.org/licenses/by/4.0/","  Chapter 4 in High-Luminosity Large Hadron Collider (HL-LHC). The Large Hadron
Collider (LHC) is one of the largest scientific instruments ever built. Since
opening up a new energy frontier for exploration in 2010, it has gathered a
global user community of about 7,000 scientists working in fundamental particle
physics and the physics of hadronic matter at extreme temperature and density.
To sustain and extend its discovery potential, the LHC will need a major
upgrade in the 2020s. This will increase its luminosity (rate of collisions) by
a factor of five beyond the original design value and the integrated luminosity
(total collisions created) by a factor ten. The LHC is already a highly complex
and exquisitely optimised machine so this upgrade must be carefully conceived
and will require about ten years to implement. The new configuration, known as
High Luminosity LHC (HL-LHC), will rely on a number of key innovations that
push accelerator technology beyond its present limits. Among these are
cutting-edge 11-12 tesla superconducting magnets, compact superconducting
cavities for beam rotation with ultra-precise phase control, new technology and
physical processes for beam collimation and 300 metre-long high-power
superconducting links with negligible energy dissipation. The present document
describes the technologies and components that will be used to realise the
project and is intended to serve as the basis for the detailed engineering
design of HL-LHC.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 06:37:06 GMT""}]","2017-05-29"
"1705.09446","Zaidao Wen","Zaidao Wen, Biao Hou and Licheng Jiao","Joint Sparse Recovery With Semisupervised MUSIC","Code is available","IEEE Signal Processing Letters (Volume: 24, Issue: 5, May 2017)","10.1109/LSP.2017.2680603",,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Discrete multiple signal classification (MUSIC) with its low computational
cost and mild condition requirement becomes a significant noniterative
algorithm for joint sparse recovery (JSR). However, it fails in rank defective
problem caused by coherent or limited amount of multiple measurement vectors
(MMVs). In this letter, we provide a novel sight to address this problem by
interpreting JSR as a binary classification problem with respect to atoms.
Meanwhile, MUSIC essentially constructs a supervised classifier based on the
labeled MMVs so that its performance will heavily depend on the quality and
quantity of these training samples. From this viewpoint, we develop a
semisupervised MUSIC (SS-MUSIC) in the spirit of machine learning, which
declares that the insufficient supervised information in the training samples
can be compensated from those unlabeled atoms. Instead of constructing a
classifier in a fully supervised manner, we iteratively refine a semisupervised
classifier by exploiting the labeled MMVs and some reliable unlabeled atoms
simultaneously. Through this way, the required conditions and iterations can be
greatly relaxed and reduced. Numerical experimental results demonstrate that
SS-MUSIC can achieve much better recovery performances than other MUSIC
extended algorithms as well as some typical greedy algorithms for JSR in terms
of iterations and recovery probability.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 06:37:47 GMT""}]","2017-05-29"
"1705.09447","Scientific Information Service CERN","D. Angal-Kalinin, R. Appleby, G. Arduini, D. Banfi, J. Barranco, N.
  Biancacci, D. Brett, R. Bruce, O. Bruening, X. Buffat, A. Burov, Y. Cai, R.
  Calaga, A. Chanc\'e, M. Crouch, B. Dalena, H. Day, R. de Maria, J. Esteban
  Muller, S. Fartoukh, M. Fitterer, O. Frasciello, M. Giovannozzi, W. Herr, W.
  H\""ofle, B. Holzer, G. Iadarola, J.M. Jowett, M. Korostelev, K. Li, E.
  McIntosh, E. M\'etral, A. Mostacci, N. Mounet, B. Muratori, Y. Nosochkov, K.
  Ohmi, Y. Papaphilippou, S. Paret, J. Payet, T. Pieloni, J. Qiang, T. Rijoff,
  L. Rossi, G. Rumolo, B. Salvant, M. Schaumann, E. Shaposhnikova, D. Shatilov,
  C. Tambasco, R. Tom\'as, A. Valishev, M.-H. Wang, R. Wanzenberg, S. White, A.
  Wolski, O. Zagorodnova, C. Zannini, F. Zimmermann and M. Zobov","Machine Layout and Performance","40 pages, chapter 2 in High-Luminosity Large Hadron Collider (HL-LHC)
  : Preliminary Design Report","CERN Yellow Report CERN 2015-005, pp. 21-60","10.5170/CERN-2015-005.21",,"physics.acc-ph","http://creativecommons.org/licenses/by/4.0/","  Chapter 2 in High-Luminosity Large Hadron Collider (HL-LHC) : Preliminary
Design Report. The Large Hadron Collider (LHC) is one of the largest scientific
instruments ever built. Since opening up a new energy frontier for exploration
in 2010, it has gathered a global user community of about 7,000 scientists
working in fundamental particle physics and the physics of hadronic matter at
extreme temperature and density. To sustain and extend its discovery potential,
the LHC will need a major upgrade in the 2020s. This will increase its
luminosity (rate of collisions) by a factor of five beyond the original design
value and the integrated luminosity (total collisions created) by a factor ten.
The LHC is already a highly complex and exquisitely optimised machine so this
upgrade must be carefully conceived and will require about ten years to
implement. The new configuration, known as High Luminosity LHC (HL-LHC), will
rely on a number of key innovations that push accelerator technology beyond its
present limits. Among these are cutting-edge 11-12 tesla superconducting
magnets, compact superconducting cavities for beam rotation with ultra-precise
phase control, new technology and physical processes for beam collimation and
300 metre-long high-power superconducting links with negligible energy
dissipation. The present document describes the technologies and components
that will be used to realise the project and is intended to serve as the basis
for the detailed engineering design of HL-LHC.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 06:38:05 GMT""}]","2017-05-29"
"1705.09448","Scientific Information Service CERN","G. Ambrosio, M. Anerella, R. Bossert, D. Cheng, G. Chlachidze, D.
  Dietderich, D Duarte Ramos, P. Fabbricatore, S. Farinon, H. Felice, P.
  Ferracin, P. Fessia, J. Garcia Matos, A. Ghosh, P. Hagen, S. Izquierdo
  Bermudez, M. Juchno, S. Krave, M. Marchevsky, T. Nakamoto, T. Ogitsu, J.C.
  Perez, H. Prin, J.M. Rifflet, G.L. Sabbi, K. Sasaki, J. Schmalzle, M.
  Segreti, M. Sugano, E. Todesco, F. Toral, G. Volpini, P. Wanderer, X. Wang,
  R.V. Weelderen, Q. Xu and M. Yu","Insertion Magnets","19 pages, Chapter 3 in High-Luminosity Large Hadron Collider (HL-LHC)
  : Preliminary Design Report","CERN Yellow Report CERN 2015-005, pp. 61-79","10.5170/CERN-2015-005.61",,"physics.acc-ph","http://creativecommons.org/licenses/by/4.0/","  Chapter 3 in High-Luminosity Large Hadron Collider (HL-LHC) : Preliminary
Design Report. The Large Hadron Collider (LHC) is one of the largest scientific
instruments ever built. Since opening up a new energy frontier for exploration
in 2010, it has gathered a global user community of about 7,000 scientists
working in fundamental particle physics and the physics of hadronic matter at
extreme temperature and density. To sustain and extend its discovery potential,
the LHC will need a major upgrade in the 2020s. This will increase its
luminosity (rate of collisions) by a factor of five beyond the original design
value and the integrated luminosity (total collisions created) by a factor ten.
The LHC is already a highly complex and exquisitely optimised machine so this
upgrade must be carefully conceived and will require about ten years to
implement. The new configuration, known as High Luminosity LHC (HL-LHC), will
rely on a number of key innovations that push accelerator technology beyond its
present limits. Among these are cutting-edge 11-12 tesla superconducting
magnets, compact superconducting cavities for beam rotation with ultra-precise
phase control, new technology and physical processes for beam collimation and
300 metre-long high-power superconducting links with negligible energy
dissipation. The present document describes the technologies and components
that will be used to realise the project and is intended to serve as the basis
for the detailed engineering design of HL-LHC.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 06:38:58 GMT""}]","2017-05-29"
"1705.09449","Samad Khabbazi Oskouei","Fabio Benatti, Samad Khabbazi Oskouei, Ahmad Shafiei Deh Abad","Quantum entropy and complexity",,"Open Syst. Inf. Dyn. 24, 1750005 (2017)","10.1142/S1230161217500056",,"cs.IT math.DS math.IT quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the relations between the recently proposed machine-independent
quantum complexity of P. Gacs~\cite{Gacs} and the entropy of classical and
quantum systems. On one hand, by restricting Gacs complexity to ergodic
classical dynamical systems, we retrieve the equality between the Kolmogorov
complexity rate and the Shannon entropy rate derived by A.A.
Brudno~\cite{Brudno}. On the other hand, using the quantum Shannon-Mc Millan
theorem~\cite{BSM}, we show that such an equality holds densely in the case of
ergodic quantum spin chains.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 06:40:49 GMT""}]","2018-04-23"
"1705.09450","Jun He","Jun He, Jiankui Li, and Danjun Zhao","Derivations, local and 2-local derivations on some algebras of operators
  on Hilbert C*-modules","12 pages",,,,"math.OA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For a commutative C*-algebra $\mathcal A$ with unit $e$ and a
Hilbert~$\mathcal A$-module $\mathcal M$, denote by End$_{\mathcal A}(\mathcal
M)$ the algebra of all bounded $\mathcal A$-linear mappings on $\mathcal M$,
and by End$^*_{\mathcal A}(\mathcal M)$ the algebra of all adjointable mappings
on $\mathcal M$. We prove that if $\mathcal M$ is full, then each derivation on
End$_{\mathcal A}(\mathcal M)$ is $\mathcal A$-linear, continuous, and inner,
and each 2-local derivation on End$_{\mathcal A}(\mathcal M)$ or
End$^{*}_{\mathcal A}(\mathcal M)$ is a derivation. If there exist $x_0$ in
$\mathcal M$ and $f_0$ in $\mathcal M^{'}$, such that $f_0(x_0)=e$, where
$\mathcal M^{'}$ denotes the set of all bounded $\mathcal A$-linear mappings
from $\mathcal M$ to $\mathcal A$, then each $\mathcal A$-linear local
derivation on End$_{\mathcal A}(\mathcal M)$ is a derivation.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 06:41:37 GMT""},{""version"":""v2"",""created"":""Thu, 1 Jun 2017 05:46:51 GMT""}]","2017-06-02"
"1705.09451","Biswa Sengupta","Y Qian and P Giaccone and M Sasdelli and E Vasquez and B Sengupta","Algorithmic clothing: hybrid recommendation, from street-style-to-shop","KDD 2017 Workshop on ML meets Fashion",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we detail Cortexica's (https://www.cortexica.com)
recommendation framework -- particularly, we describe how a hybrid visual
recommender system can be created by combining conditional random fields for
segmentation and deep neural networks for object localisation and feature
representation. The recommendation system that is built after localisation,
segmentation and classification has two properties -- first, it is knowledge
based in the sense that it learns pairwise preference/occurrence matrix by
utilising knowledge from experts (images from fashion blogs) and second, it is
content-based as it utilises a deep learning based framework for learning
feature representation. Such a construct is especially useful when there is a
scarcity of user preference data, that forms the foundation of many
collaborative recommendation algorithms.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 06:43:47 GMT""},{""version"":""v2"",""created"":""Sun, 12 Nov 2017 09:45:36 GMT""}]","2017-11-15"
"1705.09452","Wang Hao","Hao Wang, Huanxia Fa and Junbo Li","Representations of Super $W(2,2)$ algebra $\mathfrak{L}$","21pages,0figures",,,,"math.RT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In paper, we study the representation theory of super $W(2,2)$ algebra
${\mathfrak{L}}$. We prove that ${\mathfrak{L}}$ has no mixed irreducible
modules and give the classification of irreducible modules of intermediate
series. We determinate the conjugate-linear anti-involution of ${\mathfrak{L}}$
and give the unitary modules of intermediate series.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 06:50:05 GMT""}]","2017-05-29"
"1705.09453","Stafford Withington Prof.","Stafford Withington, Emily Williams, David J. Goldie, Christopher N.
  Thomas and Max Schneiderman","Thermal elastic-wave attenuation in low-dimensional SiN$_{x}$ bars at
  low temperatures","3 figures",,"10.1063/1.4997466",,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  At low temperatures, < 200 mK, the thermal flux through low-dimensional
amorphous dielectric bars, < 2 $\mu$m wide and 200 nm thick, is transported by
a small number of low-order elastic modes. For long bars, L > 400 $\mu$m, it is
known that the conductance scales as 1/L, where L is the length, but for short
bars, 1 $\mu$m < L < 400 $\mu$m, the length dependence is poorly known.
Although it is assumed that the transport must exhibit a diffusive to ballistic
transition, the functional form of the transition and the scale size over which
the transition occurs have not, to our knowledge, been measured. In this paper,
we use ultra-low-noise superconducting Transition Edge Sensors (TESs) to
measure the heat flux through a set of SiN$_{x}$ bars to establish the
characteristic scale size of the ballistic to diffusive transition. For bars
supporting 6 to 7 modes, we measure a thermal elastic-wave attenuation length
of 20 $\mu$m. The measurement is important because it sheds light on the
scattering processes, which in turn are closely related to the generation of
thermal fluctuation noise. Our own interest lies in creating patterned phononic
filters for controlling heat flow and thermal noise in ultra-low-noise devices,
but the work will be of interest to others trying to isolate devices from their
environments, and studying loss mechanisms in micro-mechanical resonators.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 06:50:52 GMT""}]","2017-09-13"
"1705.09454","Mohammadreza Doostmohammadian","Mohammadreza Doostmohammadian, Houman Zarrabi, Hamid R. Rabiee","Sensor Selection Cost Optimization for Tracking Structurally Cyclic
  Systems: a P-Order Solution",,,"10.1080/00207721.2017.1322640",,"cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Measurements and sensing implementations impose certain cost in sensor
networks. The sensor selection cost optimization is the problem of minimizing
the sensing cost of monitoring a physical (or cyber- physical) system. Consider
a given set of sensors tracking states of a dynamical system for estimation
purposes. For each sensor assume different costs to measure different
(realizable) states. The idea is to assign sensors to measure states such that
the global cost is minimized. The number and selection of sensor measurements
need to ensure the observability to track the dynamic state of the system with
bounded estimation error. The main question we address is how to select the
state measurements to minimize the cost while satisfying the observability
conditions. Relaxing the observability condition for structurally cyclic
systems, the main contribution is to propose a graph theoretic approach to
solve the problem in polynomial time. Note that, polynomial time algorithms are
suitable for large-scale systems as their running time is upper-bounded by a
polynomial expression in the size of input for the algorithm. We frame the
problem as a linear sum assignment with solution complexity of O(m3).
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 06:53:45 GMT""}]","2017-06-01"
"1705.09455","Jia Liu","Vedran Brdar, Joachim Kopp, Jia Liu, Pascal Prass, Xiao-Ping Wang (JGU
  Mainz)","Fuzzy Dark Matter and Non-Standard Neutrino Interactions","7 pages, 3 figures; v2: references added, matched to Journal version","Phys. Rev. D 97, 043001 (2018)","10.1103/PhysRevD.97.043001","MITP/17-037","hep-ph astro-ph.HE hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We discuss novel ways in which neutrino oscillation experiments can probe
dark matter. In particular, we focus on interactions between neutrinos and
ultra-light (""fuzzy"") dark matter particles with masses of order $10^{-22}$ eV.
It has been shown previously that such dark matter candidates are
phenomenologically successful and might help ameliorate the tension between
predicted and observed small scale structures in the Universe. We argue that
coherent forward scattering of neutrinos on fuzzy dark matter particles can
significantly alter neutrino oscillation probabilities. These effects could be
observable in current and future experiments. We set new limits on fuzzy dark
matter interacting with neutrinos using T2K and solar neutrino data, and we
estimate the sensitivity of reactor neutrino experiments and of future
long-baseline accelerator experiments. These results are based on detailed
simulations in GLoBES. We allow the dark matter particle to be either a scalar
or a vector boson. In the latter case, we find potentially interesting
connections to models addressing various $B$ physics anomalies.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 07:04:23 GMT""},{""version"":""v2"",""created"":""Fri, 2 Feb 2018 16:02:24 GMT""}]","2018-02-05"
"1705.09456","Wang Hao","Hao Wang, Huanxia Fa and Junbo Li","Derivation algebras and automorphism groups of a class of deformative
  super $W$-algebras $W^s_\lambda(2,2)$","19pages, 0 figures",,,,"math.RA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, the derivation algebras and automorphism groups of a class of
deformative super $W$-algebras $W_{\lambda}(2,2)$ are determined.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 07:11:37 GMT""}]","2017-05-29"
"1705.09457","Christiane G\""orgen","Christiane G\""orgen, Anna Bigatti, Eva Riccomagno, Jim Q. Smith","Discovery of statistical equivalence classes using computer algebra","26 pages, 9 figures",,,,"math.ST stat.CO stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Discrete statistical models supported on labelled event trees can be
specified using so-called interpolating polynomials which are generalizations
of generating functions. These admit a nested representation. A new algorithm
exploits the primary decomposition of monomial ideals associated with an
interpolating polynomial to quickly compute all nested representations of that
polynomial. It hereby determines an important subclass of all trees
representing the same statistical model. To illustrate this method we analyze
the full polynomial equivalence class of a staged tree representing the best
fitting model inferred from a real-world dataset.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 07:17:24 GMT""}]","2017-05-29"
"1705.09458","Young-Hoon Kiem","Young-Hoon Kiem and Jun Li","Localizing virtual structure sheaves by cosections","25 pages; published version",,,,"math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We construct a cosection localized virtual structure sheaf when a
Deligne-Mumford stack is equipped with a perfect obstruction theory and a
cosection of the obstruction sheaf.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 07:17:53 GMT""},{""version"":""v2"",""created"":""Fri, 16 Nov 2018 02:15:35 GMT""}]","2018-11-19"
"1705.09459","Caroline Lasser","Oliver Deiser and Caroline Lasser","On the higher derivates of arctan","7 pages",,,,"math.CA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  WWe give a rational closed form expression for the higher derivatives of the
inverse tangent function and discuss its relation to Chebyshev polynomials,
trigonometric expansions and Appell sequences of polynomials.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 07:18:37 GMT""},{""version"":""v2"",""created"":""Fri, 16 Jun 2017 15:30:14 GMT""}]","2017-06-19"
"1705.09460","Alfonso Iacovazzi","Alfonso Iacovazzi, Sanat Sarda, Daniel Frassinelli, and Yuval Elovici","DROPWAT: an Invisible Network Flow Watermark for Data Exfiltration
  Traceback",,,"10.1109/TIFS.2017.2779113",,"cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Watermarking techniques have been proposed during the last 10 years as an
approach to trace network flows for intrusion detection purposes. These
techniques aim to impress a hidden signature on a traffic flow. A central
property of network flow watermarking is invisibility, i.e., the ability to go
unidentified by an unauthorized third party. Although widely sought after, the
development of an invisible watermark is a challenging task that has not yet
been accomplished.
  In this paper we take a step forward in addressing the invisibility problem
with DROPWAT, an active network flow watermarking technique developed for
tracing Internet flows directed to the staging server that is the final
destination in a data exfiltration attack, even in the presence of several
intermediate stepping stones or an anonymous network. DROPWAT is a timing-based
technique that indirectly modifies interpacket delays by exploiting network
reaction to packet loss. We empirically demonstrate that the watermark embedded
by means of DROPWAT is invisible to a third party observing the watermarked
traffic. We also validate DROPWAT and analyze its performance in a controlled
experimental framework involving the execution of a series of experiments on
the Internet, using Web proxy servers as stepping stones executed on several
instances in Amazon Web Services, as well as the TOR anonymous network in the
place of the stepping stones. Our results show that the detection algorithm is
able to identify an embedded watermark achieving over 95% accuracy while being
invisible.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 07:24:47 GMT""}]","2017-12-05"
"1705.09461","Milivoje Lukic","Milivoje Lukic","Spectral edge behavior for eventually monotone Jacobi and Verblunsky
  coefficients","33 pages. Same results as in previous version, some expository
  changes; to appear in Journal of Spectral Theory",,,,"math.SP math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider Jacobi matrices with eventually increasing sequences of diagonal
and off-diagonal Jacobi parameters. We describe the asymptotic behavior of the
subordinate solution at the top of the essential spectrum, and the asymptotic
behavior of the spectral density at the top of the essential spectrum.
  In particular, allowing on both diagonal and off-diagonal Jacobi parameters
perturbations of the free case of the form $- \sum_{j=1}^J c_j n^{-\tau_j} +
o(n^{-\tau_1-1})$ with $0 < \tau_1 < \tau_2 < \dots < \tau_J$ and $c_1>0$, we
find the asymptotic behavior of the $\log$ of spectral density to order
$O(\log(2-x))$ as $x$ approaches $2$.
  Apart from its intrinsic interest, the above results also allow us to
describe the asymptotics of the spectral density for orthogonal polynomials on
the unit circle with real-valued Verblunsky coefficients of the same form.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 07:31:21 GMT""},{""version"":""v2"",""created"":""Thu, 1 Feb 2018 00:22:40 GMT""}]","2018-02-02"
"1705.09462","Jing Liu","Fanqi Zeng, Li Gong, Jing Liu, Jiang Zhang, Qinghua Chen, Ruyue Xin","Interactive Levy Flight in Interest Space",,,"10.1088/2632-072X/ab7f4f",,"cs.SI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Compared to the well-studied topic of human mobility in real geographic
space, very few studies focus on human mobility in virtual space, such as
interests, knowledge, ideas, and so forth. However, it relates to the issues of
management of public opinions, knowledge diffusion, and innovation. In this
paper, we assume that the interests of a group of online users can span a
Euclidean space which is called interest space, and the transfers of user
interests can be modeled as the Levy Flight on the interest space. To consider
the interaction between users, we assume that the random walkers are not
independent but interact each other indirectly via the digital resources in the
interest space. The model can successfully reproduce a set of scaling laws for
describing the growth of the attention flow networks of real online
communities, and the ranges of the exponents of the scaling are similar with
the empirical data. Further, we can infer parameters for describing the
individual behaviors of the users according to the scaling laws of the
empirical attention flow network. Our model can not only provide theoretical
understanding on human online behaviors, but also has wide potential
applications, such as dissemination and management of public opinions, online
recommendation, etc.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 07:33:29 GMT""}]","2021-04-27"
"1705.09463","Tomasz Grzywny","Tomasz Grzywny and Hyunchul Park and Renming Song","Spectral Heat Content for L\'evy Processes","19 pages",,"10.1002/mana.201800035",,"math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we study the spectral heat content for various L\'evy
processes. We establish the asymptotic behavior of the spectral heat content
for L\'{e}vy processes of bounded variation in $\mathbb{R}^{d}$, $d\geq 1$. We
also study the spectral heat content for arbitrary open sets of finite Lebesgue
measure in $\mathbb{R}$ with respect to L\'{e}vy processes of unbounded
variation under certain conditions on their characteristic exponents. Finally
we establish that the asymptotic behavior of the spectral heat content is
stable under integrable perturbations to the L\'{e}vy measure.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 07:33:32 GMT""}]","2018-11-29"
"1705.09464","Genevieve Robin","Genevi\`eve Robin and Christophe Ambroise and St\'ephane Robin","Incomplete graphical model inference via latent tree aggregation",,,,,"stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Graphical network inference is used in many fields such as genomics or
ecology to infer the conditional independence structure between variables, from
measurements of gene expression or species abundances for instance. In many
practical cases, not all variables involved in the network have been observed,
and the samples are actually drawn from a distribution where some variables
have been marginalized out. This challenges the sparsity assumption commonly
made in graphical model inference, since marginalization yields locally dense
structures, even when the original network is sparse. We present a procedure
for inferring Gaussian graphical models when some variables are unobserved,
that accounts both for the influence of missing variables and the low density
of the original network. Our model is based on the aggregation of spanning
trees, and the estimation procedure on the Expectation-Maximization algorithm.
We treat the graph structure and the unobserved nodes as missing variables and
compute posterior probabilities of edge appearance. To provide a complete
methodology, we also propose several model selection criteria to estimate the
number of missing nodes. A simulation study and an illustration flow cytometry
data reveal that our method has favorable edge detection properties compared to
existing graph inference techniques. The methods are implemented in an R
package.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 07:36:00 GMT""},{""version"":""v2"",""created"":""Wed, 21 Mar 2018 17:12:17 GMT""}]","2018-03-22"
"1705.09465","Chor-Hoi Chan","Chor-Hoi Chan, Gregory Brown, Per Arne Rikvold","Phase diagrams and free-energy landscapes for model spin-crossover
  materials with antiferromagnetic-like nearest-neighbor and ferromagnetic-like
  long-range interactions","35 pages, 20 figures","Phys. Rev. B 96, 174428 (2017)","10.1103/PhysRevB.96.174428",,"cond-mat.mtrl-sci cond-mat.other cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present phase diagrams, free-energy landscapes, and order-parameter
distributions for a model spin-crossover material with a two-step transition
between the high-spin and low-spin states (a square-lattice Ising model with
antiferromagnetic-like nearest-neighbor and ferromagnetic-like long-range
interactions) [P. A. Rikvold et al., Phys. Rev. B 93, 064109 (2016)]. The
results are obtained by a recently introduced, macroscopically constrained
Wang-Landau Monte Carlo simulation method [C. H. Chan, G. Brown, and P. A.
Rikvold, Phys. Rev. E 95, 053302 (2017)]. The method's computational efficiency
enables calculation of thermodynamic quantities for a wide range of
temperatures, applied fields, and long-range interaction strengths. For
long-range interactions of intermediate strength, tricritical points in the
phase diagrams are replaced by pairs of critical end points and mean-field
critical points that give rise to horn-shaped regions of metastability. The
corresponding free-energy landscapes offer insights into the nature of
asymmetric, multiple hysteresis loops that have been experimentally observed in
spin-crossover materials characterized by competing short-range interactions
and long-range elastic interactions.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 07:44:39 GMT""},{""version"":""v2"",""created"":""Thu, 30 Nov 2017 06:14:41 GMT""}]","2017-12-01"
"1705.09466","Kota Ido","Kota Ido, Takahiro Ohgoe, Masatoshi Imada","Correlation-induced superconductivity dynamically stabilized and
  enhanced by laser irradiation","23 pages, 13 figures","Sci. Adv. 3, e1700718 (2017)","10.1126/sciadv.1700718",,"cond-mat.supr-con","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Studies on out-of-equilibrium dynamics have paved a way to realize a new
state of matter. Especially, superconductor-like properties above room
temperatures recently suggested in copper oxides achieved by selectively
exciting vibrational phonon modes by laser have inspired studies on an
alternative and general strategy to be pursued for high temperature
superconductivity. Here, we show that the superconductivity can be enhanced by
irradiating laser to correlated electron systems owing to two mechanisms:
First, the effective attractive interaction of carriers is enhanced by the
dynamical localization mechanism, which drives the system into strong coupling
regions. Secondly, the irradiation allows reaching uniform and enhanced
superconductivity dynamically stabilized without deteriorating into equilibrium
inhomogeneities that suppress superconductivity. The dynamical
superconductivity is subject to the Higgs oscillations during and after the
irradiation. Our finding shed light on a way to enhance superconductivity that
is inaccessible in equilibrium in strongly correlated electron systems.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 07:56:17 GMT""}]","2017-08-22"
"1705.09467","Yichao Yan","Yichao Yan, Bingbing Ni, Xiaokang Yang","Predicting Human Interaction via Relative Attention Model","To appear in IJCAI 2017",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Predicting human interaction is challenging as the on-going activity has to
be inferred based on a partially observed video. Essentially, a good algorithm
should effectively model the mutual influence between the two interacting
subjects. Also, only a small region in the scene is discriminative for
identifying the on-going interaction. In this work, we propose a relative
attention model to explicitly address these difficulties. Built on a
tri-coupled deep recurrent structure representing both interacting subjects and
global interaction status, the proposed network collects spatio-temporal
information from each subject, rectified with global interaction information,
yielding effective interaction representation. Moreover, the proposed network
also unifies an attention module to assign higher importance to the regions
which are relevant to the on-going action. Extensive experiments have been
conducted on two public datasets, and the results demonstrate that the proposed
relative attention network successfully predicts informative regions between
interacting subjects, which in turn yields superior human interaction
prediction accuracy.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 08:04:24 GMT""}]","2017-05-29"
"1705.09468","Alexander Span","Alexander Span, Vahid Aref, Henning Buelow, Stephan ten Brink","On Time-Bandwidth Product of Multi-Soliton Pulses","Accepted for ISIT 2017",,,,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Multi-soliton pulses are potential candidates for fiber optical transmission
where the information is modulated and recovered in the so-called nonlinear
Fourier domain. While this is an elegant technique to account for the channel
nonlinearity, the obtained spectral efficiency, so far, is not competitive with
the classic Nyquist-based schemes. In this paper, we study the evolution of the
time-bandwidth product of multi-solitons as they propagate along the optical
fiber. For second and third order soliton pulses, we numerically optimize the
pulse shapes to achieve the smallest time-bandwidth product when the phase of
the spectral amplitudes is used for modulation. Moreover, we analytically
estimate the pulse-duration and bandwidth of multi-solitons in some practically
important cases. Those estimations enable us to approximate the time-bandwidth
product for higher order solitons.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 08:05:22 GMT""}]","2017-05-29"
"1705.09469","Tomas Salac","Tomas Salac","$k$-Dirac Complexes",,"SIGMA 14 (2018), 012, 33 pages","10.3842/SIGMA.2018.012",,"math.DG","http://creativecommons.org/licenses/by-sa/4.0/","  This is the first paper in a series of two papers. In this paper we construct
complexes of invariant differential operators which live on homogeneous spaces
of $|2|$-graded parabolic geometries of some particular type. We call them
$k$-Dirac complexes. More explicitly, we will show that each $k$-Dirac complex
arises as the direct image of a relative BGG sequence and so this fits into the
scheme of the Penrose transform. We will also prove that each $k$-Dirac complex
is formally exact, i.e., it induces a long exact sequence of infinite
(weighted) jets at any fixed point. In the second part of the series we use
this information to show that each $k$-Dirac complex is exact at the level of
formal power series at any point and that it descends to a resolution of the
$k$-Dirac operator studied in Clifford analysis.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 08:15:28 GMT""},{""version"":""v2"",""created"":""Tue, 30 May 2017 07:35:14 GMT""},{""version"":""v3"",""created"":""Fri, 9 Feb 2018 17:46:29 GMT""},{""version"":""v4"",""created"":""Fri, 16 Feb 2018 05:11:29 GMT""}]","2018-02-19"
"1705.09470","Alexander Kamenshchik","A.O. Barvinsky and A.Yu. Kamenshchik","Darkness without dark matter and energy -- generalized unimodular
  gravity","11 pages, final version, to be published in Physics Letters B","Physics Letters B 774, 59-63 (2017)","10.1016/j.physletb.2017.09.045",,"gr-qc hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We suggest a Lorentz non-invariant generalization of the unimodular gravity
theory, which is classically equivalent to general relativity with a locally
inert (devoid of local degrees of freedom) perfect fluid having an equation of
state with a constant parameter $w$. For the range of $w$ near $-1$ this dark
fluid can play the role of dark energy, while for $w=0$ this dark dust admits
spatial inhomogeneities and can be interpreted as dark matter. We discuss
possible implications of this model in the cosmological initial conditions
problem. In particular, this is the extension of known microcanonical density
matrix predictions for the initial quantum state of the closed cosmology to the
case of spatially open Universe, based on the imitation of the spatial
curvature by the dark fluid density. We also briefly discuss quantization of
this model necessarily involving the method of gauge systems with reducible
constraints and the effect of this method on the treatment of recently
suggested mechanism of vacuum energy sequestering.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 08:17:11 GMT""},{""version"":""v2"",""created"":""Fri, 15 Sep 2017 13:30:05 GMT""}]","2017-10-02"
"1705.09471","Washington Chagas-Filho","W. F. Chagas-Filho","Loop Quantum Gravity in the Momentum Representation",,,,,"gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a generalization of the first-order formalism used to describe the
dynamics of a classical system. The generalization is then applied to the
first-order action that describes General Relativity. As a result we obtain
equations that can be interpreted as describing quantum gravity in the momentum
representation.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 08:17:30 GMT""}]","2017-05-29"
"1705.09472","Muneaki Hase","Kirill V. Mitrofanov, Paul Fons, Kotaro Makino, Ryo Terashima, Toru
  Shimada, Alexander V. Kolobov, Junji Tominaga, Valeria Bragaglia, Alessandro
  Giussani, Raffaella Calarco, Henning Riechert, Takahiro Sato, Tetsuo
  Katayama, Kanade Ogawa, Tadashi Togashi, Makina Yabashi, Simon Wall, Dale
  Brewe, and Muneaki Hase","Sub-nanometre resolution of atomic motion during electronic excitation
  in phase-change materials","8 pages, 4 figures","Scientific Reports Vol.6, 20633 (2016)","10.1038/srep20633",,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  Phase-change materials based on Ge-Sb-Te alloys are widely used in industrial
applications such as nonvolatile memories, but reaction pathways for
crystalline-to-amorphous phase-change on picosecond timescales remain unknown.
Femtosecond laser excitation and an ultrashort x-ray probe is used to show the
temporal separation of electronic and thermal effects in a long-lived ($>$100
ps) transient metastable state of Ge$_{2}$Sb$_{2}$Te$_{5}$ with muted
interatomic interaction induced by a weakening of resonant bonding. Due to a
specific electronic state, the lattice undergoes a reversible nondestructive
modification over a nanoscale region, remaining cold for 4 ps. An independent
time-resolved x-ray absorption fine structure experiment confirms the existence
of an intermediate state with disordered bonds. This newly unveiled effect
allows the utilization of non-thermal ultra-fast pathways enabling artificial
manipulation of the switching process, ultimately leading to a redefined speed
limit, and improved energy efficiency and reliability of phase-change memory
technologies.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 08:19:45 GMT""}]","2017-05-29"
"1705.09473","Andrea Tassi","Suzie Brown, Oliver Johnson, Andrea Tassi","Reliability of Broadcast Communications Under Sparse Random Linear
  Network Coding","Accepted for publication on IEEE Transactions on Vehicular Technology","IEEE Transactions on Vehicular Technology, vol 67/5, 2018, pages
  4677-4682","10.1109/TVT.2018.2790436",,"cs.IT cs.PF math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Ultra-reliable Point-to-Multipoint (PtM) communications are expected to
become pivotal in networks offering future dependable services for smart
cities. In this regard, sparse Random Linear Network Coding (RLNC) techniques
have been widely employed to provide an efficient way to improve the
reliability of broadcast and multicast data streams. This paper addresses the
pressing concern of providing a tight approximation to the probability of a
user recovering a data stream protected by this kind of coding technique. In
particular, by exploiting the Stein--Chen method, we provide a novel and
general performance framework applicable to any combination of system and
service parameters, such as finite field sizes, lengths of the data stream and
level of sparsity. The deviation of the proposed approximation from Monte Carlo
simulations is negligible, improving significantly on the state of the art
performance bounds.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 08:21:00 GMT""},{""version"":""v2"",""created"":""Wed, 1 Nov 2017 10:14:04 GMT""},{""version"":""v3"",""created"":""Thu, 4 Jan 2018 10:00:46 GMT""},{""version"":""v4"",""created"":""Thu, 18 Oct 2018 09:53:37 GMT""}]","2019-01-30"
"1705.09474","Donghui Wang","Yanan Li, Donghui Wang","Zero-Shot Learning with Generative Latent Prototype Model","This work was completed in Oct, 2016",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Zero-shot learning, which studies the problem of object classification for
categories for which we have no training examples, is gaining increasing
attention from community. Most existing ZSL methods exploit deterministic
transfer learning via an in-between semantic embedding space. In this paper, we
try to attack this problem from a generative probabilistic modelling
perspective. We assume for any category, the observed representation, e.g.
images or texts, is developed from a unique prototype in a latent space, in
which the semantic relationship among prototypes is encoded via linear
reconstruction. Taking advantage of this assumption, virtual instances of
unseen classes can be generated from the corresponding prototype, giving rise
to a novel ZSL model which can alleviate the domain shift problem existing in
the way of direct transfer learning. Extensive experiments on three benchmark
datasets show our proposed model can achieve state-of-the-art results.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 08:22:13 GMT""}]","2017-05-29"
"1705.09475","Adam Kabela","Adam Kabela","An update on non-Hamiltonian $\frac{5}{4}$-tough maximal planar graphs",,,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Studying the shortness of longest cycles in maximal planar graphs, we improve
the upper bound on the shortness exponent of the class of $\frac{5}{4}$-tough
maximal planar graphs presented by Harant and Owens [Discrete Math. 147 (1995),
301--305]. In addition, we present two generalizations of a similar result of
Tk\'{a}\v{c} who considered $1$-tough maximal planar graphs [Discrete Math. 154
(1996), 321--328]; we remark that one of these generalizations gives a tight
upper bound. We fix a problematic argument used in the first paper.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 08:28:10 GMT""},{""version"":""v2"",""created"":""Mon, 30 Oct 2017 15:59:40 GMT""},{""version"":""v3"",""created"":""Fri, 26 Oct 2018 12:19:04 GMT""}]","2018-10-29"
"1705.09476","Donghui Wang","Yanan Li, Donghui Wang","Learning Robust Features with Incremental Auto-Encoders","This work was completed in Feb, 2015",,,,"cs.LG cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Automatically learning features, especially robust features, has attracted
much attention in the machine learning community. In this paper, we propose a
new method to learn non-linear robust features by taking advantage of the data
manifold structure. We first follow the commonly used trick of the trade, that
is learning robust features with artificially corrupted data, which are
training samples with manually injected noise. Following the idea of the
auto-encoder, we first assume features should contain much information to well
reconstruct the input from its corrupted copies. However, merely reconstructing
clean input from its noisy copies could make data manifold in the feature space
noisy. To address this problem, we propose a new method, called Incremental
Auto-Encoders, to iteratively denoise the extracted features. We assume the
noisy manifold structure is caused by a diffusion process. Consequently, we
reverse this specific diffusion process to further contract this noisy
manifold, which results in an incremental optimization of model parameters .
Furthermore, we show these learned non-linear features can be stacked into a
hierarchy of features. Experimental results on real-world datasets demonstrate
the proposed method can achieve better classification performances.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 08:30:41 GMT""}]","2017-05-29"
"1705.09477","Yueling Yang","Junfeng Sun, Yueling Yang, Na Wang, Qin Chang, Gongru Lu","Possibility of searching for $B_{c}^{\ast}$ ${\to}$ $B_{u,d,s}V$,
  $B_{u,d,s}P$ decays","19 pages, revtex","Phys. Rev. D 95, 074032 (2017)","10.1103/PhysRevD.95.074032",,"hep-ph hep-ex","http://creativecommons.org/licenses/by/4.0/","  The $B_{c}^{\ast}$ ${\to}$ $B_{u,d,s}V$, $B_{u,d,s}P$ decays are investigated
with the QCD factorization approach, where $V$ and $P$ denote the ground
$SU(3)$ vector and pseudoscalar mesons, respectively. The $B_{c}^{\ast}$
${\to}$ $B_{u,d,s}$ transition form factors are calculated with the
Wirbel-Stech-Bauer model. It is found that branching ratios for the
color-favored and Cabibbo-favored $B_{c}^{\ast}$ ${\to}$ $B_{s}{\rho}$,
$B_{s}{\pi}$ decays can reach up to ${\cal O}(10^{-7})$, which might be
measurable in the future LHC experiments.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 08:32:11 GMT""}]","2017-05-29"
"1705.09478","Pei Sun","Pei Sun, Fakai Wen, Kun Hao, Junpeng Cao, Guang-Liang Li, Wen-Li Yang
  and Kangjie Shi","On the Bethe states of the one-dimensional supersymmetric t-J model with
  generic open boundaries","17 pages, 2 tables, published version","JHEP07(2017)051","10.1007/JHEP07(2017)051",,"math-ph cond-mat.str-el math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  By combining the algebraic Bethe ansatz and the off-diagonal Bethe ansatz, we
investigate the supersymmetric t-J model with generic open boundaries. The
eigenvalues of the transfer matrix are given in terms of an inhomogeneous T-Q
relation, and the corresponding eigenstates are expressed in terms of nested
Bethe states which have well-defined homogeneous limit. This exact solution
provides basis for further analyzing the thermodynamic properties and
correlation functions of the model.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 08:52:34 GMT""},{""version"":""v2"",""created"":""Wed, 31 May 2017 13:59:56 GMT""},{""version"":""v3"",""created"":""Wed, 12 Jul 2017 15:21:53 GMT""}]","2017-07-13"
"1705.09479","Ruben Gomez-Ojeda","Ruben Gomez-Ojeda, David Zu\~niga-No\""el, Francisco-Angel Moreno,
  Davide Scaramuzza, and Javier Gonzalez-Jimenez","PL-SLAM: a Stereo SLAM System through the Combination of Points and Line
  Segments",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Traditional approaches to stereo visual SLAM rely on point features to
estimate the camera trajectory and build a map of the environment. In
low-textured environments, though, it is often difficult to find a sufficient
number of reliable point features and, as a consequence, the performance of
such algorithms degrades. This paper proposes PL-SLAM, a stereo visual SLAM
system that combines both points and line segments to work robustly in a wider
variety of scenarios, particularly in those where point features are scarce or
not well-distributed in the image. PL-SLAM leverages both points and segments
at all the instances of the process: visual odometry, keyframe selection,
bundle adjustment, etc. We contribute also with a loop closure procedure
through a novel bag-of-words approach that exploits the combined descriptive
power of the two kinds of features. Additionally, the resulting map is richer
and more diverse in 3D elements, which can be exploited to infer valuable,
high-level scene structures like planes, empty spaces, ground plane, etc. (not
addressed in this work). Our proposal has been tested with several popular
datasets (such as KITTI and EuRoC), and is compared to state of the art methods
like ORB-SLAM, revealing a more robust performance in most of the experiments,
while still running in real-time. An open source version of the PL-SLAM C++
code will be released for the benefit of the community.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 08:52:38 GMT""},{""version"":""v2"",""created"":""Mon, 9 Apr 2018 11:28:52 GMT""}]","2018-04-10"
"1705.09480","Sergey Basalaev","S. G. Basalaev","Privileged coordinates for Carnot-Carath\'eodory spaces of low
  smoothness","19 pages",,,,"math.MG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We describe classes of coordinate systems in Carnot-Carath\'eodory spaces of
low smoothness which allow for homogeneous approximations of quasimetrics and
basis vector fields. We establish the minimal smoothness required for these
classes to coinside with the class of the privileged coordinates described
earlier for the smooth case. We also apply these results to prove partial
analogues of existing results in the canonical coordinates of the 2nd kind. As
a geometric tool we prove some convergence theorems in quasimetric spaces.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 08:53:41 GMT""}]","2017-05-29"
"1705.09481","Diego Gonzalez-Diaz","C.D.R. Azevedo, D. Gonzalez-Diaz, S. F. Biagi, C.A.B. Oliveira, C.A.O.
  Henriques, J. Escada, F. Monrabal, J.J. G\'omez-Cadenas, V. \'Alvarez, J. M.
  Benlloch-Rodr\'iguez F.I.G.M. Borges, A. Botas, S. C\'arcel, J. V. Carri\'on,
  S. Cebri\'an, C.A.N. Conde, J. D\'iaz, M. Diesburg, R. Esteve, R. Felkai,
  L.M.P. Fernandes, P. Ferrario, A.L. Ferreira, E.D.C. Freitas, A. Goldschmidt,
  R.M. Guti\'errez, J. Hauptman, A. I. Hernandez, J.A. Hernando Morata, V.
  Herrero, B.J.P. Jones, L. Labarga, A. Laing, P. Lebrun, I. Liubarsky, N.
  Lopez-March, M. Losada, J. Mart\'in-Albo, A. Mart\'inez, A. D. McDonald,
  C.M.B. Monteiro, F.J. Mora, L.M. Moutinho, J. Mu\~noz Vidal, M. Musti, M.
  Nebot-Guinot, P. Novella, D. Nygren, B. Palmeiro, A. Para, J. P\'erez, M.
  Querol, J. Renner, L. Ripoll, J. Rodr\'iguez, L. Rogers, F.P. Santos, J.M.F.
  dos Santos, L. Serra, D. Shuman, A. Sim\'on, C. Sofka, M. Sorel, T. Stiegler,
  J.F. Toledo, J. Torrent, Z. Tsamalaidze, J.F.C.A. Veloso, R. Webb, J.T.
  White, N. Yahlali","Microscopic simulation of xenon-based optical TPCs in the presence of
  molecular additives",,,"10.1016/j.nima.2017.08.049",,"physics.ins-det","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce a simulation framework for the transport of high and low energy
electrons in xenon-based gaseous optical time projection chambers (OTPCs). The
simulation relies on elementary cross sections (electron-atom and
electron-molecule) and incorporates, in order to compute the gas scintillation,
the reaction/quenching rates (atom-atom and atom-molecule) of the first 41
excited states of xenon and the relevant associated excimers, together with
their radiative cascade. The results compare positively with observations made
in pure xenon and its mixtures with CO$_2$ and CF$_4$ in a range of pressures
from 0.1 to 10~bar. This work sheds some light on the elementary processes
responsible for the primary and secondary xenon-scintillation mechanisms in the
presence of additives, that are of interest to the OTPC technology.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 08:53:49 GMT""},{""version"":""v2"",""created"":""Sat, 1 Jul 2017 14:03:23 GMT""}]","2018-03-14"
"1705.09482","Guy Louchard","Guy Louchard","A refined and asymptotic analysis of optimal stopping problems of Bruss
  and Weber","22 pages, 19 figures",,,,"cs.PF","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The classical secretary problem has been generalized over the years into
several directions. In this paper we confine our interest to those
generalizations which have to do with the more general problem of stopping on a
last observation of a specific kind. We follow Dendievel, (where a bibliography
can be found) who studies several types of such problems, mainly initiated by
Bruss and Weber. Whether in discrete time or continuous time, whether all
parameters are known or must be sequentially estimated, we shall call such
problems simply ""Bruss-Weber problems"". Our contribution in the present paper
is a refined analysis of several problems in this class and a study of the
asymptotic behaviour of solutions.
  The problems we consider center around the following model. Let
$X_1,X_2,\ldots,X_n$ be a sequence of independent random variables which can
take three values: $\{+1,-1,0\}.$ Let $p:=\P(X_i=1), p':=\P(X_i=-1),
\qt:=\P(X_i=0), p\geq p'$, where $p+p'+\qt=1$. The goal is to maximize the
probability of stopping on a value $+1$ or $-1$ appearing for the last time in
the sequence. Following a suggestion by Bruss, we have also analyzed an
x-strategy with incomplete information: the cases $p$ known, $n$ unknown, then
$n$ known, $p$ unknown and finally $n,p$ unknown are considered. We also
present simulations of the corresponding complete selection algorithm.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 08:58:29 GMT""}]","2017-05-29"
"1705.09483","Scientific Information Service CERN","R.B. Appleby, R. Barlow, A. Bertarelli, R. Bruce, F. Carra, F.
  Cerutti, L. Esposito, A. Faus-Golfe, H. Garcia Morales, L. Gentini, S. M.
  Gibson, P. Gradassi, J.M. Jowett, R. Kwee-Hinzmann, L. Lari, A. Lechner, T.
  Markiewicz, A. Marsili, J. Molson, L.J. Nevay, E. Quaranta, H. Rafique, S.
  Redaelli, M. Serluca, E. Skordis, G. Stancari, G. Steele and A. Toader","Collimation System","22 pages, chapter 5 in High-Luminosity Large Hadron Collider (HL-LHC)
  : Preliminary Design Report","CERN Yellow Report CERN 2015-005, pp.109-130","10.5170/CERN-2015-005.109",,"physics.acc-ph","http://creativecommons.org/licenses/by/4.0/","  Chapter 5 in High-Luminosity Large Hadron Collider (HL-LHC) : Preliminary
Design Report. The Large Hadron Collider (LHC) is one of the largest scientific
instruments ever built. Since opening up a new energy frontier for exploration
in 2010, it has gathered a global user community of about 7,000 scientists
working in fundamental particle physics and the physics of hadronic matter at
extreme temperature and density. To sustain and extend its discovery potential,
the LHC will need a major upgrade in the 2020s. This will increase its
luminosity (rate of collisions) by a factor of five beyond the original design
value and the integrated luminosity (total collisions created) by a factor ten.
The LHC is already a highly complex and exquisitely optimised machine so this
upgrade must be carefully conceived and will require about ten years to
implement. The new configuration, known as High Luminosity LHC (HL-LHC), will
rely on a number of key innovations that push accelerator technology beyond its
present limits. Among these are cutting-edge 11-12 tesla superconducting
magnets, compact superconducting cavities for beam rotation with ultra-precise
phase control, new technology and physical processes for beam collimation and
300 metre-long high-power superconducting links with negligible energy
dissipation. The present document describes the technologies and components
that will be used to realise the project and is intended to serve as the basis
for the detailed engineering design of HL-LHC.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 08:59:55 GMT""}]","2017-05-29"
"1705.09484","Gulsemay Y{\i}g{\i}t","G\""ulsemay Y{\i}g{\i}t and Mustafa Bayram","Chebyshev Differential Quadrature for Numerical Solutions of Higher
  Order Singular Perturbation Problems",,,,,"math.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this study linear and nonlinear higher order singularly perturbed problems
are examined by a numerical approach, the differential quadrature method. Here,
the main idea is using Chebyshev polynomials to acquire the weighting
coefficient matrix which is necessary to get numerical results. Following this,
different class of perturbation problems are considered as test problems. Then,
all results are shown in tables and also comparison between numerical and exact
solution shows the accuracy and effectiveness of the presented method.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 09:03:27 GMT""}]","2017-05-29"
"1705.09485","Robert Griffiths Professor","Robert C. Griffiths and Simon Tavar\'e","Ancestral inference from haplotypes and mutations",,,,,"math.ST q-bio.PE stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider inference about the history of a sample of DNA sequences,
conditional upon the haplotype counts and the number of segregating sites
observed at the present time. After deriving some theoretical results in the
coalescent setting, we implement rejection sampling and importance sampling
schemes to perform the inference. The importance sampling scheme addresses an
extension of the Ewens Sampling Formula for a configuration of haplotypes and
the number of segregating sites in the sample. The implementations include both
constant and variable population size models. The methods are illustrated by
two human Y chromosome data sets.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 09:03:30 GMT""},{""version"":""v2"",""created"":""Wed, 28 Feb 2018 17:48:00 GMT""}]","2018-03-01"
"1705.09486","Scientific Information Service CERN","A. Ballarino, J.P. Burnet, D. Ramos, U. Wagner, S. Weisz and Y. Yang","Cold Powering","16 pages, chapter 6 in High-Luminosity Large Hadron Collider (HL-LHC)
  : Preliminary Design Report","CERN Yellow Report CERN 2015-005, pp.131-146","10.5170/CERN-2015-005.131",,"physics.acc-ph","http://creativecommons.org/licenses/by/4.0/","  Chapter 6 in High-Luminosity Large Hadron Collider (HL-LHC) : Preliminary
Design Report. The Large Hadron Collider (LHC) is one of the largest scientific
instruments ever built. Since opening up a new energy frontier for exploration
in 2010, it has gathered a global user community of about 7,000 scientists
working in fundamental particle physics and the physics of hadronic matter at
extreme temperature and density. To sustain and extend its discovery potential,
the LHC will need a major upgrade in the 2020s. This will increase its
luminosity (rate of collisions) by a factor of five beyond the original design
value and the integrated luminosity (total collisions created) by a factor ten.
The LHC is already a highly complex and exquisitely optimised machine so this
upgrade must be carefully conceived and will require about ten years to
implement. The new configuration, known as High Luminosity LHC (HL-LHC), will
rely on a number of key innovations that push accelerator technology beyond its
present limits. Among these are cutting-edge 11-12 tesla superconducting
magnets, compact superconducting cavities for beam rotation with ultra-precise
phase control, new technology and physical processes for beam collimation and
300 metre-long high-power superconducting links with negligible energy
dissipation. The present document describes the technologies and components
that will be used to realise the project and is intended to serve as the basis
for the detailed engineering design of HL-LHC.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 09:05:19 GMT""}]","2017-05-29"
"1705.09487","Minjun Choi","M. J. Choi (1), J. Kim (1), J.-M. Kwon (1), H. K. Park (1 and 2), Y.
  In (1), W. Lee (1), K. D. Lee (1), G. S. Yun (3), J. Lee (2), M. Kim (2),
  W.-H. Ko (1), J. H. Lee (1), Y. S. Park (4), Y.-S. Na (5), N. C. Luhmann Jr
  (6), B. H. Park (1) ((1) National Fusion Research Institute, (2) Ulsan
  National Institute of Science and Technology, (3) Pohang University of
  Science and Technology, (4) Columbia University, (5) Seoul National
  University, (6) University of California at Davis)","Multiscale interaction between a large scale magnetic island and small
  scale turbulence","15 pages, 6 figures","Nucl. Fusion 57 (2017) 126058 (7pp)","10.1088/1741-4326/aa86fe",,"physics.plasm-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Multiscale interaction between the magnetic island and turbulence has been
demonstrated through simultaneous two-dimensional measurements of turbulence
and temperature and flow profiles. The magnetic island and turbulence mutually
interact via the coupling between the electron temperature ($T_e$) gradient,
the $T_e$ turbulence, and the poloidal flow. The $T_e$ gradient altered by the
magnetic island is peaked outside and flattened inside the island. The $T_e$
turbulence can appear in the increased $T_e$ gradient regions. The combined
effects of the $T_e$ gradient and the the poloidal flow shear determine
two-dimensional distribution of the $T_e$ turbulence. When the reversed
poloidal flow forms, it can maintain the steepest $T_e$ gradient and the
magnetic island acts more like a electron heat transport barrier.
Interestingly, when the $T_e$ gradient, the $T_e$ turbulence, and the flow
shear increase beyond critical levels, the magnetic island turns into a fast
electron heat transport channel, which directly leads to the minor disruption.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 09:06:45 GMT""},{""version"":""v2"",""created"":""Fri, 3 Nov 2017 05:12:57 GMT""}]","2017-11-22"
"1705.09488","Lan Truong","Lan V. Truong","Performance of Viterbi Decoding with and without ARQ on Rician Fading
  Channels","Accepted to IEEE Transactions on Communications in Sept. 2018",,,,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we investigate the performance of the Viterbi decoding
algorithm with/without Automatic Repeat reQuest (ARQ) over a Rician flat fading
channel with unlimited interleaving. We show that the decay rate of the average
bit error probability with respect to the bit energy to noise ratio is at least
equal to $d_f$ at high bit energy to noise ratio for both cases (with ARQ and
without ARQ), where $d_f$ is the free distance of the convolutional code. The
Yamamoto-Itoh flag helps to reduce the average bit error probability by a
factor of $4^{d_f}$ with a negligible retransmission rate. We also prove an
interesting result that the average bit error probability decays exponentially
fast with respect to the Rician factor for any fixed bit energy per noise
ratio. In addition, the average bit error exponent with respect to the Rician
factor is shown to be $d_f$.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 09:07:34 GMT""},{""version"":""v2"",""created"":""Wed, 31 May 2017 21:31:06 GMT""},{""version"":""v3"",""created"":""Fri, 12 Jan 2018 11:49:18 GMT""},{""version"":""v4"",""created"":""Wed, 16 May 2018 10:59:57 GMT""},{""version"":""v5"",""created"":""Thu, 4 Oct 2018 03:49:34 GMT""}]","2018-10-05"
"1705.09489","Scientific Information Service CERN","A. Apollonio, T. Baer, K. Dahlerup-Petersen, R. Denz, I. Romera
  Ramirez, R. Schmidt, A. Siemko, J. Wenninger, D. Wollmann and M. Zerlauth","Machine Protection, Interlocks and Availability","10 pages, chapter 7 in High-Luminosity Large Hadron Collider (HL-LHC)
  : Preliminary Design Report","CERN Yellow Report CERN 2015-005, pp. 147-156","10.5170/CERN-2015-005.147",,"physics.acc-ph","http://creativecommons.org/licenses/by/4.0/","  Chapter 7 in High-Luminosity Large Hadron Collider (HL-LHC) : Preliminary
Design Report. The Large Hadron Collider (LHC) is one of the largest scientific
instruments ever built. Since opening up a new energy frontier for exploration
in 2010, it has gathered a global user community of about 7,000 scientists
working in fundamental particle physics and the physics of hadronic matter at
extreme temperature and density. To sustain and extend its discovery potential,
the LHC will need a major upgrade in the 2020s. This will increase its
luminosity (rate of collisions) by a factor of five beyond the original design
value and the integrated luminosity (total collisions created) by a factor ten.
The LHC is already a highly complex and exquisitely optimised machine so this
upgrade must be carefully conceived and will require about ten years to
implement. The new configuration, known as High Luminosity LHC (HL-LHC), will
rely on a number of key innovations that push accelerator technology beyond its
present limits. Among these are cutting-edge 11-12 tesla superconducting
magnets, compact superconducting cavities for beam rotation with ultra-precise
phase control, new technology and physical processes for beam collimation and
300 metre-long high-power superconducting links with negligible energy
dissipation. The present document describes the technologies and components
that will be used to realise the project and is intended to serve as the basis
for the detailed engineering design of HL-LHC.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 09:10:52 GMT""}]","2017-05-29"
"1705.09490","Xiang-Hua Zhai","Xiang-hua Zhai, Rui-hui Lin, Chao-jun Feng, and Xin-zhou Li","Action functional of the Cardassian universe","7 pages, 3 figures","Physical Review D 95, 104030 (2017)","10.1103/PhysRevD.95.104030",,"gr-qc astro-ph.CO hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It is known that the Cardassian universe is successful in describing the
accelerated expansion of the universe, but its dynamical equations are hard to
get from the action principle. In this paper, we establish the connection
between the Cardassian universe and $f(T, \mathcal{T})$ gravity, where $T$ is
the torsion scalar and $\mathcal{T}$ is the trace of the matter energy-momentum
tensor. For dust matter, we find that the modified Friedmann equations from
$f(T, \mathcal{T})$ gravity can correspond to those of Cardassian models, and
thus, a possible origin of Cardassian universe is given. We obtain the original
Cardassian model, the modified polytropic Cardassian model, and the exponential
Cardassian model from the Lagrangians of $f(T,\mathcal{T})$ theory.
Furthermore, by adding an additional term to the corresponding Lagrangians, we
give three generalized Cardassian models from $f(T,\mathcal{T})$ theory. Using
the observation data of type Ia supernovae, cosmic microwave background
radiation, and baryon acoustic oscillations, we get the fitting results of the
cosmological parameters and give constraints of model parameters for all of
these models.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 09:13:54 GMT""}]","2017-05-31"
"1705.09491","Angelo Lucia","Michael J. Kastoryano and Angelo Lucia","Divide and conquer method for proving gaps of frustration free
  Hamiltonians","This is an author-created, un-copyedited version of an article
  accepted for publication/published in Journal of Statistical Mechanics:
  Theory and Experiment. IOP Publishing Ltd is not responsible for any errors
  or omissions in this version of the manuscript or any version derived from
  it. The Version of Record is available online at
  http://dx.doi.org/10.1088/1742-5468/aaa793, Journal of Statistical Mechanics:
  Theory and Experiment, March 2018","Journal of Statistical Mechanics: Theory and Experiment, Volume
  2018, March 2018","10.1088/1742-5468/aaa793",,"math-ph math.MP quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Providing system-size independent lower bounds on the spectral gap of local
Hamiltonian is in general a hard problem. For the case of finite-range,
frustration free Hamiltonians on a spin lattice of arbitrary dimension, we show
that a property of the ground state space is sufficient to obtain such a bound.
We furthermore show that such a condition is necessary and equivalent to a
constant spectral gap. Thanks to this equivalence, we can prove that for
gapless models in any dimension, the spectral gap on regions of diameter $n$ is
at most $o\left(\frac{\log(n)^{2+\epsilon}}{n}\right)$ for any positive
$\epsilon$.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 09:17:25 GMT""},{""version"":""v2"",""created"":""Sun, 29 Apr 2018 18:36:46 GMT""}]","2019-08-29"
"1705.09492","Scientific Information Service CERN","H. Burkhardt and I. Efthymiopoulos","Interface with Experiments","4 pages, chapter 8 in High-Luminosity Large Hadron Collider (HL-LHC)
  : Preliminary Design Report","CERN Yellow Report CERN 2015-005, pp.157-160","10.5170/CERN-2015-005.157",,"physics.acc-ph","http://creativecommons.org/licenses/by/4.0/","  Chapter 8 in High-Luminosity Large Hadron Collider (HL-LHC) : Preliminary
Design Report. The Large Hadron Collider (LHC) is one of the largest scientific
instruments ever built. Since opening up a new energy frontier for exploration
in 2010, it has gathered a global user community of about 7,000 scientists
working in fundamental particle physics and the physics of hadronic matter at
extreme temperature and density. To sustain and extend its discovery potential,
the LHC will need a major upgrade in the 2020s. This will increase its
luminosity (rate of collisions) by a factor of five beyond the original design
value and the integrated luminosity (total collisions created) by a factor ten.
The LHC is already a highly complex and exquisitely optimised machine so this
upgrade must be carefully conceived and will require about ten years to
implement. The new configuration, known as High Luminosity LHC (HL-LHC), will
rely on a number of key innovations that push accelerator technology beyond its
present limits. Among these are cutting-edge 11-12 tesla superconducting
magnets, compact superconducting cavities for beam rotation with ultra-precise
phase control, new technology and physical processes for beam collimation and
300 metre-long high-power superconducting links with negligible energy
dissipation. The present document describes the technologies and components
that will be used to realise the project and is intended to serve as the basis
for the detailed engineering design of HL-LHC.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 09:18:40 GMT""}]","2017-05-29"
"1705.09493","Xizheng Zhang","X. Z. Zhang, L. Jin, and Z. Song","Non-Hermitian description of the dynamics of inter-chain pair tunnelling","10 pages, 4 figures","Phys. Rev. A 95, 052122 (2017)","10.1103/PhysRevA.95.052122",,"cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study inter-chain pair tunnelling dynamics based on an exact two-particle
solution for a two-leg ladder. We show that the Hermitian Hamiltonian shares a
common two-particle eigenstate with a corresponding non-Hermitian Hubbard
Hamiltonian in which the non-Hermiticity arises from an on-site interaction of
imaginary strength. Our results provides that the dynamic processes of
two-particle collision and across-legs tunnelling are well described by the
effective non-Hermitian Hubbard Hamiltonian based on the eigenstate
equivalence. We also find that any common eigenstate is always associated with
the emergence of spectral singularity in the non-Hermitian Hubbard model. This
result is valid for both Bose and Fermi systems and provides a clear physical
implication of the non-Hermitian Hubbard model.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 09:19:10 GMT""}]","2017-05-29"
"1705.09494","Thomas Fung","Thomas Fung and Eugene Seneta","Quantile function expansion using regularly varying functions","20 pages",,,,"math.ST stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a simple result that allows us to evaluate the asymptotic order of
the remainder of a partial asymptotic expansion of the quantile function $h(u)$
as $u\to 0^+$ or $1^-$. This is focussed on important univariate distributions
when $h(\cdot)$ has no simple closed form, with a view to assessing asymptotic
rate of decay to zero of tail dependence in the context of bivariate copulas.
The Introduction motivates the study in terms of the standard Normal. The
Normal, Skew-Normal and Gamma are used as initial examples. Finally, we discuss
approximation to the lower quantile of the Variance-Gamma and Skew-Slash
distributions.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 09:22:57 GMT""},{""version"":""v2"",""created"":""Wed, 9 Aug 2017 11:16:51 GMT""}]","2017-08-10"
"1705.09495","Stefan Muff","Stefan Muff, Mauro Fanciulli, Andrew P. Weber, Nicolas Pilet, Zoran
  Ristic, Zhiming Wang, Nicholas C. Plumb, Milan Radovic, J. Hugo Dil","Observation of a two-dimensional electron gas at CaTiO$_3$ film surfaces",,,"10.1016/j.apsusc.2017.05.229",,"cond-mat.mes-hall physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The two-dimensional electron gas at the surface of titanates gathered
attention due to its potential to replace conventional silicon based
semiconductors in the future. In this study, we investigated films of the
parent perovskite CaTiO$_3$, grown by pulsed laser deposition, by means of
angular-resolved photoelectron spectroscopy. The films show a c(4x2) surface
reconstruction after the growth that is reduced to a p(2x2) reconstruction
under UV-light. At the CaTiO$_3$ film surface, a two-dimensional electron gas
(2DEG) is found with an occupied band width of 400 meV. With our findings
CaTiO$_3$ is added to the group of oxides with a 2DEG at their surface. Our
study widens the phase space to investigate strontium and barium doped
CaTiO$_3$ and the interplay of ferroelectric properties with the 2DEG at oxide
surfaces. This could open up new paths to tailor two-dimensional transport
properties of these systems towards possible applications.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 09:26:01 GMT""}]","2017-08-08"
"1705.09496","Giacomo Beccari","G. Beccari, M.G. Petr-Gotzens, H.M.J. Boffin, M. Romaniello, D.
  Fedele, G. Carraro, G. De Marchi, W.-J. de Wit, J.E. Drew, V.M. Kalari, C.F.
  Manara, E.L. Martin, S. Mieske, N. Panagia, L. Testi, J.S. Vink, J.R. Walsh,
  N.J. Wright","A Tale of Three Cities: OmegaCAM discovers multiple sequences in the
  color-magnitude diagram of the Orion Nebula Cluster","A&A in print","A&A 604, A22 (2017)","10.1051/0004-6361/201730432",,"astro-ph.SR astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  As part of the Accretion Discs in H$\alpha$ with OmegaCAM (ADHOC) survey, we
imaged in r, i and H-alpha a region of 12x8 square degrees around the Orion
Nebula Cluster. Thanks to the high-quality photometry obtained, we discovered
three well-separated pre-main sequences in the color-magnitude diagram. The
populations are all concentrated towards the cluster's center. Although several
explanations can be invoked to explain these sequences we are left with two
competitive, but intriguing, scenarios: a population of unresolved binaries
with an exotic mass ratio distribution or three populations with different
ages. Independent high-resolution spectroscopy supports the presence of
discrete episodes of star formation, each separated by about a million years.
The stars from the two putative youngest populations rotate faster than the
older ones, in agreement with the evolution of stellar rotation observed in
pre-main sequence stars younger than 4 Myr in several star forming regions.
Whatever the final explanation, our results prompt for a revised look at the
formation mode and early evolution of stars in clusters.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 09:29:53 GMT""}]","2017-08-02"
"1705.09497","Scientific Information Service CERN","M. Karppinen, S. Izquierdo Bermudez, A. Nobrega, H. Prin, D. Ramos, S.
  Redaelli, F. Savary, D. Smekens and A. Zlobin","11 T Dipole for the Dispersion Suppressor Collimators","8 pages, chapter 11 in High-Luminosity Large Hadron Collider (HL-LHC)
  : Preliminary Design Report","CERN Yellow Report CERN 2015-005, pp.187-194","10.5170/CERN-2015-005.187",,"physics.acc-ph","http://creativecommons.org/licenses/by/4.0/","  Chapter 11 in High-Luminosity Large Hadron Collider (HL-LHC) : Preliminary
Design Report. The Large Hadron Collider (LHC) is one of the largest scientific
instruments ever built. Since opening up a new energy frontier for exploration
in 2010, it has gathered a global user community of about 7,000 scientists
working in fundamental particle physics and the physics of hadronic matter at
extreme temperature and density. To sustain and extend its discovery potential,
the LHC will need a major upgrade in the 2020s. This will increase its
luminosity (rate of collisions) by a factor of five beyond the original design
value and the integrated luminosity (total collisions created) by a factor ten.
The LHC is already a highly complex and exquisitely optimised machine so this
upgrade must be carefully conceived and will require about ten years to
implement. The new configuration, known as High Luminosity LHC (HL-LHC), will
rely on a number of key innovations that push accelerator technology beyond its
present limits. Among these are cutting-edge 11-12 tesla superconducting
magnets, compact superconducting cavities for beam rotation with ultra-precise
phase control, new technology and physical processes for beam collimation and
300 metre-long high-power superconducting links with negligible energy
dissipation. The present document describes the technologies and components
that will be used to realise the project and is intended to serve as the basis
for the detailed engineering design of HL-LHC.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 09:31:07 GMT""}]","2017-05-29"
"1705.09498","Shota Ono","Shota Ono","Effect of one-dimensional superlattice potentials on the band gap of
  two-dimensional materials",,"J. Appl. Phys. 121, 204301 (2017)","10.1063/1.4984069",,"cond-mat.mes-hall cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Using the tight-binding approach, we analyze the effect of a one-dimensional
superlattice (1DSL) potential on the electronic structure of black phosphorene
and transition metal dichalcogenides. We observe that the 1DSL potential
results in a decrease of the energy band gap of the two-dimensional (2D)
materials. An analytical model is presented to relate the decrease in the
direct-band gap to the different orbital characters between the valence band
top and conduction band bottom of the 2D materials. The direct-to-indirect gap
transition, which occurs under a 1DSL potential with an unequal barrier width,
is also discussed.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 09:31:40 GMT""}]","2017-06-07"
"1705.09499","Scientific Information Service CERN","V. Baglin, P. Chiggiato, P. Cruikshank, M. Gallilee, C. Garion and R.
  Kersevan","Vacuum System","11 pages, chapter 12 in High-Luminosity Large Hadron Collider
  (HL-LHC) : Preliminary Design Report","CERN Yellow Report CERN 2015-005, pp.195-205","10.5170/CERN-2015-005.195",,"physics.acc-ph","http://creativecommons.org/licenses/by/4.0/","  Chapter 12 in High-Luminosity Large Hadron Collider (HL-LHC) : Preliminary
Design Report. The Large Hadron Collider (LHC) is one of the largest scientific
instruments ever built. Since opening up a new energy frontier for exploration
in 2010, it has gathered a global user community of about 7,000 scientists
working in fundamental particle physics and the physics of hadronic matter at
extreme temperature and density. To sustain and extend its discovery potential,
the LHC will need a major upgrade in the 2020s. This will increase its
luminosity (rate of collisions) by a factor of five beyond the original design
value and the integrated luminosity (total collisions created) by a factor ten.
The LHC is already a highly complex and exquisitely optimised machine so this
upgrade must be carefully conceived and will require about ten years to
implement. The new configuration, known as High Luminosity LHC (HL-LHC), will
rely on a number of key innovations that push accelerator technology beyond its
present limits. Among these are cutting-edge 11-12 tesla superconducting
magnets, compact superconducting cavities for beam rotation with ultra-precise
phase control, new technology and physical processes for beam collimation and
300 metre-long high-power superconducting links with negligible energy
dissipation. The present document describes the technologies and components
that will be used to realise the project and is intended to serve as the basis
for the detailed engineering design of HL-LHC.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 09:34:48 GMT""}]","2017-05-31"
"1705.09500","Jian Tang","Jian Tang and Yibing Zhang","Study of Non-Standard Charged-Current Interactions at the MOMENT
  experiment","14 pages, 5 figures. Matches the published version","Phys. Rev. D 97, 035018 (2018)","10.1103/PhysRevD.97.035018",,"hep-ph hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  MuOn-decay MEdium baseline NeuTrino beam experiment (MOMENT) is a
next-generation accelerator neutrino experiment looking for more physics study.
We try to simulate neutrino oscillations confronting with
Charged-Current\&Non-Standard neutrino Interactions(CC-NSIs) at MOMENT. These
NSIs could alter neutrino production and detection processes and get involved
in neutrino oscillation channels. We separate a perturbative discussion of
oscillation channels at near and far detectors, and analyze parameter
correlations with the impact of CC-NSIs. Taking $\delta_{cp}$ and $\theta_{23}$
as an example, we find that CC-NSIs can induce bias in precision measurements
of standard oscillation parameters. In addition, a combination of near and far
detectors using Gd-doped water cherenkov technology at MOMENT is able to
provide good constraints of CC-NSIs happening at the neutrino production and
detection processes.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 09:38:12 GMT""},{""version"":""v2"",""created"":""Wed, 22 Nov 2017 14:46:32 GMT""},{""version"":""v3"",""created"":""Thu, 1 Mar 2018 01:01:50 GMT""}]","2018-03-02"
"1705.09501","Scientific Information Service CERN","E. Bravin, B. Dehning, R. Jones, T. Lefevre and H. Schmickler","Beam Instrumentation and Long-Range Beam-Beam Compensation","14 pages, chapter 13 in High-Luminosity Large Hadron Collider
  (HL-LHC) : Preliminary Design Report","CERN Yellow Report CERN 2015-005, pp. 207-220","10.5170/CERN-2015-005.207",,"physics.acc-ph","http://creativecommons.org/licenses/by/4.0/","  Chapter 13 in High-Luminosity Large Hadron Collider (HL-LHC) : Preliminary
Design Report. The Large Hadron Collider (LHC) is one of the largest scientific
instruments ever built. Since opening up a new energy frontier for exploration
in 2010, it has gathered a global user community of about 7,000 scientists
working in fundamental particle physics and the physics of hadronic matter at
extreme temperature and density. To sustain and extend its discovery potential,
the LHC will need a major upgrade in the 2020s. This will increase its
luminosity (rate of collisions) by a factor of five beyond the original design
value and the integrated luminosity (total collisions created) by a factor ten.
The LHC is already a highly complex and exquisitely optimised machine so this
upgrade must be carefully conceived and will require about ten years to
implement. The new configuration, known as High Luminosity LHC (HL-LHC), will
rely on a number of key innovations that push accelerator technology beyond its
present limits. Among these are cutting-edge 11-12 tesla superconducting
magnets, compact superconducting cavities for beam rotation with ultra-precise
phase control, new technology and physical processes for beam collimation and
300 metre-long high-power superconducting links with negligible energy
dissipation. The present document describes the technologies and components
that will be used to realise the project and is intended to serve as the basis
for the detailed engineering design of HL-LHC.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 09:38:30 GMT""}]","2017-05-31"
"1705.09502","Scientific Information Service CERN","B. Goddard, A. Lechner and J. Uythoven","Injection and Dumping Systems","8 pages, chapter 14 in High-Luminosity Large Hadron Collider (HL-LHC)
  : Preliminary Design Report","CERN Yellow Report CERN 2015-005, pp.221-228","10.5170/CERN-2015-005.221",,"physics.acc-ph","http://creativecommons.org/licenses/by/4.0/","  Chapter 14 in High-Luminosity Large Hadron Collider (HL-LHC) : Preliminary
Design Report. The Large Hadron Collider (LHC) is one of the largest scientific
instruments ever built. Since opening up a new energy frontier for exploration
in 2010, it has gathered a global user community of about 7,000 scientists
working in fundamental particle physics and the physics of hadronic matter at
extreme temperature and density. To sustain and extend its discovery potential,
the LHC will need a major upgrade in the 2020s. This will increase its
luminosity (rate of collisions) by a factor of five beyond the original design
value and the integrated luminosity (total collisions created) by a factor ten.
The LHC is already a highly complex and exquisitely optimised machine so this
upgrade must be carefully conceived and will require about ten years to
implement. The new configuration, known as High Luminosity LHC (HL-LHC), will
rely on a number of key innovations that push accelerator technology beyond its
present limits. Among these are cutting-edge 11-12 tesla superconducting
magnets, compact superconducting cavities for beam rotation with ultra-precise
phase control, new technology and physical processes for beam collimation and
300 metre-long high-power superconducting links with negligible energy
dissipation. The present document describes the technologies and components
that will be used to realise the project and is intended to serve as the basis
for the detailed engineering design of HL-LHC.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 09:41:23 GMT""}]","2017-05-29"
"1705.09503","Scientific Information Service CERN","M. Lamont, M. Pojer and J.M. Jowett","Commissioning and Operation","12 pages, chapter 16 in High-Luminosity Large Hadron Collider
  (HL-LHC) : Preliminary Design Report","CERN Yellow Report CERN 2015-005, pp.237-248","10.5170/CERN-2015-005.237",,"physics.acc-ph","http://creativecommons.org/licenses/by/4.0/","  Chapter 16 in High-Luminosity Large Hadron Collider (HL-LHC) : Preliminary
Design Report. The Large Hadron Collider (LHC) is one of the largest scientific
instruments ever built. Since opening up a new energy frontier for exploration
in 2010, it has gathered a global user community of about 7,000 scientists
working in fundamental particle physics and the physics of hadronic matter at
extreme temperature and density. To sustain and extend its discovery potential,
the LHC will need a major upgrade in the 2020s. This will increase its
luminosity (rate of collisions) by a factor of five beyond the original design
value and the integrated luminosity (total collisions created) by a factor ten.
The LHC is already a highly complex and exquisitely optimised machine so this
upgrade must be carefully conceived and will require about ten years to
implement. The new configuration, known as High Luminosity LHC (HL-LHC), will
rely on a number of key innovations that push accelerator technology beyond its
present limits. Among these are cutting-edge 11-12 tesla superconducting
magnets, compact superconducting cavities for beam rotation with ultra-precise
phase control, new technology and physical processes for beam collimation and
300 metre-long high-power superconducting links with negligible energy
dissipation. The present document describes the technologies and components
that will be used to realise the project and is intended to serve as the basis
for the detailed engineering design of HL-LHC.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 09:47:48 GMT""}]","2017-05-29"
"1705.09504","Yuki Igarashi","Yuki Igarashi and Diptarama and Ryo Yoshinaka and Ayumi Shinohara","New Variants of Pattern Matching with Constants and Variables","15 pages, 2 figures",,,,"cs.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Given a text and a pattern over two types of symbols called constants and
variables, the parameterized pattern matching problem is to find all
occurrences of substrings of the text that the pattern matches by substituting
a variable in the text for each variable in the pattern, where the substitution
should be injective. The function matching problem is a variant of it that
lifts the injection constraint. In this paper, we discuss variants of those
problems, where one can substitute a constant or a variable for each variable
of the pattern. We give two kinds of algorithms for both problems, a
convolution-based method and an extended KMP-based method, and analyze their
complexity.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 09:55:38 GMT""}]","2017-05-29"
"1705.09505","Mathias Beiglboeck","Mathias Beiglboeck, Alexander Cox, Martin Huesmann","The geometry of multi-marginal Skorokhod Embedding",,,,,"math.PR q-fin.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Skorokhod Embedding Problem (SEP) is one of the classical problems in the
study of stochastic processes, with applications in many different fields (cf.~
the surveys \cite{Ob04,Ho11}). Many of these applications have natural
multi-marginal extensions leading to the \emph{(optimal) multi-marginal
Skorokhod problem} (MSEP). Some of the first papers to consider this problem
are \cite{Ho98b, BrHoRo01b, MaYo02}. However, this turns out to be difficult
using existing techniques: only recently a complete solution was be obtained in
\cite{CoObTo15} establishing an extension of the Root construction, while other
instances are only partially answered or remain wide open.
  In this paper, we extend the theory developed in \cite{BeCoHu14} to the
multi-marginal setup which is comparable to the extension of the optimal
transport problem to the multi-marginal optimal transport problem. As for the
one-marginal case, this viewpoint turns out to be very powerful. In particular,
we are able to show that all classical optimal embeddings have natural
multi-marginal counterparts. Notably these different constructions are linked
through a joint geometric structure and the classical solutions are recovered
as particular cases.
  Moreover, our results also have consequences for the study of the martingale
transport problem as well as the peacock problem.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 09:59:38 GMT""}]","2017-05-29"
"1705.09506","Masahiro Takeoka","Masahiro Takeoka, Kaushik P. Seshadreesan, Chenglong You, Shuro Izumi,
  Jonathan P. Dowling","Fundamental precision limit of a Mach-Zehnder interferometric sensor
  when one of the inputs is the vacuum","9 pages, 2 figures","Phys. Rev. A 96, 052118 (2017)","10.1103/PhysRevA.96.052118",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the lore of quantum metrology, one often hears (or reads) the following
no-go theorem: If you put vacuum into one input port of a balanced Mach-Zehnder
Interferometer, then no matter what you put into the other input port, and no
matter what your detection scheme, the sensitivity can never be better than the
shot noise limit (SNL). Often the proof of this theorem is cited to be in Ref.
[C. Caves, Phys. Rev. D 23, 1693 (1981)], but upon further inspection, no such
claim is made there. A quantum-Fisher-information-based argument suggestive of
this no-go theorem appears in Ref. [M. Lang and C. Caves, Phys. Rev. Lett. 111,
173601 (2013)], but is not stated in its full generality. Here we thoroughly
explore this no-go theorem and give the rigorous statement: the no-go theorem
holds whenever the unknown phase shift is split between both arms of the
interferometer, but remarkably does not hold when only one arm has the unknown
phase shift. In the latter scenario, we provide an explicit measurement
strategy that beats the SNL. We also point out that these two scenarios are
physically different and correspond to different types of sensing applications.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 10:00:16 GMT""}]","2017-11-22"
"1705.09507","Yauhen Yakimenka","Irina E. Bocharova, Boris D. Kudryashov, Vitaly Skachek and Yauhen
  Yakimenka","BP-LED decoding algorithm for LDPC codes over AWGN channels","Submitted to IEEE Transactions on Information Theory",,,,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A new method for low-complexity near-maximum-likelihood (ML) decoding of
low-density parity-check (LDPC) codes over the additive white Gaussian noise
channel is presented. The proposed method termed belief-propagation--list
erasure decoding (BP-LED) is based on erasing carefully chosen unreliable bits
performed in case of BP decoding failure. A strategy of introducing erasures
into the received vector and a new erasure decoding algorithm are proposed. The
new erasure decoding algorithm, called list erasure decoding, combines ML
decoding over the BEC with list decoding applied if the ML decoder fails to
find a unique solution. The asymptotic exponent of the average list size for
random regular LDPC codes from the Gallager ensemble is analyzed. Furthermore,
a few examples of regular and irregular quasi-cyclic LDPC codes of short and
moderate lengths are studied by simulations and their performance is compared
with the upper bound on the LDPC ensemble-average performance and the upper
bound on the average performance of random linear codes under ML decoding. A
comparison with the BP decoding performance of the WiMAX standard codes and
performance of the near-ML BEAST decoding are presented. The new algorithm is
applied to decoding a short nonbinary LDPC code over the extension of the
binary Galois field. The obtained simulation results are compared to the upper
bound on the ensemble-average performance of the binary image of regular
nonbinary LDPC codes.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 10:02:54 GMT""}]","2017-05-29"
"1705.09508","Victor Rohde","Andreas Basse-O'Connor, Jan Pedersen, and Victor Rohde","On infinite divisibility of a class of two-dimensional vectors in the
  second Wiener chaos",,,,,"math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Infinite divisibility of a class of two-dimensional vectors with components
in the second Wiener chaos is studied. Necessary and sufficient conditions for
infinite divisibility is presented as well as more easily verifiable sufficient
conditions. The case where both components consist of a sum of two Gaussian
squares is treated in more depth, and it is conjectured that such vectors are
infinitely divisible.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 10:03:42 GMT""}]","2017-05-29"
"1705.09509","Boris Barbour","Boris Barbour","Inverse sensitivity of plasmonic nanosensors at the single-molecule
  limit",,,,,"q-bio.QM physics.chem-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent work using plasmonic nanosensors in a clinically relevant detection
assay reports extreme sensitivity based upon a mechanism termed 'inverse
sensitivity', whereby reduction of substrate concentration increases reaction
rate, even at the single-molecule limit. This near-homoeopathic mechanism
contradicts the law of mass action. The assay involves deposition of silver
atoms upon gold nanostars, changing their absorption spectrum. Multiple
additional aspects of the assay appear to be incompatible with settled chemical
knowledge, in particular the detection of tiny numbers of silver atoms on a
background of the classic 'silver mirror reaction'. Finally, it is estimated
here that the reported spectral changes require some 2.5E11 times more silver
atoms than are likely to be produced. It is suggested that alternative
explanations must be sought for the original observations.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 10:06:10 GMT""},{""version"":""v2"",""created"":""Thu, 1 Jun 2017 19:59:07 GMT""}]","2017-06-05"
"1705.09510","Judith Croston","J.H. Croston, J. Ineson, M.J. Hardcastle and B. Mingo","A new method for finding and characterizing galaxy groups via
  low-frequency radio surveys","7 pages, 3 figures. Accepted for publication in MNRAS",,"10.1093/mnras/stx1347",,"astro-ph.GA astro-ph.CO astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We describe a new method for identifying and characterizing the thermodynamic
state of large samples of evolved galaxy groups at high redshifts using
high-resolution, low-frequency radio surveys, such as those that will be
carried out with LOFAR and the Square Kilometre Array (SKA). We identify a
sub-population of morphologically regular powerful (FRII) radio galaxies and
demonstrate that, for this sub-population, the internal pressure of the radio
lobes is a reliable tracer of the external intragroup/intracluster medium (ICM)
pressure, and that the assumption of a universal pressure profile for relaxed
groups enables the total mass and X-ray luminosity to be estimated. Using a
sample of well-studied FRII radio galaxies, we demonstrate that our method
enables the estimation of group/cluster X-ray luminosities over three orders of
magnitude in luminosity to within a factor of ~2 from low-frequency radio
properties alone. Our method could provide a powerful new tool for building
samples of thousands of evolved galaxy groups at z>1 and characterizing their
ICM.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 10:06:46 GMT""}]","2017-07-26"
"1705.09511","Marek Napiorkowski","Marek Napiorkowski and Jaroslaw Piasecki","Thermodynamic equivalence of two-dimensional imperfect attractive Fermi
  and repulsive Bose gases","5 pages, 1 figure","Phys. Rev. A 95, 063627 (2017)","10.1103/PhysRevA.95.063627",,"cond-mat.quant-gas cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider two-dimensional imperfect attractive Fermi and repulsive Bose
gases consisting of spinless point particles whose total interparticle
interaction energy is represented by $a N^2/2 V$ with $a=-a_{F}\leq 0$ for
fermions, and $a=a_{B}\geq 0$ for bosons. We show that in spite of the
attraction the thermodynamics of $d=2$ imperfect Fermi gas remains well defined
for $0 \leq a_{F}\leq a_{0}=h^2/2\pi m$, and is exactly the same as the one of
the repulsive imperfect Bose gas with $a_{B}=a_{0}-a_{F}$. In particular, for
$a_{F}=a_{0}$ one observes the thermodynamic equivalence of the attractive
imperfect Fermi gas and the ideal Bose gas.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 10:08:09 GMT""}]","2017-07-05"
"1705.09512","Scientific Information Service CERN","C. Adorisio, I. Bejar Alonso, J.C. Gascon, T. Otto and S. Roesler","Safety","8 pages, chapter 17 in High-Luminosity Large Hadron Collider (HL-LHC)
  : Preliminary Design Report","CERN Yellow Report CERN 2015-005, pp.249-256","10.5170/CERN-2015-005.249",,"physics.acc-ph","http://creativecommons.org/licenses/by/4.0/","  Chapter 17 in High-Luminosity Large Hadron Collider (HL-LHC) : Preliminary
Design Report. The Large Hadron Collider (LHC) is one of the largest scientific
instruments ever built. Since opening up a new energy frontier for exploration
in 2010, it has gathered a global user community of about 7,000 scientists
working in fundamental particle physics and the physics of hadronic matter at
extreme temperature and density. To sustain and extend its discovery potential,
the LHC will need a major upgrade in the 2020s. This will increase its
luminosity (rate of collisions) by a factor of five beyond the original design
value and the integrated luminosity (total collisions created) by a factor ten.
The LHC is already a highly complex and exquisitely optimised machine so this
upgrade must be carefully conceived and will require about ten years to
implement. The new configuration, known as High Luminosity LHC (HL-LHC), will
rely on a number of key innovations that push accelerator technology beyond its
present limits. Among these are cutting-edge 11-12 tesla superconducting
magnets, compact superconducting cavities for beam rotation with ultra-precise
phase control, new technology and physical processes for beam collimation and
300 metre-long high-power superconducting links with negligible energy
dissipation. The present document describes the technologies and components
that will be used to realise the project and is intended to serve as the basis
for the detailed engineering design of HL-LHC.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 10:28:38 GMT""}]","2017-05-29"
"1705.09513","Sennosuke Watanabe","Sennosuke Watanabe, Yuto Tozuka, Yoshihide Watanabe, Aito Yasuda and
  Masashi Iwasaki","Two characteristic polynomials corresponding to graphical networks over
  min-plus algebra","16 pages and one figure",,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we investigate characteristic polynomials of matrices in
min-plus algebra. Eigenvalues of min-plus matrices are known to be the minimum
roots of the characteristic polynomials based on tropical determinants which
are designed from emulating standard determinants. Moreover, minimum roots of
characteristic polynomials have a close relationship to graphs associated with
min-plus matrices consisting of vertices and directed edges with weights. The
literature has yet to focus on the other roots of min-plus characteristic
polynomials. Thus, here we consider how to relate the 2nd, 3rd,... minimum
roots of min-plus characteristic polynomials to graphical features. We then
define new characteristic polynomials of min-plus matrices by considering an
analogue of the Faddeev-LeVerrier algorithm that generates the characteristic
polynomials of linear matrices. We conclusively show that minimum roots of the
proposed characteristic polynomials coincide with min-plus eigenvalues, and
observe the other roots as in the study of the already known characteristic
polynomials. We also give an example to illustrate the difference between the
already known and proposed characteristic polynomials.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 10:29:34 GMT""}]","2017-05-29"
"1705.09514","Masaki Kawamoto","Masaki Kawamoto","Klein-Gordon equations with homogeneous time-dependent electric fields",,,"10.1007/s11565-017-0294-y",,"math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider a system associated to Klein-Gordon equations with homogeneous
time-dependent electric fields. The upper and lower boundaries of a
time-evolution propagator for this system were proven by Veseli\'c in 1991 for
electric fields that are independent of time. We extend this result to
time-dependent electric fields.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 10:34:06 GMT""},{""version"":""v2"",""created"":""Wed, 19 Jul 2017 09:26:50 GMT""},{""version"":""v3"",""created"":""Thu, 12 Oct 2017 02:25:16 GMT""}]","2017-12-01"
"1705.09515","Yannick Esteve","Edwin Simonnet (LIUM), Sahar Ghannay (LIUM), Nathalie Camelin (LIUM),
  Yannick Est\`eve (LIUM), Renato De Mori (LIA)","ASR error management for improving spoken language understanding","Interspeech 2017, Aug 2017, Stockholm, Sweden. 2017",,,,"cs.CL cs.AI cs.NE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper addresses the problem of automatic speech recognition (ASR) error
detection and their use for improving spoken language understanding (SLU)
systems. In this study, the SLU task consists in automatically extracting, from
ASR transcriptions , semantic concepts and concept/values pairs in a e.g
touristic information system. An approach is proposed for enriching the set of
semantic labels with error specific labels and by using a recently proposed
neural approach based on word embeddings to compute well calibrated ASR
confidence measures. Experimental results are reported showing that it is
possible to decrease significantly the Concept/Value Error Rate with a state of
the art system, outperforming previously published results performance on the
same experimental data. It also shown that combining an SLU approach based on
conditional random fields with a neural encoder/decoder attention based
architecture , it is possible to effectively identifying confidence islands and
uncertain semantic output segments useful for deciding appropriate error
handling actions by the dialogue manager strategy .
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 10:34:24 GMT""}]","2017-05-29"
"1705.09516","Sunil Sahu","Patchigolla V S S Rahul, Sunil Kumar Sahu, Ashish Anand","Biomedical Event Trigger Identification Using Bidirectional Recurrent
  Neural Network Based Models","The work has been accepted in BioNLP at ACL-2017",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Biomedical events describe complex interactions between various biomedical
entities. Event trigger is a word or a phrase which typically signifies the
occurrence of an event. Event trigger identification is an important first step
in all event extraction methods. However many of the current approaches either
rely on complex hand-crafted features or consider features only within a
window. In this paper we propose a method that takes the advantage of recurrent
neural network (RNN) to extract higher level features present across the
sentence. Thus hidden state representation of RNN along with word and entity
type embedding as features avoid relying on the complex hand-crafted features
generated using various NLP toolkits. Our experiments have shown to achieve
state-of-art F1-score on Multi Level Event Extraction (MLEE) corpus. We have
also performed category-wise analysis of the result and discussed the
importance of various features in trigger identification task.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 10:36:12 GMT""}]","2017-05-29"
"1705.09517","Pasin Manurangsi","Pasin Manurangsi and Aviad Rubinstein","Inapproximability of VC Dimension and Littlestone's Dimension","To appear in Conference On Learning Theory (COLT) 2017",,,,"cs.CC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the complexity of computing the VC Dimension and Littlestone's
Dimension. Given an explicit description of a finite universe and a concept
class (a binary matrix whose $(x,C)$-th entry is $1$ iff element $x$ belongs to
concept $C$), both can be computed exactly in quasi-polynomial time ($n^{O(\log
n)}$). Assuming the randomized Exponential Time Hypothesis (ETH), we prove
nearly matching lower bounds on the running time, that hold even for
approximation algorithms.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 10:38:01 GMT""}]","2017-05-29"
"1705.09518","Aamir Anis","Aamir Anis and Aly El Gamal and Salman Avestimehr and Antonio Ortega","A Sampling Theory Perspective of Graph-based Semi-supervised Learning",,"in IEEE Transactions on Information Theory, vol. 65, no. 4, pp.
  2322-2342, April 2019","10.1109/TIT.2018.2879897",,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Graph-based methods have been quite successful in solving unsupervised and
semi-supervised learning problems, as they provide a means to capture the
underlying geometry of the dataset. It is often desirable for the constructed
graph to satisfy two properties: first, data points that are similar in the
feature space should be strongly connected on the graph, and second, the class
label information should vary smoothly with respect to the graph, where
smoothness is measured using the spectral properties of the graph Laplacian
matrix. Recent works have justified some of these smoothness conditions by
showing that they are strongly linked to the semi-supervised smoothness
assumption and its variants. In this work, we reinforce this connection by
viewing the problem from a graph sampling theoretic perspective, where class
indicator functions are treated as bandlimited graph signals (in the
eigenvector basis of the graph Laplacian) and label prediction as a bandlimited
reconstruction problem. Our approach involves analyzing the bandwidth of class
indicator signals generated from statistical data models with separable and
nonseparable classes. These models are quite general and mimic the nature of
most real-world datasets. Our results show that in the asymptotic limit, the
bandwidth of any class indicator is also closely related to the geometry of the
dataset. This allows one to theoretically justify the assumption of
bandlimitedness of class indicator signals, thereby providing a sampling
theoretic interpretation of graph-based semi-supervised classification.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 10:39:08 GMT""},{""version"":""v2"",""created"":""Sat, 13 Apr 2019 06:03:29 GMT""}]","2019-04-16"
"1705.09519","Giovanni Rastelli","Claudia Maria Chanu, Giovanni Rastelli","Extended Hamiltonians and shift, ladder functions and operators","25 pages","Annals of Physics Volume 386, November 2017, Pages 254-274","10.1016/j.aop.2017.09.001",,"math-ph math.MP quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In recent years, many natural Hamiltonian systems, classical and quantum,
with constants of motion of high degree, or symmetry operators of high order,
have been found and studied. Most of these Hamiltonians, in the classical case,
can be included in the family of extended Hamiltonians, geometrically
characterized by the structure of warped manifold of their configuration
manifold. For the extended manifolds, the characteristic constants of motion of
high degree are polynomial in the momenta of determined form. We consider here
a different form of the constants of motion, based on the factorization
procedure developed by S. Kuru, J. Negro and others. We show that an important
subclass of the extended Hamiltonians admits factorized constants of motion and
we determine their expression. The classical constants may be non-polynomial in
the momenta, but the factorization procedure allows, in a type of extended
Hamiltonians, their quantization via shift and ladder operators, for systems of
any finite dimension.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 10:41:24 GMT""}]","2017-10-12"
"1705.09520","Peeyush Singh","Peeyush Singh","Robust Numerical Solution for Solving Elastohydrodynamic Lubrication
  (EHL) Problems using Total Variation Diminishing (TVD) Approach",,,,,"math.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this study, we propose a class of total variation diminishing (TVD)
schemes for solving pseudo-monotone variational inequality arises in
elasto-hydrodynamic lubrication point contact problem. A limiter based stable
hybrid line splittings are introduced on hierarchical multi-level grid. These
hybrid splittings are designed by use of diffusive coefficient and mesh
dependent switching parameter in the computing domain of interest. The spectrum
of illustrated splittings is derived with the help of well known local Fourier
analysis (LFA). Numerical tests validate the performance of scheme and its
competitiveness to the previous existing schemes. Advantages of proposed
splittings are observed in the sense that it reduces computational complexity
(up to ($O(n\log n)$) and solve high order discretization directly (no
defect-correction tool require) without perturbing the robustness of the
solution procedure (i.e. it works well for large range of load parameters).
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 10:43:04 GMT""},{""version"":""v2"",""created"":""Fri, 13 Jul 2018 18:02:06 GMT""}]","2018-07-17"
"1705.09521","Florian Sch\""one","Florian Sch\""one, Heinrich Stolz, Nobuko Naka","The phonon assisted absorption of excitons in Cu$_2$O",,"Phys. Rev. B 96, 115207 (2017)","10.1103/PhysRevB.96.115207",,"cond-mat.mes-hall quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The basic theoretical foundation for the modelling of phonon assisted
absorption spectra in direct bandgap semiconductors, introduced by Elliott 60
years ago using second order perturbation theory, results in a square root
shaped dependency close to the absorption edge. A careful analysis of the
experiments reveals that for the yellow S excitons in Cu$_2$O the lineshape
does not follow that square root dependence. The reexamination of the theory
shows that the basic assumptions of constant matrix elements and constant
energy denominators is invalid for semiconductors with dominant exciton effects
like Cu$_2$O, where the phonon assisted absorption proceeds via intermediate
exciton states. The overlap between these and the final exciton states strongly
determines the dependence of the absorption on the photon energy. To describe
the experimental observed line shape of the indirect absorption of the yellow S
exciton states we find it necessary to assume a momentum dependent deformation
potential for the optical phonons.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 10:43:05 GMT""},{""version"":""v2"",""created"":""Mon, 18 Sep 2017 10:16:47 GMT""}]","2017-10-04"
"1705.09522","Roberto Guerra","Roberto Guerra, Merel van Wijk, Andrea Vanossi, Annalisa Fasolino,
  Erio Tosatti","Graphene on h-BN: to align or not to align?",,,"10.1039/C7NR02352A",,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The contact strength, adhesion and friction, between graphene and an
incommensurate crystalline substrate such as {\it h}-BN depends on their
relative alignment angle $\theta$. The well established Novaco-McTague (NM)
theory predicts for a monolayer graphene on a hard bulk {\it h}-BN crystal face
a small spontaneous misalignment, here $\theta_{NM}$\,$\simeq$\,0.45 degrees
which if realized would be relevant to a host of electronic properties besides
the mechanical ones. Because experimental equilibrium is hard to achieve, we
inquire theoretically about alignment or misalignment by simulations based on
dependable state-of-the-art interatomic force fields. Surprisingly at first, we
find compelling evidence for $\theta = 0$, i.e., full energy-driven alignment
in the equilibrium state of graphene on {\it h}-BN. Two factors drive this
deviation from NM theory. First, graphene is not flat, developing on {\it h}-BN
a long-wavelength out-of-plane corrugation. Second, {\it h}-BN is not hard,
releasing its contact stress by planar contractions/expansions that accompany
the interface moir\'e structure. Repeated simulations by artificially forcing
graphene to keep flat, and {\it h}-BN to keep rigid, indeed yield an
equilibrium misalignment similar to $\theta_{NM}$ as expected. Subsequent
sliding simulations show that friction of graphene on {\it h}-BN, small and
essentially independent of misalignments in the artificial frozen state,
strongly increases in the more realistic corrugated, strain-modulated, aligned
state.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 10:45:15 GMT""}]","2017-05-29"
"1705.09523","Anna Rozanova-Pierrat","Kevin Arfi, Anna Rozanova-Pierrat","Dirichlet-to-Neumann or Poincar\'e-Steklov operator on fractals
  described by d -sets",,,,,"math.FA math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the framework of the Laplacian transport, described by a Robin boundary
value problem in an exterior domain in $\mathbb{R}^n$, we generalize the
definition of the Poincar\'e-Steklov operator to $d$-set boundaries, $n-2<
d<n$, and give its spectral properties to compare to the spectra of the
interior domain and also of a truncated domain, considered as an approximation
of the exterior case. The well-posedness of the Robin boundary value problems
for the truncated and exterior domains is given in the general framework of
$n$-sets. The results are obtained thanks to a generalization of the continuity
and compactness properties of the trace and extension operators in Sobolev,
Lebesgue and Besov spaces, in particular, by a generalization of the classical
Rellich-Kondrachov Theorem of compact embeddings for $n$ and $d$-sets.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 10:45:49 GMT""},{""version"":""v2"",""created"":""Wed, 5 Jul 2017 11:31:10 GMT""}]","2017-07-06"
"1705.09524","Marco Cristoforetti","Marco Cristoforetti, Giuseppe Jurman, Andrea I. Nardelli, Cesare
  Furlanello","Towards meaningful physics from generative models",,,,,"hep-lat cond-mat.stat-mech cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In several physical systems, important properties characterizing the system
itself are theoretically related with specific degrees of freedom. Although
standard Monte Carlo simulations provide an effective tool to accurately
reconstruct the physical configurations of the system, they are unable to
isolate the different contributions corresponding to different degrees of
freedom. Here we show that unsupervised deep learning can become a valid
support to MC simulation, coupling useful insights in the phases detection task
with good reconstruction performance. As a testbed we consider the 2D XY model,
showing that a deep neural network based on variational autoencoders can detect
the continuous Kosterlitz-Thouless (KT) transitions, and that, if endowed with
the appropriate constrains, they generate configurations with meaningful
physical content.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 10:45:59 GMT""}]","2017-05-29"
"1705.09525","Claudio Mezzina","Claudio Antares Mezzina and Emilio Tuosto","Choreographies for Automatic Recovery",,,,,"cs.LO cs.FL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a choreographic model of reversible computations based on a
conservative extension of global graphs and communicating finite-state
machines. The main advantage of our approach is that does not require to
instrument models in order to control reversibility but for a minor decoration
of branches. We show that our models are conservative extensions of existing
ones and that the reversible semantics guarantees causal consistency.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 10:49:22 GMT""}]","2017-05-29"
"1705.09526","Fanglin Bao","F. Bao, K. Shi, and S. He","Quantum propulsion and trapping of nano-objects by inhomogeneity-induced
  lateral Casimir forces","3 figures","Phys. Rev. Lett. 121, 130401 (2018)","10.1103/PhysRevLett.121.130401",,"physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Lateral Casimir force near a laterally-inhomogeneous plate is first revealed
by both rigorous simulations and proximity approximations. The
inhomogeneity-induced lateral Casimir force provides a novel method to control
the lateral motion of nano-objects above the plate, and makes source-free
manipulations of them possible. When incorporated with the Casimir repulsion in
a fluid, the lateral Casimir force is shown to dominate over Brownian motion
and enables long-distance quantum propulsion and firm quantum trapping of
nano-objects. Gratings of varying filling factors to mimic micro-scale
inhomogeneity also confirm those effects. The idea to design asymmetric
distributions of nano-structures paves the way to sophisticated tailoring of
the lateral Casimir force.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 10:50:18 GMT""}]","2018-10-03"
"1705.09527","Pedro J.  Mart\'inez-Aparicio","Daniela Giachetti, Pedro J. Mart\'inez-Aparicio and Fran\c{c}ois Murat","Homogenization of a Dirichlet semilinear elliptic problem with a strong
  singularity at $u=0$ in a domain with many small holes",,,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We perform the homogenization of the semilinear elliptic problem
  \begin{equation*} \begin{cases} u^\varepsilon \geq 0 & \mbox{in} \;
\Omega^\varepsilon,\\ \displaystyle - div \,A(x) D u^\varepsilon =
F(x,u^\varepsilon) & \mbox{in} \; \Omega^\varepsilon,\\ u^\varepsilon = 0 &
\mbox{on} \; \partial \Omega^\varepsilon.\\ \end{cases} \end{equation*} In this
problem $F(x,s)$ is a Carath\'eodory function such that $0 \leq F(x,s) \leq
h(x)/\Gamma(s)$ a.e. $x\in\Omega$ for every $s > 0$, with $h$ in some
$L^r(\Omega)$ and $\Gamma$ a $C^1([0, +\infty[)$ function such that $\Gamma(0)
= 0$ and $\Gamma'(s) > 0$ for every $s > 0$. On the other hand the open sets
$\Omega^\varepsilon$ are obtained by removing many small holes from a fixed
open set $\Omega$ in such a way that a ""strange term"" $\mu u^0$ appears in the
limit equation in the case where the function $F(x,s)$ depends only on $x$.
  We already treated this problem in the case of a ""mild singularity"", namely
in the case where the function $F(x,s)$ satisfies $0 \leq F(x,s) \leq h(x)
(\frac 1s + 1)$. In this case the solution $u^\varepsilon$ to the problem
belongs to $H^1_0 (\Omega^\varepsilon)$ and its definition is a ""natural"" and
rather usual one.
  In the general case where $F(x,s)$ exhibits a ""strong singularity"" at $u =
0$, which is the purpose of the present paper, the solution $u^\varepsilon$ to
the problem only belongs to $H_{\tiny loc}^1(\Omega^\varepsilon)$ but in
general does not belongs to $H^1_0 (\Omega^\varepsilon)$ any more, even if
$u^\varepsilon$ vanishes on $\partial\Omega^\varepsilon$ in some sense.
Therefore we introduced a new notion of solution (in the spirit of the
solutions defined by transposition) for problems with a strong singularity.
This definition allowed us to obtain existence, stability and uniqueness
results.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 10:53:33 GMT""}]","2017-05-29"
"1705.09528","Hang Deng","Hang Deng and Cun-Hui Zhang","Beyond Gaussian Approximation: Bootstrap for Maxima of Sums of
  Independent Random Vectors",,,,,"stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Bonferroni adjustment, or the union bound, is commonly used to study rate
optimality properties of statistical methods in high-dimensional problems.
However, in practice, the Bonferroni adjustment is overly conservative. The
extreme value theory has been proven to provide more accurate multiplicity
adjustments in a number of settings, but only on ad hoc basis. Recently,
Gaussian approximation has been used to justify bootstrap adjustments in large
scale simultaneous inference in some general settings when $n \gg (\log p)^7$,
where $p$ is the multiplicity of the inference problem and $n$ is the sample
size. The thrust of this theory is the validity of the Gaussian approximation
for maxima of sums of independent random vectors in high-dimension. In this
paper, we reduce the sample size requirement to $n \gg (\log p)^5$ for the
consistency of the empirical bootstrap and the multiplier/wild bootstrap in the
Kolmogorov-Smirnov distance, possibly in the regime where the Gaussian
approximation is not available. New comparison and anti-concentration theorems,
which are of considerable interest in and of themselves, are developed as
existing ones interweaved with Gaussian approximation are no longer applicable.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 11:01:01 GMT""},{""version"":""v2"",""created"":""Fri, 10 Jan 2020 06:48:49 GMT""}]","2020-01-13"
"1705.09529","Guang Yang A","Guang Yang, Xiahai Zhuang, Habib Khan, Shouvik Haldar, Eva Nyktari,
  Lei Li, Rick Wage, Xujiong Ye, Greg Slabaugh, Raad Mohiaddin, Tom Wong,
  Jennifer Keegan, David Firmin","Fully Automatic Segmentation and Objective Assessment of Atrial Scars
  for Longstanding Persistent Atrial Fibrillation Patients Using Late
  Gadolinium-Enhanced MRI","39 pages, 8 figure, 2 tables, submitted to MRM journal",,"10.1002/mp.12832",,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Purpose: Atrial fibrillation (AF) is the most common cardiac arrhythmia and
is correlated with increased morbidity and mortality. It is associated with
atrial fibrosis, which may be assessed non-invasively using late
gadolinium-enhanced (LGE) magnetic resonance imaging (MRI) where scar tissue is
visualised as a region of signal enhancement. In this study, we proposed a
novel fully automatic pipeline to achieve an accurate and objective atrial
scarring segmentation and assessment of LGE MRI scans for the AF patients.
Methods: Our fully automatic pipeline uniquely combined: (1) a multi-atlas
based whole heart segmentation (MA-WHS) to determine the cardiac anatomy from
an MRI Roadmap acquisition which is then mapped to LGE MRI, and (2) a
super-pixel and supervised learning based approach to delineate the
distribution and extent of atrial scarring in LGE MRI. Results: Both our MA-WHS
and atrial scarring segmentation showed accurate delineations of cardiac
anatomy (mean Dice = 89%) and atrial scarring (mean Dice =79%) respectively
compared to the established ground truth from manual segmentation. Compared
with previously studied methods with manual interventions, our innovative
pipeline demonstrated comparable results, but was computed fully automatically.
Conclusion: The proposed segmentation methods allow LGE MRI to be used as an
objective assessment tool for localisation, visualisation and quantification of
atrial scarring.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 11:04:47 GMT""}]","2018-07-04"
"1705.09530","Nicholas Horton","Beverly L. Wood and Megan Mocko and Michelle Everson and Nicholas J.
  Horton and Paul Velleman","Updated guidelines, updated curriculum: The GAISE College Report and
  introductory statistics for the modern student","in press, CHANCE",,"10.1080/09332480.2018.1467642",,"stat.OT stat.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Since the 2005 American Statistical Association's (ASA) endorsement of the
Guidelines for Assessment and Instruction in Statistics Education (GAISE)
College Report, changes in the statistics field and statistics education have
had a major impact on the teaching and learning of statistics. We now live in a
world where ""Statistics - the science of learning from data - is the
fastest-growing science, technology, engineering, and math (STEM) undergraduate
degree in the United States,"" according to the ASA, and where many jobs demand
an understanding of how to explore and make sense of data. In light of these
new reports and other changes and demands on the discipline, a group of
volunteers revised the 2005 GAISE College Report. The updated report was
endorsed by the Board of Directors of the American Statistical Association in
July 2016. To help shed additional light on the revision process and subsequent
changes in the report, we review the report and share insights into the
committee's thoughts and assumptions.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 11:09:15 GMT""}]","2020-07-21"
"1705.09531","David Benton Dr","David M Benton","Multiple beam steering using dynamic zone plates on a micro-mirror array",,,"10.1117/1.OE.57.7.073109",,"physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Three dimensional laser beam steering has been demonstrated using a single
optical device -a DMD micro-mirror array. Laser beam focus position is
controlled using dynamically adjustable zone plates. These zone plates take the
form of elliptical Fresnel zone plates or other variations such as binary Gabor
zone plates. Active beam control can be realised without the need for a pair of
galvanometer mirrors and a focusing lens. Writing multiple zone plate patterns
to the DMD enables multiple focussed spots to be generated and controlled
independently
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 11:10:21 GMT""}]","2018-08-29"
"1705.09532","Smarajit  Karmakar Dr.","Indrajit Tah, Shiladitya Sengupta, Srikanth Sastry, Chandan Dasgupta,
  and Smarajit Karmakar","Glass Transition in Supercooled Liquids with Medium Range Crystalline
  Order",,"Phys. Rev. Lett. 121, 085703 (2018)","10.1103/PhysRevLett.121.085703",,"cond-mat.soft cond-mat.dis-nn cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The origins of rapid dynamical slow down in glass forming liquids in the
growth of static length scales, possibly associated with identifiable
structural ordering, is a much debated issue. Growth of medium range
crystalline order (MRCO) has been observed in various model systems to be
associated with glassy behaviour. Such observations raise the question about
the eventual state reached by a glass former, if allowed to relax for
sufficiently long times. Is a slowly growing crystalline order responsible for
slow dynamics? Are the molecular mechanisms for glass transition in liquids
with and without MRCO the same? If yes, glass formers with MRCO provide a
paradigm for understanding glassy behaviour generically. If not, systems with
MRCO form a new class of glass forming materials whose molecular mechanism for
slow dynamics may be easier to understand in terms of growing crystalline
order, and should be approached in that manner, even while they will not
provide generic insights. In this study we perform extensive molecular dynamics
simulations of a number of glass forming liquids in two dimensions and show
that the static and dynamic properties of glasses with MRCO are different from
other glass forming liquids with no predominant local order. We also resolve an
important issue regarding the so-called Point-to-set method for determining
static length scales, and demonstrate it to be a robust, order agnostic, method
for determining static correlation lengths in glass formers.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 11:12:09 GMT""}]","2018-08-29"
"1705.09533","Graham Shore","Graham M. Shore","A New Twist on the Geometry of Gravitational Plane Waves","60 pages, 2 figures. Extended version with new material on Rosen
  geodesics and isometries. Title changed",,"10.1007/JHEP09(2017)039",,"gr-qc hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The geometry of twisted null geodesic congruences in gravitational plane wave
spacetimes is explored, with special focus on homogeneous plane waves. The role
of twist in the relation of the Rosen coordinates adapted to a null congruence
with the fundamental Brinkmann coordinates is explained and a generalised form
of the Rosen metric describing a gravitational plane wave is derived. The
Killing vectors and isometry algebra of homogeneous plane waves (HPWs) are
described in both Brinkmann and twisted Rosen form and used to demonstrate the
coset space structure of HPWs. The van Vleck-Morette determinant for twisted
congruences is evaluated in both Brinkmann and Rosen descriptions. The twisted
null congruences of the Ozsvath-Schucking,`anti-Mach' plane wave are
investigated in detail. These developments provide the necessary geometric
toolkit for future investigations of the role of twist in loop effects in
quantum field theory in curved spacetime, where gravitational plane waves arise
generically as Penrose limits; in string theory, where they are important as
string backgrounds; and potentially in the detection of gravitational waves in
astronomy.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 11:15:48 GMT""},{""version"":""v2"",""created"":""Mon, 31 Jul 2017 16:35:02 GMT""}]","2017-10-11"
"1705.09534","Victor Lakhno","Victor D. Lakhno","Peculiarities in the concentration dependence of the superconducting
  transition temperature in the bipolaron theory of Cooper pairs","3 pages","Modern Physics Letters B, 31, 1750125 (2017)","10.1142/S0217984917501251",,"cond-mat.supr-con","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It is shown that the bipolaron theory of Cooper pairs suggests that there is
a possibility for a superconducting phase to exist at low and high levels of
doping and be absent at intermediate level of doping. The results obtained
imply possibly universal character of 1/8 anomaly.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 11:16:43 GMT""}]","2017-05-29"
"1705.09535","Haihao Liu","Haihao Liu, M. Shoufie Ukhtary, Riichiro Saito","Hidden symmetries in $N$-layer dielectric stacks","9 pages, 8 figures",,"10.1088/1361-648X/aa865c",,"physics.optics math-ph math.MP physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The optical properties of a multilayer system of dielectric media with
arbitrary $N$ layers is investigated. Each layer is one of two dielectric
media, with thickness one-quarter the wavelength of light in that medium,
corresponding to a central frequency. Using the transfer matrix method, the
transmittance $T$ is calculated for all possible $2^N$ sequences for small $N$.
Unexpectedly, it is found that instead of $2^N$ different values of $T$ at the
central frequency ($T_0$), there are either $(N/2+1)$ or $(N+1)$ discrete
values of $T_0$ for even or odd $N$, respectively. We explain the high
degeneracy in the $T_0$ values by defining new symmetry operations that do not
change $T_0$. Analytical formulae were derived for the $T_0$ values and their
degeneracy as functions of $N$ and an integer parameter for each sequence we
call ""charge"". Additionally, the bandwidth of the transmission spectra at $f_0$
is investigated, revealing some asymptotic behavior at large $N$.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 11:27:28 GMT""}]","2017-10-25"
"1705.09536","Aiguo Xu Prof. Dr.","Yudong Zhang, Aiguo Xu, Guangcai Zhang, and Zhihua Chen","Discrete Boltzmann method with Maxwell-type boundary condition for slip
  flow","9 pages,9 figures. Comm. Theor. Phys.(Accepted)","Commun. Theor. Phys. 69 (2018) 77","10.1088/0253-6102/69/1/77",,"physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The rarefied effect of gas flow in microchannel is significant and cannot be
well described by traditional hydrodynamic models. It has been know that
discrete Boltzmann model (DBM) has the potential to investigate flows in a
relatively wider range of Knudsen number because of its intrinsic kinetic
nature inherited from Boltzmann equation. It is crucial to have a proper
kinetic boundary condition for DBM to capture the velocity slip and the flow
characteristics in the Knudsen layer. In this paper, we present a DBM combined
with Maxwell-type boundary condition model for slip flow. The tangential
momentum accommodation coefficient is introduced to implement a gas-surface
interaction model. Both the velocity slip and the Knudsen layer under various
Knudsen numbers and accommodation coefficients can be well described. Two kinds
of slip flows, including Couette flow and Poiseuille flow, are simulated to
verify the model. To dynamically compare results from different models, the
relation between the definition of Knudsen number in hard sphere model and that
in BGK model is clarified.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 11:30:56 GMT""},{""version"":""v2"",""created"":""Wed, 30 Aug 2017 10:03:34 GMT""},{""version"":""v3"",""created"":""Tue, 24 Oct 2017 01:55:59 GMT""}]","2017-12-27"
"1705.09537","Imran Anwar","Imran Anwar, Zunaira Kosar, Shaheen Nazir","An Efficient Algebraic Criterion for Shellability",,,,,"math.AC math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we give a new and efficient algebraic criterion for the pure
as well as non-pure shellability of simplicial complex $\Delta$ over [n]. We
also give an algebraic characterization of a leaf in a simplicial complex
(defined in [8]). Moreover, we introduce the concept of Gallai-simplicial
complex $\Delta_{\Gamma}(G)$ of a finite simple graph G. As an application, we
show that the face ring of the Gallai simplicial complex associated to tree is
Cohen-Macaulay.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 11:31:47 GMT""},{""version"":""v2"",""created"":""Sun, 10 Dec 2017 15:58:20 GMT""},{""version"":""v3"",""created"":""Thu, 14 Dec 2017 11:28:44 GMT""}]","2017-12-15"
"1705.09538","Dmitry Kosolobov","Golnaz Badkobeh, Travis Gagie, Shunsuke Inenaga, Tomasz Kociumaka,
  Dmitry Kosolobov, Simon J. Puglisi","On Two LZ78-style Grammars: Compression Bounds and Compressed-Space
  Computation","12 pages, accepted to SPIRE 2017",,,,"cs.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate two closely related LZ78-based compression schemes: LZMW (an
old scheme by Miller and Wegman) and LZD (a recent variant by Goto et al.).
Both LZD and LZMW naturally produce a grammar for a string of length $n$; we
show that the size of this grammar can be larger than the size of the smallest
grammar by a factor $\Omega(n^{\frac{1}3})$ but is always within a factor
$O((\frac{n}{\log n})^{\frac{2}{3}})$. In addition, we show that the standard
algorithms using $\Theta(z)$ working space to construct the LZD and LZMW
parsings, where $z$ is the size of the parsing, work in $\Omega(n^{\frac{5}4})$
time in the worst case. We then describe a new Las Vegas LZD/LZMW parsing
algorithm that uses $O (z \log n)$ space and $O(n + z \log^2 n)$ time w.h.p..
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 11:33:05 GMT""},{""version"":""v2"",""created"":""Tue, 25 Jul 2017 11:15:37 GMT""}]","2017-07-26"
"1705.09539","Rahim Rahmati-Asghar","Rahim Rahmati-Asghar","Expansion and contraction functors on matriods","13 pages",,,,"math.CO math.AC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $M$ be a matroid. We study the expansions of $M$ mainly to see how the
combinatorial properties of $M$ and its expansions are related to each other.
It is shown that $M$ is a graphic, binary or a transversal matroid if and only
if an arbitrary expansion of $M$ has the same property. Then we introduce a new
functor, called contraction, which acts in contrast to expansion functor. As a
main result of paper, we prove that a matroid $M$ satisfies White's conjecture
if and only if an arbitrary expansion of $M$ does. It follows that it suffices
to focus on the contraction of a given matroid for checking whether the matroid
satisfies White's conjecture. Finally, some classes of matroids satisfying
White's conjecture are presented.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 11:41:49 GMT""}]","2017-05-29"
"1705.09540","Xingzhi Zhan","Pu Qiao and Xingzhi Zhan","On vertex types of graphs",,,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The vertices of a graph are classified into seven types by J.T. Hedetniemi,
S.M. Hedetniemi, S.T. Hedetniemi and T.M. Lewis and they ask the following
questions: 1) What is the smallest order $n$ of a graph having $n-2$ very
typical vertices or $n-2$ typical vertices? 2) What is the smallest order of a
pantypical graph? We answer these two questions in this paper.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 11:43:21 GMT""}]","2017-05-29"
"1705.09541","Franz-Viktor Kuhlmann","Anna Blaszczok and Franz-Viktor Kuhlmann","Counting the number of distinct distances of elements in valued field
  extensions",,,,,"math.AC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The defect of valued field extensions is a major obstacle in open problems in
resolution of singularities and in the model theory of valued fields, whenever
positive characteristic is involved. We continue the detailed study of defect
extensions through the tool of distances, which measure how well an element in
an immediate extension can be approximated by elements from the base field. We
show that in several situations the number of essentially distinct distances in
fixed extensions, or even just over a fixed base field, is finite, and we
compute upper bounds. We apply this to the special case of valued functions
fields over perfect base fields. This provides important information used in
forthcoming research on relative resolution problems.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 11:48:58 GMT""}]","2017-05-29"
"1705.09542","Stefan Roth","Wolfgang Karcher, Stefan Roth, Evgeny Spodarev, Corinna Walk","An Inverse Problem for Infinitely Divisible Moving Average Random Fields","44 pages, 4 figures",,,,"math.ST stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Given a low frequency sample of an infinitely divisible moving average random
field $\{\int_{\mathbb{R}^d} f(x-t)\Lambda(dx); \ t \in \mathbb{R}^d \}$ with a
known simple function $f$, we study the problem of nonparametric estimation of
the L\'{e}vy characteristics of the independently scattered random measure
$\Lambda$. We provide three methods, a simple plug-in approach, a method based
on Fourier transforms and an approach involving decompositions with respect to
$L^2$-orthonormal bases, which allow to estimate the L\'{e}vy density of
$\Lambda$. For these methods, the bounds for the $L^2$-error are given. Their
numerical performance is compared in a simulation study.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 11:49:27 GMT""}]","2017-05-29"
"1705.09543","St\'ephane K\""undig Mr","Zhongliang Zhao, Stephane Kuendig, Jose Carrera, Blaise Carron,
  Torsten Braun, Jose Rolim","Indoor Location for Smart Environments with Wireless Sensor and Actuator
  Networks","different version is ongoing",,,,"cs.SY cs.NI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Smart environments interconnect indoor building environments, indoor wireless
sensor and actuator networks, smartphones, and human together to provide smart
infrastructure management and intelligent user experiences. To enable the
""smart"" operations, a complete set of hardware and software components are
required. In this work, we present Smart Syndesi, a system for creating indoor
location-aware smart building environments using wireless sensor and actuator
networks (WSANs). Smart Syndesi includes an indoor tracking system, a WSAN for
indoor environmental monitoring and activation automation, and a gateway
interconnecting WSAN, tracking system with mobile users.The indoor positioning
system tracks the real-time location of occupants with high accuracy, which
works as a basis for indoor location-based sensor actuation automation.To show
how the multiple software/hardware components are integrated, we implemented
the system prototype and performed intensive experiments in indoor office
environments to automate the indoor location-driven environmental sensor
monitoring and activation process. The tracked indoor location of a user's
smartphone triggers the retrieval of environmental measurements and activates
the actuators automatically (i.e. turn on/off lights, switch on/off fans) based
on the location and correlated environmental sensor information.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 11:56:21 GMT""},{""version"":""v2"",""created"":""Mon, 14 Jun 2021 07:11:43 GMT""}]","2021-06-15"
"1705.09544","Javier Principe","Vicente Bitri\'an and Javier Principe","Driving mechanisms and streamwise homogeneity in molecular dynamics
  simulations of nanochannel flows",,"Phys. Rev. Fluids 3, 014202 (2018)","10.1103/PhysRevFluids.3.014202",,"physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In molecular dynamics simulations, nanochannel flows are usually driven by a
constant force, that aims to represent a pressure difference between inlet and
outlet, and periodic boundary conditions are applied in the streamwise
direction resulting in an homogeneous flow. The homogeneity hypothesis can be
eliminated adding reservoirs at the inlet and outlet of the channel which
permits to predict streamwise variation of flow properties. It also opens the
door to drive the flow by applying pressure gradient instead of a constant
force. We analyze the impact of these modeling modifications in the prediction
of the flow properties and we show when they make a difference with respect to
the standard approach. It turns out that both assumptions are irrelevant when
low pressure differences are considered, but important differences are observed
at high pressure differences. They include the density and velocity variation
along the channel (the mass flow rate is constant) but, more importantly, the
temperature increase and slip length decrease. Because viscous heating is
important at high shear rates, these modeling issues are also linked to the use
of thermostating procedures. Specifically, selecting the region where the
thermostat is applied has a critical influence on the results. Whereas in the
traditional homogeneous model the choices are limited to the fluid and/or the
wall, in the inhomogeneous cases the reservoirs are also available, which
permits to leave the region of interest, the channel, unperturbed.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 17:51:23 GMT""}]","2018-01-17"
"1705.09545","Mark Lewis","Fred Glover, Mark Lewis, Gary Kochenberger","Logical and Inequality Implications for Reducing the Size and Complexity
  of Quadratic Unconstrained Binary Optimization Problems","30 pages + 6 pages of Appendices",,,,"cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The quadratic unconstrained binary optimization (QUBO) problem arises in
diverse optimization applications ranging from Ising spin problems to classical
problems in graph theory and binary discrete optimization. The use of
preprocessing to transform the graph representing the QUBO problem into a
smaller equivalent graph is important for improving solution quality and time
for both exact and metaheuristic algorithms and is a step towards mapping large
scale QUBO to hardware graphs used in quantum annealing computers. In an
earlier paper (Lewis and Glover, 2016) a set of rules was introduced that
achieved significant QUBO reductions as verified through computational testing.
Here this work is extended with additional rules that provide further
reductions that succeed in exactly solving 10% of the benchmark QUBO problems.
An algorithm and associated data structures to efficiently implement the entire
set of rules is detailed and computational experiments are reported that
demonstrate their efficacy.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 11:59:49 GMT""}]","2017-05-29"
"1705.09546","Aswin Sekhar","Aswin Sekhar","Kozai Mechanism and real Kozai: Raw Talents of The Highest Order","4 pages including references (Article bordering Astrophysics,
  Mathematics and Philosophy)",,,,"physics.hist-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A slightly(!!!) philosophical article which looks at some interesting
overlaps between some fine mathematical brains and a celestial mechanics legend
from Japan.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 12:01:45 GMT""}]","2017-05-29"
"1705.09547","Sirin Caliskan","Unal Ertan, Sirin Caliskan, M. Ali Alpar","Optical excess of dim isolated neutron stars","7 pages, 6 figures. Accepted for publication in MNRAS",,"10.1093/mnras/stx1310",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The optical excess in the spectra of dim isolated neutron stars (XDINs) is a
significant fraction of their rotational energy loss-rate. This is strikingly
different from the situation in isolated radio pulsars. We investigate this
problem in the framework of the fallback disc model. The optical spectra can be
powered by magnetic stresses on the innermost disc matter, as the energy
dissipated is emitted as blackbody radiation mainly from the inner rim of the
disc. In the fallback disc model, XDINs are the sources evolving in the
propeller phase with similar torque mechanisms. In this this model, the ratio
of the total magnetic work that heats up the inner disc matter is expected to
be similar for different XDINs. Optical luminosities that are calculated
consistently with the the optical spectra and the theoretical constraints on
the inner disc radii give very similar ratios of the optical luminosity to the
rotational energy loss rate for all these sources. These ratios indicate that a
significant fraction of the magnetic torque heats up the disc matter while the
remaining fraction expels disc matter from the system. For XDINs, the
contribution of heating by X-ray irradiation to the optical luminosity is
negligible in comparison with the magnetic heating. The correlation we expect
between the optical luminosities and the rotational energy loss-rates of XDINs
can be a property of the systems with low X-ray luminosities, in particular
those in the propeller phase.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 12:03:15 GMT""}]","2017-07-05"
"1705.09549","Daiki Ikami","Daiki Ikami, Toshihiko Yamasaki and Kiyoharu Aizawa","Residual Expansion Algorithm: Fast and Effective Optimization for
  Nonconvex Least Squares Problems","Accepted to CVPR2017",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose the residual expansion (RE) algorithm: a global (or near-global)
optimization method for nonconvex least squares problems. Unlike most existing
nonconvex optimization techniques, the RE algorithm is not based on either
stochastic or multi-point searches; therefore, it can achieve fast global
optimization. Moreover, the RE algorithm is easy to implement and successful in
high-dimensional optimization. The RE algorithm exhibits excellent empirical
performance in terms of k-means clustering, point-set registration, optimized
product quantization, and blind image deblurring.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 12:08:50 GMT""}]","2017-05-29"
"1705.09550","Igor Bandos","Igor Bandos","An analytic superfield formalism for tree superamplitudes in D=10 and
  D=11","LaTeX, 51pp. V2: improved and completed; to be published in JHEP;
  63pp",,"10.1007/JHEP05(2018)103",,"hep-th gr-qc hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Tree amplitudes of 10D supersymmetric Yang-Mills theory (SYM) and 11D
supergravity (SUGRA) are collected in multi-particle counterparts of analytic
on-shell superfields. These have essentially the same form as their chiral 4D
counterparts describing ${\cal N}=4$ SYM and ${\cal N}=8$ SUGRA, but with
components dependent on a different set of bosonic variables. These are the
D=10 and D=11 spinor helicity variables, the set of which includes the spinor
frame variable (Lorentz harmonics) and a scalar density, and generalized
homogeneous coordinates of the coset $\frac{SO(D-2)}{SO(D-4)\otimes U(1)}$
(internal harmonics).
  We present an especially convenient parametrization of the spinor harmonics
(Lorentz covariant gauge fixed with the use of an auxiliary gauge symmetry) and
use this to find (a gauge fixed version of) the 3-point tree superamplitudes of
10D SYM and 11D SUGRA which generalize the 4 dimensional anti-MHV
superamplitudes.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 12:34:29 GMT""},{""version"":""v2"",""created"":""Mon, 7 May 2018 09:48:46 GMT""}]","2018-06-13"
"1705.09551","Istvan Tomon","Istv\'an Tomon","Forbidden induced subposets in the grid","7 pages, added references",,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this short paper, we prove the following generalization of a result of
Methuku and P\'{a}lv\""{o}lgyi. Let $P$ be a poset, then there exists a constant
$C_{P}$ with the following property. Let $k$ and $n$ be arbitrary positive
integers such that $n$ is at least the dimension of $P$, and let $w$ be the
size of the largest antichain of the grid $[k]^{n}$ endowed with the usual
pointwise ordering. If $S$ is a subset of $[k]^{n}$ not containing an induced
copy of $P$, then $|S|\leq C_{P}w$.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 12:38:43 GMT""},{""version"":""v2"",""created"":""Thu, 1 Jun 2017 16:07:57 GMT""}]","2017-06-02"
"1705.09552","Seyed-Mohsen Moosavi-Dezfooli","Alhussein Fawzi, Seyed-Mohsen Moosavi-Dezfooli, Pascal Frossard,
  Stefano Soatto","Classification regions of deep neural networks",,,,,"cs.CV cs.AI cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The goal of this paper is to analyze the geometric properties of deep neural
network classifiers in the input space. We specifically study the topology of
classification regions created by deep networks, as well as their associated
decision boundary. Through a systematic empirical investigation, we show that
state-of-the-art deep nets learn connected classification regions, and that the
decision boundary in the vicinity of datapoints is flat along most directions.
We further draw an essential connection between two seemingly unrelated
properties of deep networks: their sensitivity to additive perturbations in the
inputs, and the curvature of their decision boundary. The directions where the
decision boundary is curved in fact remarkably characterize the directions to
which the classifier is the most vulnerable. We finally leverage a fundamental
asymmetry in the curvature of the decision boundary of deep nets, and propose a
method to discriminate between original images, and images perturbed with small
adversarial examples. We show the effectiveness of this purely geometric
approach for detecting small adversarial perturbations in images, and for
recovering the labels of perturbed images.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 12:38:48 GMT""}]","2017-05-29"
"1705.09553","Adam Chapman","Adam Chapman and Kelly McKinnie","Kato-Milne Cohomology and Polynomial Forms",,,,,"math.RA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Given a prime number $p$, a field $F$ with $\operatorname{char}(F)=p$ and a
positive integer $n$, we study the class-preserving modifications of Kato-Milne
classes of decomposable differential forms. These modifications demonstrate a
natural connection between differential forms and $p$-regular forms. A
$p$-regular form is defined to be a homogeneous polynomial form of degree $p$
for which there is no nonzero point where all the order $p-1$ partial
derivatives vanish simultaneously. We define a $\widetilde C_{p,m}$ field to be
a field over which every $p$-regular form of dimension greater than $p^m$ is
isotropic. The main results are that for a $\widetilde C_{p,m}$ field $F$, the
symbol length of $H_p^2(F)$ is bounded from above by $p^{m-1}-1$ and for any $n
\geq \lceil (m-1) \log_2(p) \rceil+1$, $H_p^{n+1}(F)=0$.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 12:40:55 GMT""},{""version"":""v2"",""created"":""Wed, 28 Feb 2018 21:14:01 GMT""}]","2018-03-02"
"1705.09554","Seyed-Mohsen Moosavi-Dezfooli","Seyed-Mohsen Moosavi-Dezfooli, Alhussein Fawzi, Omar Fawzi, Pascal
  Frossard, Stefano Soatto","Robustness of classifiers to universal perturbations: a geometric
  perspective","Published at ICLR 2018",,,,"cs.CV cs.AI cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deep networks have recently been shown to be vulnerable to universal
perturbations: there exist very small image-agnostic perturbations that cause
most natural images to be misclassified by such classifiers. In this paper, we
propose the first quantitative analysis of the robustness of classifiers to
universal perturbations, and draw a formal link between the robustness to
universal perturbations, and the geometry of the decision boundary.
Specifically, we establish theoretical bounds on the robustness of classifiers
under two decision boundary models (flat and curved models). We show in
particular that the robustness of deep networks to universal perturbations is
driven by a key property of their curvature: there exists shared directions
along which the decision boundary of deep networks is systematically positively
curved. Under such conditions, we prove the existence of small universal
perturbations. Our analysis further provides a novel geometric method for
computing universal perturbations, in addition to explaining their properties.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 12:42:55 GMT""},{""version"":""v2"",""created"":""Mon, 1 Mar 2021 20:45:00 GMT""}]","2021-03-03"
"1705.09558","Andrew Wilson","Yunus Saatchi, Andrew Gordon Wilson","Bayesian GAN","Updated to the version that appears at Advances in Neural Information
  Processing Systems 30 (NIPS), 2017","Advances in Neural Information Processing Systems 30 (NIPS), 2017",,,"stat.ML cs.AI cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Generative adversarial networks (GANs) can implicitly learn rich
distributions over images, audio, and data which are hard to model with an
explicit likelihood. We present a practical Bayesian formulation for
unsupervised and semi-supervised learning with GANs. Within this framework, we
use stochastic gradient Hamiltonian Monte Carlo to marginalize the weights of
the generator and discriminator networks. The resulting approach is
straightforward and obtains good performance without any standard interventions
such as feature matching, or mini-batch discrimination. By exploring an
expressive posterior over the parameters of the generator, the Bayesian GAN
avoids mode-collapse, produces interpretable and diverse candidate samples, and
provides state-of-the-art quantitative results for semi-supervised learning on
benchmarks including SVHN, CelebA, and CIFAR-10, outperforming DCGAN,
Wasserstein GANs, and DCGAN ensembles.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 12:47:56 GMT""},{""version"":""v2"",""created"":""Mon, 29 May 2017 07:54:47 GMT""},{""version"":""v3"",""created"":""Wed, 8 Nov 2017 17:52:21 GMT""}]","2017-11-09"
"1705.09560","Mai Ibrahim Khaleel","Mai Ibrahim Khaleel, Yu-Da Chen, Ching-Hang Chien, Yia-Chung Chang","Sensing of streptococcus mutans by microscopic imaging ellipsometry","Keywords: imaging ellipsometry, streptococcus mutans, biosensing,
  bacterial cells",,"10.1117/1.JBO.22.5.056005",,"physics.bio-ph physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Microscopic Imaging Ellipsometry is an optical technique that uses an
objective and sensing procedure to measure the ellipsometric parameters {\Psi}
and {\Delta} in the form of microscopic maps. This technique is well known for
being non-invasive and label-free. Therefore it can be used to detect and
characterize biological species without any impact. In this work MIE was used
to measure the optical response of dried Streptococcus mutans cells on a glass
substrate. The ellipsometric {\Psi} and {\Delta} maps were obtained with Optrel
Multiskop system for specular reflection in the visible range ({\lambda}= 450nm
-750nm). The {\Psi} and {\Delta} images at 500nm, 600nm, and 700nm were
analyzed using three different theoretical models with single-bounce,
two-bounce, and multi-bounce light paths to obtain the optical constants and
height distribution. The obtained images of the optical constants show
different aspects when comparing the single-bounce analysis with the two-bounce
or multi-bounce analysis in detecting S. mutans samples. Furthermore, the
height distributions estimated by two-bounce and multi-bounce analysis of S.
mutans samples were in agreement with the thickness values measured by AFM,
which implies that the two-bounce and multi-bounce analysis can provide
information complementary to that obtained by single-bounce light path.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 12:48:58 GMT""}]","2017-06-07"
"1705.09561","Andr\'es F. Barrientos","Andr\'es F. Barrientos, Jerome P. Reiter, Ashwin Machanavajjhala, Yan
  Chen","Differentially private significance tests for regression coefficients",,,,,"stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Many data producers seek to provide users access to confidential data without
unduly compromising data subjects' privacy and confidentiality. One general
strategy is to require users to do analyses without seeing the confidential
data; for example, analysts only get access to synthetic data or query systems
that provide disclosure-protected outputs of statistical models. With synthetic
data or redacted outputs, the analyst never really knows how much to trust the
resulting findings. In particular, if the user did the same analysis on the
confidential data, would regression coefficients of interest be statistically
significant or not? We present algorithms for assessing this question that
satisfy differential privacy. We describe conditions under which the algorithms
should give accurate answers about statistical significance. We illustrate the
properties of the proposed methods using artificial and genuine data.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 12:55:36 GMT""},{""version"":""v2"",""created"":""Mon, 11 Jun 2018 13:57:26 GMT""}]","2018-06-12"
"1705.09563","Jason Black","Jason Black, Amanda Terry, Daniel Lizotte","FRAMR-EMR: Framework for Prognostic Predictive Model Development Using
  Electronic Medical Record Data with a Case Study in Osteoarthritis Risk",,,,,"stat.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Background-Prognostic predictive models are used in the delivery of primary
care to estimate a patients risk of future disease development. Electronic
medical record, EMR, data can be used for the construction of these models.
Objectives- To provide a framework for those seeking to develop prognostic
predictive models using EMR data, and to illustrate these steps using
osteoarthritis risk estimation as an example. FRAMR-EMR-The FRAmework for
Modelling Risk from EMR data, FRAMR-EMR, was created, which outlines
step-by-step guidance for the construction of a prognostic predictive model
using EMR data. Throughout these steps, several potential pitfalls specific to
using EMR data for predictive purposes are described and methods for addressing
them are suggested. Case Study-We used the DELPHI, DELiver Primary Healthcare
Information, database to develop our prognostic predictive model for estimation
of osteoarthritis risk. We constructed a retrospective cohort of 28447 eligible
primary care patients. Patients were included if they had an encounter with
their primary care practitioner between 1 January 2008 and 31 December 2009.
Patients were excluded if they had a diagnosis of osteoarthritis prior to
baseline. Construction of a prognostic predictive model following FRAMR-EMR
yielded a predictive model capable of estimating 5-year risk of osteoarthritis
diagnosis. Logistic regression was used to predict osteoarthritis based on age,
sex, BMI, previous leg injury, and osteoporosis. Internal validation of the
models performance demonstrated good discrimination and moderate calibration.
Conclusions-This study provides guidance to those interested in developing
prognostic predictive models based on EMR data. The production of high quality
prognostic predictive models allows for practitioner communication of
accurately estimated risks of developing future disease among primary care
patients.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 12:59:29 GMT""},{""version"":""v2"",""created"":""Wed, 6 Sep 2017 02:28:48 GMT""}]","2017-09-07"
"1705.09565","Adam Peddle","Adam Peddle and Terry Haut and Beth Wingate","Parareal Convergence for Oscillatory PDEs with Finite Time-scale
  Separation",,,,,"math.NA math.CA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A variant of the Parareal method for highly oscillatory systems of PDEs was
proposed by Haut and Wingate (2014). In that work they proved superlinear
conver- gence of the method in the limit of infinite time scale separation.
Their coarse solver features a coordinate transformation and a fast-wave
averag- ing method inspired by analysis of multiple scales PDEs and is
integrated using an HMM-type method. However, for many physical applications
the timescale separation is finite, not infinite. In this paper we prove con-
vergence for finite timescale separaration by extending the error bound on the
coarse propagator to this case. We show that convergence requires the solution
of an optimization problem that involves the averaging win- dow interval, the
time step, and the parameters in the problem. We also propose a method for
choosing the averaging window relative to the time step based as a function of
the finite frequencies inherent in the problem.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 13:00:12 GMT""}]","2017-05-29"
"1705.09566","Giacomo Scornavacca","Andrea Clementi, Luciano Gual\`a, Guido Proietti, Giacomo Scornavacca","Rational Fair Consensus in the GOSSIP Model","Accepted at IPDPS'17",,,,"cs.GT cs.DC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The \emph{rational fair consensus problem} can be informally defined as
follows. Consider a network of $n$ (selfish) \emph{rational agents}, each of
them initially supporting a \emph{color} chosen from a finite set $ \Sigma$.
The goal is to design a protocol that leads the network to a stable
monochromatic configuration (i.e. a consensus) such that the probability that
the winning color is $c$ is equal to the fraction of the agents that initially
support $c$, for any $c \in \Sigma$. Furthermore, this fairness property must
be guaranteed (with high probability) even in presence of any fixed
\emph{coalition} of rational agents that may deviate from the protocol in order
to increase the winning probability of their supported colors. A protocol
having this property, in presence of coalitions of size at most $t$, is said to
be a \emph{whp\,-$t$-strong equilibrium}. We investigate, for the first time,
the rational fair consensus problem in the GOSSIP communication model where, at
every round, every agent can actively contact at most one neighbor via a
\emph{push$/$pull} operation. We provide a randomized GOSSIP protocol that,
starting from any initial color configuration of the complete graph, achieves
rational fair consensus within $O(\log n)$ rounds using messages of
$O(\log^2n)$ size, w.h.p. More in details, we prove that our protocol is a
whp\,-$t$-strong equilibrium for any $t = o(n/\log n)$ and, moreover, it
tolerates worst-case permanent faults provided that the number of non-faulty
agents is $\Omega(n)$. As far as we know, our protocol is the first solution
which avoids any all-to-all communication, thus resulting in $o(n^2)$ message
complexity.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 13:01:31 GMT""}]","2017-05-29"
"1705.09572","Vicent Costa","Vicent Costa and Pilar Dellunde","Term Models of Horn Clauses over Rational Pavelka Predicate Logic","International Symposium on Multiple-Valued Logic 2017",,,,"math.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper is a contribution to the study of the universal Horn fragment of
predicate fuzzy logics, focusing on the proof of the existence of free models
of theories of Horn clauses over Rational Pavelka predicate logic. We define
the notion of a term structure associated to every consistent theory T over
Rational Pavelka predicate logic and we prove that the term models of T are
free on the class of all models of T. Finally, it is shown that if T is a set
of Horn clauses, the term structure associated to T is a model of T.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 13:07:37 GMT""}]","2017-05-29"
"1705.09573","A. N. Ivanov","A. N. Ivanov","Comment on ""On the implementation of CVC in weak charged-current
  proton-neutron transitions"" by C. Giunti, arXiv: 1602.00215 [hep-ph]","3 pages, no figures",,,,"hep-ph astro-ph.CO hep-ex nucl-ex nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show that the term maintaining conservation of the charged vector current
for the transitions ""neutron <-> proton"" even for different masses of the
neutron and proton (see T. Leitner et al., Phys. Rev. C {\bf 73}, 065502 (2006)
and A. M. Ankowski, arXiv:1601.06169 [hep-ph]) is related to the first class
current contribution but not to the second class one as has been pointed out by
C. Giunti, arXiv: 1602.00215 [hep-ph].
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 13:07:45 GMT""}]","2017-05-30"
"1705.09574","Alessio Benavoli","Alessio Benavoli and Alessandro Facchini and Jose Vicente-Perez and
  Marco Zaffalon","A polarity theory for sets of desirable gambles","Accepted at ISIPTA 2017",,,,"math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Coherent sets of almost desirable gambles and credal sets are known to be
equivalent models. That is, there exists a bijection between the two
collections of sets preserving the usual operations, e.g. conditioning. Such a
correspondence is based on the polarity theory for closed convex cones.
Learning from this simple observation, in this paper we introduce a new
(lexicographic) polarity theory for general convex cones and then we apply it
in order to establish an analogous correspondence between coherent sets of
desirable gambles and convex sets of lexicographic probabilities.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 13:15:49 GMT""}]","2017-05-29"
"1705.09575","Christophe Ley","Christophe Ley and Tom Van de Wiele and Hans Van Eetvelde","Ranking soccer teams on basis of their current strength: a comparison of
  maximum likelihood approaches","16 pages, 3 figures",,,,"stat.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present ten different strength-based statistical models that we use to
model soccer match outcomes with the aim of producing a new ranking. The models
are of four main types: Thurstone-Mosteller, Bradley-Terry, Independent Poisson
and Bivariate Poisson, and their common aspect is that the parameters are
estimated via weighted maximum likelihood, the weights being a match importance
factor and a time depreciation factor giving less weight to matches that are
played a long time ago. Since our goal is to build a ranking reflecting the
teams' current strengths, we compare the 10 models on basis of their predictive
performance via the Rank Probability Score at the level of both domestic
leagues and national teams. We find that the best models are the Bivariate and
Independent Poisson models. We then illustrate the versatility and usefulness
of our new rankings by means of three examples where the existing rankings fail
to provide enough information or lead to peculiar results.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 13:16:47 GMT""},{""version"":""v2"",""created"":""Thu, 8 Feb 2018 13:53:57 GMT""},{""version"":""v3"",""created"":""Tue, 13 Nov 2018 21:04:15 GMT""}]","2018-11-15"
"1705.09576","Satyaki Kar","Debabrata Sinha and Satyaki Kar","Andreev tunnelling and Josephson current in light irradiated graphene","Final version","Current Applied Physics Vol. 18, Issue 9. Pages 1087-1094 (2018)","10.1016/j.cap.2018.05.021",,"cond-mat.str-el cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate the Andreev tunneling and Josephson current in graphene
irradiated with high-frequency linearly polarized light. The corresponding
stroboscopic dynamics can be solved using Floquet mechanism which results in an
effective stationary theory to the problem. It exhibits anisotropy in the Dirac
spectrum and modifies the so-called pseudospin-momentum locking in graphene.
The Andreev reflection at a normal graphene - superconductor (NS) interface
becomes an oscillatory function of the optical strength. Specifically we find
that, by varying the polarization direction we can both suppress AR
considerably or cause the Andreev transport to remain maximum at sub-gap
excitation energies even in the presence of Fermi level mismatch. Furthermore,
we study the optical effect on the Andreev bound states (ABS) within a short
normal-graphene sheet, sandwiched between two s-wave superconductors. It shows
redistribution of the low energy regime in the ABS spectrum, which in turn, has
major effect in shaping the Josephson super-current. Subjected to efficient
tuning, such current can be sufficiently altered even at the charge neutrality
point. Our observations provide useful feedback in regulating the quantum
transport in Dirac-like systems, achieved via controlled off-resonant optical
irradiation on them.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 13:23:30 GMT""},{""version"":""v2"",""created"":""Tue, 7 Nov 2017 05:21:27 GMT""},{""version"":""v3"",""created"":""Wed, 20 Jun 2018 10:07:45 GMT""}]","2018-06-21"
"1705.09577","Gabor Horvath","G\'abor Horv\'ath and Chrystopher L. Nehaniv and K\'aroly Podoski","The maximal subgroups and the complexity of the flow semigroup of finite
  (di)graphs","25 pages",,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The flow semigroup, introduced by John Rhodes, is an invariant for digraphs
and a complete invariant for graphs. After collecting together previous partial
results, we refine and prove Rhodes's conjecture on the structure of the
maximal groups in the flow semigroup for finite, antisymmetric, strongly
connected digraphs.
  Building on this result, we investigate and fully describe the structure and
actions of the maximal subgroups of the flow semigroup acting on all but $k$
points for all finite digraphs and graphs for all $k\geq 1$. A linear algorithm
(in the number of edges) is presented to determine these so-called `defect $k$
groups' for any finite (di)graph.
  Finally, we prove that the complexity of the flow semigroup of a 2-vertex
connected (and strongly connected di)graph with $n$ vertices is $n-2$,
completely confirming Rhodes's conjecture for such (di)graphs.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 13:27:55 GMT""},{""version"":""v2"",""created"":""Wed, 16 Aug 2017 18:24:59 GMT""}]","2017-08-18"
"1705.09578","Beatriz Mingo Dr","B. Mingo, M. J. Hardcastle, J. Ineson, V. Mahatma, J. H. Croston, D.
  Dicken, D. A. Evans, R. Morganti, and C. Tadhunter","An X-ray survey of the 2Jy sample. II: X-ray emission from extended
  structures","18 pages, 3 tables, 29 figures, accepted for publication in Monthly
  Notices of the Royal Astronomical Society (MNRAS)",,"10.1093/mnras/stx1307",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The 2Jy sample is a survey of radio galaxies with flux densities above 2 Jy
at 2.7 GHz. As part of our ongoing work on the southern subset of 2Jy sources,
in paper I of this series we analysed the X-ray cores of the complete 2Jy
sample with redshifts 0.05<z<0.7. For this work we focus on the X-ray emission
associated with the extended structures (jets, lobes, and environments) of the
complete subset of 2Jy sources with 0.05<z<0.2, that we have observed with
Chandra. We find that hotspots and jet knots are ubiquitous in FRII sources,
which also inhabit systematically poorer environments than the FRI sources in
our sample. Spectral fits of the hotspots with good X-ray statistics invariably
show properties consistent with synchrotron emission, and we show that
inverse-Compton mechanisms under-predict the X-ray emission we observe by 1-2
orders of magnitude. Inverse-Compton emission is detected from many of the
lobes in our sample, and we find that the lobes of the FRII sources show
magnetic fields lower by up to an order of magnitude than expected from
equipartition extrapolations. This is consistent with previous results, which
show that most FRII sources have electron energy densities higher than minimum
energy requirements.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 13:32:11 GMT""}]","2017-05-29"
"1705.09579","Ram\'on Jos\'e Aliaga Varea","Ram\'on J. Aliaga and Antonio J. Guirao","On the preserved extremal structure of Lipschitz-free spaces","15 pages. Results have been generalized to the general (i.e.
  non-compact) case. Comments are welcome","Studia Mathematica 245 (2019), pp. 1-14","10.4064/sm170529-30-11","MR3863062, Zbl 1420.46014","math.FA math.MG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We characterize preserved extreme points of Lipschitz-free spaces
$\mathcal{F}(X)$ in terms of simple geometric conditions on the underlying
metric space $(X,d)$. Namely, each preserved extreme point corresponds to a
pair of points $p,q$ in $X$ such that the triangle inequality $d(p,q)\leq
d(p,r)+d(q,r)$ is uniformly strict for $r$ away from $p,q$. For compact $X$,
this condition reduces to the triangle inequality being strict. This result
gives an affirmative answer to a conjecture of N. Weaver that compact spaces
are concave if and only if they have no triple of metrically aligned points.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 13:35:08 GMT""},{""version"":""v2"",""created"":""Tue, 30 May 2017 07:58:38 GMT""},{""version"":""v3"",""created"":""Wed, 26 Jul 2017 14:29:41 GMT""}]","2022-03-16"
"1705.09580","Agostino Capponi","Agostino Capponi and Reza Ghanadan and Matt Stern","Risk-Sensitive Cooperative Games for Human-Machine Systems","15 pages, 10 figures",,,,"stat.ML cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Autonomous systems can substantially enhance a human's efficiency and
effectiveness in complex environments. Machines, however, are often unable to
observe the preferences of the humans that they serve. Despite the fact that
the human's and machine's objectives are aligned, asymmetric information, along
with heterogeneous sensitivities to risk by the human and machine, make their
joint optimization process a game with strategic interactions. We propose a
framework based on risk-sensitive dynamic games; the human seeks to optimize
her risk-sensitive criterion according to her true preferences, while the
machine seeks to adaptively learn the human's preferences and at the same time
provide a good service to the human. We develop a class of performance measures
for the proposed framework based on the concept of regret. We then evaluate
their dependence on the risk-sensitivity and the degree of uncertainty. We
present applications of our framework to self-driving taxis, and robo-financial
advising.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 13:35:28 GMT""}]","2017-05-29"
"1705.09581","Mitchell Struble","Mitchell F. Struble","Coma Cluster Ultra-Diffuse Galaxies Are Not Standard Radio Galaxies","10 pages, 3 tables Revised version accepted for publication in MNRAS",,"10.1093/mnras/stx1785",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Matching members in the Coma cluster catalogue of ultra-diffuse galaxies
(UDGs, Yagi et al. 2016) from SUBARU imaging with a very deep radio continuum
survey source catalogue of the cluster (Miller et al. 2009) using the Karl G.
Jansky Very Large Array (VLA) within a rectangular region of ~ 1.19 square
degrees centred on the cluster core reveals matches consistent with random. An
overlapping set of 470 UDGs and 696 VLA radio sources in this rectangular area
finds 33 matches within a separation of 25 arcsec; dividing the sample into
bins with separations bounded by 5 arcsec, 10 arcsec, 20 arcsec and 25 arcsec
finds 1, 4, 17 and 11 matches. An analytical model estimate, based on the
Poisson probability distribution, of the number of randomly expected matches
within these same separation bounds is 1.7, 4.9, 19.4 and 14.2, each
respectively consistent with the 95 percent Poisson confidence intervals of the
observed values. Dividing the data into five clustercentric annuli of 0.1
degree, and into the four separation bins, finds the same result. This random
match of UDGs with VLA sources implies that UDGs are not radio galaxies by the
standard definition. Those VLA sources having integrated flux > 1 mJy at 1.4
GHz in Miller et al. (2009) without SDSS galaxy matches are consistent with the
known surface density of background radio sources. We briefly explore the
possibility that some unresolved VLA sources near UDGs could be young, compact,
bright, supernova remnants of type Ia events, possibly in the intracluster
volume.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 13:36:23 GMT""},{""version"":""v2"",""created"":""Fri, 14 Jul 2017 19:30:52 GMT""}]","2017-12-06"
"1705.09582","Toshiaki Fukada","Toshiaki Fukada, Walter Fornari, Luca Brandt, Shintaro Takeuchi, Takeo
  Kajishima","A numerical approach for particle-vortex interactions based on
  volume-averaged equations","54 pages, 20 figures",,"10.1016/j.ijmultiphaseflow.2018.02.019",,"physics.flu-dyn","http://creativecommons.org/licenses/by/4.0/","  To study the dynamics of particles in turbulence when their sizes are
comparable to the smallest eddies in the flow, the Kolmogorov length scale,
efficient and accurate numerical models for the particle-fluid interaction are
still missing. Therefore, we here extend the treatment of the particle feedback
on the fluid based on the volume-averaged fluid equations (VA simulation) in
the previous study of the present authors, by estimating the fluid force
correlated with the disturbed flow. We validate the model against
interface-resolved simulations using the immersed-boundary method. Simulations
of single particles show that the history effect is well captured by the
present estimation method based on the disturbed flow. Similarly, the
simulation of the flow around a rotating particle demonstrates that the lift
force is also well captured by the proposed method. We also consider the
interaction between non-negligible size particles and an array of Taylor-Green
vortices. For density ratios $\rho_d/\rho_c\geq$ 10, the results show that the
particle motion captured by the VA approach is closer to that of the
fully-resolved simulations than that obtained with a traditional two-way
coupling simulation. The flow disturbance is also well represented by the VA
simulation. In particular, it is found that history effects enhance the
curvature of the trajectory in vortices and this enhancement increases with the
particle size. Furthermore, the flow field generated by a neighboring particle
at distances of around ten particle diameters significantly influences particle
trajectories. The computational cost of the VA simulation proposed here is
considerably lower than that of the interface-resolved simulation.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 13:36:38 GMT""},{""version"":""v2"",""created"":""Tue, 27 Feb 2018 03:14:22 GMT""}]","2018-02-28"
"1705.09583","Vesselin  Petkov","Ferruccio Colombini and Vesselin Petkov","Weyl formula for the negative dissipative eigenvalues of Maxwell's
  equations",,,,,"math.AP math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $V(t) = e^{tG_b},\: t \geq 0,$ be the semigroup generated by Maxwell's
equations in an exterior domain $\Omega \subset {\mathbb R}^3$ with dissipative
boundary condition $E_{tan}- \gamma(x) (\nu \wedge B_{tan}) = 0, \gamma(x) > 0,
\forall x \in \Gamma = \partial \Omega.$ We study the case when $\Omega = \{x
\in {\mathbb R^3}:\: |x| > 1\}$ and $\gamma \neq 1$ is a constant. We establish
a Weyl formula for the counting function of the negative real eigenvalues of
$G_b.$
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 13:37:21 GMT""}]","2017-05-29"
"1705.09584","Scientific Information Service CERN","V. Malka","Plasma Wake Accelerators: Introduction and Historical Overview","28 pages, CAS - CERN Accelerator School: Plasma Wake Acceleration,
  CERN, Geneva, Switzerland, 23 - 29 Nov 2014","CERN Yellow Report CERN-2016-001, pp.1-28","10.5170/CERN-2016-001.1",,"physics.acc-ph","http://creativecommons.org/licenses/by/4.0/","  Fundamental questions on the nature of matter and energy have found answers
thanks to the use of particle accelerators. Societal applications, such as
cancer treatment or cancer imaging, illustrate the impact of accelerators in
our current life. Today, accelerators use metallic cavities that sustain
electricfields with values limited to about 100 MV/m. Because of their ability
to support extreme accelerating gradients, the plasma medium has recently been
proposed for future cavity-like accelerating structures. This contribution
highlights the tremendous evolution of plasma accelerators driven by either
laser or particle beams that allow the production of high quality particle
beams with a degree of tunability and a set of parameters that make them very
pertinent for many applications.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 13:42:20 GMT""},{""version"":""v2"",""created"":""Tue, 30 May 2017 09:36:12 GMT""}]","2017-05-31"
"1705.09585","Rohan Kshirsagar","Rohan Kshirsagar, Robert Morris, Sam Bowman","Detecting and Explaining Crisis","Accepted at CLPsych, ACL workshop. 8 pages, 5 figures",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Individuals on social media may reveal themselves to be in various states of
crisis (e.g. suicide, self-harm, abuse, or eating disorders). Detecting crisis
from social media text automatically and accurately can have profound
consequences. However, detecting a general state of crisis without explaining
why has limited applications. An explanation in this context is a coherent,
concise subset of the text that rationalizes the crisis detection. We explore
several methods to detect and explain crisis using a combination of neural and
non-neural techniques. We evaluate these techniques on a unique data set
obtained from Koko, an anonymous emotional support network available through
various messaging applications. We annotate a small subset of the samples
labeled with crisis with corresponding explanations. Our best technique
significantly outperforms the baseline for detection and explanation.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 13:44:54 GMT""}]","2017-05-29"
"1705.09586","Joseph Gage","Joseph Gage","Undergraduate algebra in nineteenth-century Oxford",,"BSHM Bulletin 32 (2017) 149-159","10.1080/17498430.2016.1244630",,"math.HO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The nineteenth century was an important period for both Oxford mathematics
and algebra in general. While there is extensive documentation of mathematical
research in Oxford at this time, the same cannot be said of the teaching. The
content of the course presents a different picture: it shows what those who set
it felt was most valuable for a young mathematician to learn, perhaps
indicating what direction they expected mathematics to take in the future. To
find out what undergraduates were taught, I have looked through examination
papers of the years between 1828 and 1912 with a focus on algebra, as well as
supporting material. In this paper I will present my findings. I will give a
picture of what an Oxford undergraduate's course in algebra looked like by the
end of the nineteenth century and discuss my own conclusions as to why it took
such a form.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 14:06:39 GMT""}]","2017-05-29"
"1705.09587","Jisoo Jeong","Jisoo Jeong, Hyojin Park, and Nojun Kwak","Enhancement of SSD by concatenating feature maps for object detection",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose an object detection method that improves the accuracy of the
conventional SSD (Single Shot Multibox Detector), which is one of the top
object detection algorithms in both aspects of accuracy and speed. The
performance of a deep network is known to be improved as the number of feature
maps increases. However, it is difficult to improve the performance by simply
raising the number of feature maps. In this paper, we propose and analyze how
to use feature maps effectively to improve the performance of the conventional
SSD. The enhanced performance was obtained by changing the structure close to
the classifier network, rather than growing layers close to the input data,
e.g., by replacing VGGNet with ResNet. The proposed network is suitable for
sharing the weights in the classifier networks, by which property, the training
can be faster with better generalization power. For the Pascal VOC 2007 test
set trained with VOC 2007 and VOC 2012 training sets, the proposed network with
the input size of 300 x 300 achieved 78.5% mAP (mean average precision) at the
speed of 35.0 FPS (frame per second), while the network with a 512 x 512 sized
input achieved 80.8% mAP at 16.6 FPS using Nvidia Titan X GPU. The proposed
network shows state-of-the-art mAP, which is better than those of the
conventional SSD, YOLO, Faster-RCNN and RFCN. Also, it is faster than
Faster-RCNN and RFCN.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 14:07:41 GMT""}]","2017-11-07"
"1705.09588","Claire Debord","Claire Debord and Georges Skandalis","Blowup constructions for Lie groupoids and a Boutet de Monvel type
  calculus","47 pages",,,,"math.OA math.DG math.KT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present natural and general ways of building Lie groupoids, by using the
classical procedures of blowups and of deformations to the normal cone. Our
constructions are seen to recover many known ones involved in index theory. The
deformation and blowup groupoids obtained give rise to several extensions of
$C^*$-algebras and to full index problems. We compute the corresponding
K-theory maps. Finally, the blowup of a manifold sitting in a transverse way in
the space of objects of a Lie groupoid leads to a calculus, quite similar to
the Boutet de Monvel calculus for manifolds with boundary.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 14:08:13 GMT""},{""version"":""v2"",""created"":""Tue, 27 Jun 2017 11:50:30 GMT""}]","2017-06-28"
"1705.09589","Maximilian L\""oschner","M. Fox, W. Grimus and M. L\""oschner","Renormalization and radiative corrections to masses in a general Yukawa
  model","28 pages, 2 figures. Reference added, results unchanged, typos
  corrected, clarifying comments and motivations added","Int. J. of Mod. Phys. A Vol. 33 (2018) 1850019 (27 pages)","10.1142/S0217751X18500197","UWThPh-2017-11","hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider a model with arbitrary numbers of Majorana fermion fields and
real scalar fields $\varphi_a$, general Yukawa couplings and a $\mathbb{Z}_4$
symmetry that forbids linear and trilinear terms in the scalar potential.
Moreover, fermions become massive only after spontaneous symmetry breaking of
the $\mathbb{Z}_4$ symmetry by vacuum expectation values (VEVs) of the
$\varphi_a$. Introducing the shifted fields $h_a$ whose VEVs vanish,
$\overline{\mbox{MS}}$ renormalization of the parameters of the unbroken theory
suffices to make the theory finite. However, in this way, beyond tree level it
is necessary to perform finite shifts of the tree-level VEVs, induced by the
finite parts of the tadpole diagrams, in order to ensure vanishing one-point
functions of the $h_a$. Moreover, adapting the renormalization scheme to a
situation with many scalars and VEVs, we consider the physical fermion and
scalar masses as derived quantities, $\textit{i.e.}$ as functions of the
coupling constants and VEVs. Consequently, the masses have to be computed order
by order in a perturbative expansion. In this scheme we compute the
selfenergies of fermions and bosons and show how to obtain the respective
one-loop contributions to the tree-level masses. Furthermore, we discuss the
modification of our results in the case of Dirac fermions and investigate, by
way of an example, the effects of a flavour symmetry group.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 14:11:23 GMT""},{""version"":""v2"",""created"":""Mon, 2 Oct 2017 14:41:33 GMT""}]","2018-01-22"
"1705.09590","Tamir Bendory","Tamir Bendory, Robert Beinert and Yonina C. Eldar","Fourier Phase Retrieval: Uniqueness and Algorithms",,,,,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The problem of recovering a signal from its phaseless Fourier transform
measurements, called Fourier phase retrieval, arises in many applications in
engineering and science. Fourier phase retrieval poses fundamental theoretical
and algorithmic challenges. In general, there is no unique mapping between a
one-dimensional signal and its Fourier magnitude and therefore the problem is
ill-posed. Additionally, while almost all multidimensional signals are uniquely
mapped to their Fourier magnitude, the performance of existing algorithms is
generally not well-understood. In this chapter we survey methods to guarantee
uniqueness in Fourier phase retrieval. We then present different algorithmic
approaches to retrieve the signal in practice. We conclude by outlining some of
the main open questions in this field.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 14:12:47 GMT""},{""version"":""v2"",""created"":""Mon, 26 Jun 2017 21:41:40 GMT""},{""version"":""v3"",""created"":""Mon, 6 Nov 2017 20:02:35 GMT""}]","2017-11-08"
"1705.09591","Annie Lee","Annie J. Lee, Karen Marder, Helen Mejia-Santana, Avi Orr-Urtreger, Nir
  Giladi, Susan Bressman, Yuanjia Wang","Estimation of Genetic Risk Function with Covariates in the Presence of
  Missing Genotypes","16 pages, 5 tables, 4 figures (7 Supplementary pages, 4 Supplementary
  tables, 13 Supplementary figures)",,,,"stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In genetic epidemiological studies, family history data are collected on
relatives of study participants and used to estimate the age-specific risk of
disease for individuals who carry a causal mutation. However, a family member's
genotype data may not be collected due to the high cost of in-person interview
to obtain blood sample or death of a relative. Previously, efficient
nonparametric genotype-specific risk estimation in censored mixture data has
been proposed without considering covariates. With multiple predictive risk
factors available, risk estimation requires a multivariate model to account for
additional covariates that may affect disease risk simultaneously. Therefore,
it is important to consider the role of covariates in the genotype-specific
distribution estimation using family history data. We propose an estimation
method that permits more precise risk prediction by controlling for individual
characteristics and incorporating interaction effects with missing genotypes in
relatives, and thus gene-gene interactions and gene-environment interactions
can be handled within the framework of a single model. We examine performance
of the proposed methods by simulations and apply them to estimate the
age-specific cumulative risk of Parkinson's disease (PD) in carriers of LRRK2
G2019S mutation using first-degree relatives who are at genetic risk for PD.
The utility of estimated carrier risk is demonstrated through designing a
future clinical trial under various assumptions. Such sample size estimation is
seen in the Huntington's disease literature using the length of abnormal
expansion of a CAG repeat in the HTT gene, but is less common in the PD
literature.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 14:18:39 GMT""}]","2017-05-29"
"1705.09592","J. G. G. De Oliveira Jr.","J. G. G. de Oliveira Jr., Gustavo de Souza, L. A. Cabral, I. G. da
  Paz, and Marcos Sampaio","Exotic looped trajectories via quantum marking","10 pages, 5 figures",,"10.1016/j.aop.2017.10.006",,"quant-ph physics.atom-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We provide an analytical and theoretical study of exotic looped trajectories
(ELTs) in a double-slit interferometer with quantum marking. We use an excited
Rydberg-like atom and which-way detectors such as superconducting cavities,
just as in the Scully-Englert-Walther interferometer. We indicate appropriate
conditions on the atomic beam or superconducting cavities so that we determine
an interference pattern and fringe visibility exclusive from the ELTs. We
quantitatively describe our results for Rubidium atoms and propose this
framework as an alternative scheme to the double-slit experiment modified to
interfere only these exotic trajectories.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 14:21:20 GMT""}]","2017-11-22"
"1705.09593","Richard Aoun","Richard Aoun and Yves Guivarc'h","Random matrix products when the top Lyapunov exponent is simple","39 pages, 3 figures Final version","J. Eur. Math. Soc. (JEMS) 22 (2020), no. 7, 2135-2182",,,"math.DS math.GR math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the present paper, we treat random matrix products on the general linear
group $\textrm{GL}(V)$, where $V$ is a vector space defined on any local field,
when the top Lyapunov exponent is simple, without irreducibility assumption. In
particular, we show the existence and uniqueness of the stationary measure
$\nu$ on $\textrm{P}(V)$ that is relative to the top Lyapunov exponent and we
describe the projective subspace generated by its support. We observe that the
dynamics takes place in a open set of $\textrm{P}(V)$ which has the structure
of a skew product space. Then, we relate this support to the limit set of the
semi-group $T_{\mu}$ of $\textrm{GL}(V)$ generated by the random walk.
Moreover, we show that $\nu$ has H\""older regularity and give some limit
theorems concerning the behavior of the random walk and the probability of
hitting a hyperplane. These results generalize known ones when $T_{\mu}$ acts
strongly irreducibly and proximally (i-p to abbreviate) on $V$. In particular,
when applied to the affine group in the so-called contracting case or more
generally when the Zariski closure of $T_{\mu}$ is not necessarily reductive,
the H\""older regularity of the stationary measure together with the description
of the limit set are new. We mention that we don't use results from the i-p
setting; rather we see it as a particular case.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 14:25:13 GMT""},{""version"":""v2"",""created"":""Sat, 8 Jul 2017 15:55:10 GMT""},{""version"":""v3"",""created"":""Tue, 5 Mar 2019 10:34:52 GMT""},{""version"":""v4"",""created"":""Tue, 16 Jun 2020 12:53:58 GMT""}]","2020-06-17"
"1705.09594","Zoltan Kollath","Zolt\'an Koll\'ath and Anita D\""om\'eny","Night sky quality monitoring in existing and planned dark sky parks by
  digital cameras","in press: International Journal of Sustainable Lighting",,,,"astro-ph.IM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A crucial part of the qualification of international dark sky places (IDSPs)
is the objective measurement of night time sky luminance or radiance. Modern
digital cameras provide an alternative way to perform all sky imaging either by
a fisheye lens or by a mosaic image taken by a wide angle lens. Here we present
a method for processing raw camera images to obtain calibrated measurements of
sky quality. The comparison of the night sky quality of different European
locations is also presented to demonstrate the use of our technique.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 14:26:10 GMT""}]","2017-05-29"
"1705.09595","Jeffrey Galkowski","Yaiza Canzani, Jeffrey Galkowski, John A. Toth","Averages of eigenfunctions over hypersurfaces","18 pages, 1 figure",,"10.1007/s00220-017-3081-9",,"math.AP math.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $(M,g)$ be a compact, smooth, Riemannian manifold and $\{ \phi_h \}$ an
$L^2$-normalized sequence of Laplace eigenfunctions with defect measure $\mu$.
Let $H$ be a smooth hypersurface. Our main result says that when $\mu$ is
$\textit{not}$ concentrated conormally to $H$, the eigenfunction restrictions
to $H$ and the restrictions of their normal derivatives to $H$ have integrals
converging to 0 as $h \to 0^+$.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 14:27:32 GMT""},{""version"":""v2"",""created"":""Mon, 22 Jan 2018 14:13:30 GMT""}]","2018-02-14"
"1705.09596","Francesca Matteucci","Francesca Matteucci, Emanuele Spitoni, Donatella Romano, Alvaro
  Rojas-Arriagada","The chemical evolution of the Milky Way","10 pages, 6 figures, in Frontier Research in Astrophysics - II 23-28
  May 2016 Mondello (Palermo), Italy",,"10.5281/zenodo.2595366",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We will discuss some highlights concerning the chemical evolution of our
Galaxy, the Milky Way. First we will describe the main ingredients necessary to
build a model for the chemical evolution of the Milky Way. Then we will
illustrate some Milky Way models which includes detailed stellar
nucleosynthesis and compute the evolution of a large number of chemical
elements, including C, N, O, $\alpha$-elements, Fe and heavier. The main
observables and in particular the chemical abundances in stars and gas will be
considered. A comparison theory-observations will follow and finally some
conclusions from this astroarchaeological approach will be derived.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 14:28:53 GMT""}]","2019-04-24"
"1705.09597","Russell Bates","Russell Bates, Benjamin Irving, Bostjan Markelc, Jakob Kaeppler, Ruth
  Muschel, Vicente Grau, and Julia A. Schnabel","Extracting 3D Vascular Structures from Microscopy Images using
  Convolutional Recurrent Networks","The article has been submitted to IEEE TMI",,,,"cs.CV","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Vasculature is known to be of key biological significance, especially in the
study of cancer. As such, considerable effort has been focused on the automated
measurement and analysis of vasculature in medical and pre-clinical images. In
tumors in particular, the vascular networks may be extremely irregular and the
appearance of the individual vessels may not conform to classical descriptions
of vascular appearance. Typically, vessels are extracted by either a
segmentation and thinning pipeline, or by direct tracking. Neither of these
methods are well suited to microscopy images of tumor vasculature. In order to
address this we propose a method to directly extract a medial representation of
the vessels using Convolutional Neural Networks. We then show that these
two-dimensional centerlines can be meaningfully extended into 3D in anisotropic
and complex microscopy images using the recently popularized Convolutional Long
Short-Term Memory units (ConvLSTM). We demonstrate the effectiveness of this
hybrid convolutional-recurrent architecture over both 2D and 3D convolutional
comparators.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 14:30:29 GMT""}]","2017-05-29"
"1705.09598","Seth Lloyd","Can Gokler, Artemy Kolchinsky, Zi-Wen Liu, Iman Marvian, Peter Shor,
  Oles Shtanko, Kevin Thompson, David Wolpert, Seth Lloyd","When is a bit worth much more than kT ln2?","7 pages, plain TeX",,,,"cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Physical processes thatobtain, process, and erase information involve
tradeoffs between information and energy. The fundamental energetic value of a
bit of information exchanged with a reservoir at temperature T is kT ln2. This
paper investigates the situation in which information is missing about just
what physical process is about to take place. The fundamental energetic value
of such information can be far greater than kT ln2 per bit.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 14:34:05 GMT""}]","2017-05-29"
"1705.09599","Zhanfeng Wang","Kani Chen, Yuanyuan Lin, Zhanfeng Wang, Zhiliang Ying","Nearly Semiparametric Efficient Estimation of Quantile Regression","33 pages",,,,"stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  As a competitive alternative to least squares regression, quantile regression
is popular in analyzing heterogenous data. For quantile regression model
specified for one single quantile level $\tau$, major difficulties of
semiparametric efficient estimation are the unavailability of a parametric
efficient score and the conditional density estimation. In this paper, with the
help of the least favorable submodel technique, we first derive the
semiparametric efficient scores for linear quantile regression models that are
assumed for a single quantile level, multiple quantile levels and all the
quantile levels in $(0,1)$ respectively. Our main discovery is a one-step
(nearly) semiparametric efficient estimation for the regression coefficients of
the quantile regression models assumed for multiple quantile levels, which has
several advantages: it could be regarded as an optimal way to pool information
across multiple/other quantiles for efficiency gain; it is computationally
feasible and easy to implement, as the initial estimator is easily available;
due to the nature of quantile regression models under investigation, the
conditional density estimation is straightforward by plugging in an initial
estimator. The resulting estimator is proved to achieve the corresponding
semiparametric efficiency lower bound under regularity conditions. Numerical
studies including simulations and an example of birth weight of children
confirms that the proposed estimator leads to higher efficiency compared with
the Koenker-Bassett quantile regression estimator for all quantiles of
interest.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 14:35:43 GMT""}]","2017-05-29"
"1705.09600","Shana Moothedath","Shana Moothedath, Prasanna Chaporkar and Madhu N. Belur","Approximating Constrained Minimum Cost Input-Output Selection for
  Generic Arbitrary Pole Placement in Structured Systems","11 pages, 2 figures",,,,"math.OC cs.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper is about minimum cost constrained selection of inputs and outputs
for generic arbitrary pole placement. The input-output set is constrained in
the sense that the set of states that each input can influence and the set of
states that each output can sense is pre-specified. Our goal is to optimally
select an input-output set that the system has no structurally fixed modes.
Polynomial algorithms do not exist for solving this problem unless P=NP. To
this end, we propose an approximation algorithm by splitting the problem in to
three sub-problems: a) minimum cost accessibility problem, b) minimum cost
sensability problem and c) minimum cost disjoint cycle problem. We prove that
problems a) and b) are equivalent to a suitably defined weighted set cover
problems. We also show that problem c) is equivalent to a minimum cost perfect
matching problem. Using these we give an approximation algorithm which solves
the minimum cost generic arbitrary pole placement problem. The proposed
algorithm incorporates an approximation algorithm to solve the weighted set
cover problem for solving a) and b) and a minimum cost perfect matching
algorithm to solve c). Further, we show that the algorithm is polynomial time
an gives an order optimal solution to the minimum cost input-output selection
for generic arbitrary pole placement problem.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 14:41:28 GMT""},{""version"":""v2"",""created"":""Wed, 10 Jan 2018 04:56:39 GMT""}]","2018-01-11"
"1705.09601","Scientific Information Service CERN","B J Holzer","Introduction to Particle Accelerators and their Limitations","22 pages, contribution to the CAS - CERN Accelerator School: Plasma
  Wake Acceleration, CERN, Geneva, Switzerland, 23 - 29 Nov 2014, pp.29-50","CERN Yellow Report CERN CERN-2016-001, pp.29-50","10.5170/CERN-2016-001.29",,"physics.acc-ph","http://creativecommons.org/licenses/by/4.0/","  The paper gives an overview of the principles of particle accelerators and
their historical development. After introducing the basic concepts, the main
emphasis is on sketching the layout of modern storage rings and discussing
their limitations in terms of energy and machine performance. Examples of
existing machines, among them the Large Hadron Collider (LHC) at CERN,
demonstrate the basic principles of and the technical and physical limits that
we face in the design and operation of particle colliders. The push for ever
higher beam energies motivates the design of future colliders as well as the
development of more efficient acceleration techniques.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 14:45:55 GMT""}]","2017-05-29"
"1705.09602","Elena Burceanu","Elena Burceanu and Marius Leordeanu","Learning a Robust Society of Tracking Parts","9.5 pages of main content, 2.5 of bibliography, 2 pages of appendix,
  3 figures",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Object tracking is an essential task in computer vision that has been studied
since the early days of the field. Being able to follow objects that undergo
different transformations in the video sequence, including changes in scale,
illumination, shape and occlusions, makes the problem extremely difficult. One
of the real challenges is to keep track of the changes in objects appearance
and not drift towards the background clutter. Different from previous
approaches, we obtain robustness against background with a tracker model that
is composed of many different parts. They are classifiers that respond at
different scales and locations. The tracker system functions as a society of
parts, each having its own role and level of credibility. Reliable classifiers
decide the tracker's next move, while newcomers are first monitored before
gaining the necessary level of reliability to participate in the decision
process. Some parts that loose their consistency are rejected, while others
that show consistency for a sufficiently long time are promoted to permanent
roles. The tracker system, as a whole, could also go through different phases,
from the usual, normal functioning to states of weak agreement and even crisis.
The tracker system has different governing rules in each state. What truly
distinguishes our work from others is not necessarily the strength of
individual tracking parts, but the way in which they work together and build a
strong and robust organization. We also propose an efficient way to learn
simultaneously many tracking parts, with a single closed-form formulation. We
obtain a fast and robust tracker with state of the art performance on the
challenging OTB50 dataset.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 14:51:43 GMT""}]","2017-05-29"
"1705.09603","Antti Niemi","Anna Sinelnikova, Antti J. Niemi, Johan Nilsson, Maksim Ulybyshev","Multiple scales and phases in discrete chains with application to folded
  proteins","22 figures","Phys. Rev. E 97, 052107 (2018)","10.1103/PhysRevE.97.052107",,"cond-mat.soft cond-mat.stat-mech physics.bio-ph q-bio.BM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Chiral heteropolymers such as larger globular proteins can simultaneously
support multiple length scales. The interplay between different scales brings
about conformational diversity, and governs the structure of the energy
landscape. Multiple scales produces also complex dynamics, which in the case of
proteins sustains live matter. However, thus far no clear understanding exist,
how to distinguish the various scales that determine the structure and dynamics
of a complex protein. Here we propose a systematic method to identify the
scales in chiral heteropolymers such as a protein. For this we introduce a
novel order parameter, that not only reveals the scales but also probes the
phase structure. In particular, we argue that a chiral heteropolymer can
simultaneously display traits of several different phases, contingent on the
length scale at which it is scrutinized. Our approach builds on a variant of
Kadanoff's block-spin transformation that we employ to coarse grain piecewise
linear chains such as the C$\alpha$ backbone of a protein. We derive
analytically and then verify numerically a number of properties that the order
parameter can display. We demonstrate how, in the case of crystallographic
protein structures in Protein Data Bank, the order parameter reveals the
presence of different length scales, and we propose that a relation must exist
between the scales, phases, and the complexity of folding pathways.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 14:53:01 GMT""}]","2018-05-16"
"1705.09604","Tirthankar Banerjee","Tirthankar Banerjee and Abhik Basu","Symmetries and scaling in generalised coupled conserved
  Kardar-Parisi-Zhang equations","accepted in JSTAT. Mech : Theory and Experiments (2017)",,"10.1088/1742-5468/aa9a58",,"cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the noisy nonequilibrium dynamics of a conserved density that is
driven by a fluctuating surface governed by the conserved Kardar-Parisi-Zhang
equation. We uncover the universal scaling properties of the conserved density.
We consider two separate minimal models where the surface fluctuations couple
(i) with the spatial variation of the conserved density, and (ii) directly with
the magnitude of the conserved density. Both these two models conserve the
density, but differ from symmetry stand point. We use our result to highlight
the dependence of nonequilibrium universality classes on the interplay between
symmetries and conservation laws.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 14:53:02 GMT""},{""version"":""v2"",""created"":""Mon, 6 Nov 2017 11:13:16 GMT""}]","2018-02-14"
"1705.09605","James Grant","James A. Grant, David S. Leslie, Kevin Glazebrook, Roberto Szechtman","Combinatorial Multi-Armed Bandits with Filtered Feedback","16 pages",,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Motivated by problems in search and detection we present a solution to a
Combinatorial Multi-Armed Bandit (CMAB) problem with both heavy-tailed reward
distributions and a new class of feedback, filtered semibandit feedback. In a
CMAB problem an agent pulls a combination of arms from a set $\{1,...,k\}$ in
each round, generating random outcomes from probability distributions
associated with these arms and receiving an overall reward. Under semibandit
feedback it is assumed that the random outcomes generated are all observed.
Filtered semibandit feedback allows the outcomes that are observed to be
sampled from a second distribution conditioned on the initial random outcomes.
This feedback mechanism is valuable as it allows CMAB methods to be applied to
sequential search and detection problems where combinatorial actions are made,
but the true rewards (number of objects of interest appearing in the round) are
not observed, rather a filtered reward (the number of objects the searcher
successfully finds, which must by definition be less than the number that
appear). We present an upper confidence bound type algorithm, Robust-F-CUCB,
and associated regret bound of order $\mathcal{O}(\ln(n))$ to balance
exploration and exploitation in the face of both filtering of reward and heavy
tailed reward distributions.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 14:53:46 GMT""}]","2017-05-29"
"1705.09606","Meysam Madadi","Meysam Madadi, Sergio Escalera, Xavier Baro and Jordi Gonzalez","End-to-end Global to Local CNN Learning for Hand Pose Recovery in Depth
  Data",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Despite recent advances in 3D pose estimation of human hands, especially
thanks to the advent of CNNs and depth cameras, this task is still far from
being solved. This is mainly due to the highly non-linear dynamics of fingers,
which make hand model training a challenging task. In this paper, we exploit a
novel hierarchical tree-like structured CNN, in which branches are trained to
become specialized in predefined subsets of hand joints, called local poses. We
further fuse local pose features, extracted from hierarchical CNN branches, to
learn higher order dependencies among joints in the final pose by end-to-end
training. Lastly, the loss function used is also defined to incorporate
appearance and physical constraints about doable hand motion and deformation.
Finally, we introduce a non-rigid data augmentation approach to increase the
amount of training depth data. Experimental results suggest that feeding a
tree-shaped CNN, specialized in local poses, into a fusion network for modeling
joints correlations and dependencies, helps to increase the precision of final
estimations, outperforming state-of-the-art results on NYU and SyntheticHand
datasets.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 14:55:44 GMT""},{""version"":""v2"",""created"":""Wed, 11 Apr 2018 23:26:00 GMT""}]","2018-04-13"
"1705.09607","Andrzej Syrwid","Andrzej Syrwid and Krzysztof Sacha","Quantum dark solitons in Bose gas confined in a hard wall box","7 pages, 4 figures, version accepted for publication in Phys. Rev. A","Phys. Rev. A 96, 043602 (2017)","10.1103/PhysRevA.96.043602",,"cond-mat.quant-gas nlin.PS quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Schr\""odinger equation for Bose gas with repulsive contact interactions in
one-dimensional space may be solved analytically with the help of the Bethe
ansatz if we impose periodic boundary conditions. It was shown that in such a
system there exist many-body eigenstates directly corresponding to dark soliton
solutions of the mean-field equation. The system is still integrable if one
switches from the periodic boundary conditions to an infinite square well
potential. The corresponding eigenstates were constructed by M. Gaudin. We
analyze weak interaction limit of Gaudin's solutions and identify
parametrization of eigenstates strictly connected with single and multiple dark
solitons. Numerical simulations of detection of particle's positions reveal
dark solitons in the weak interaction regime and their quantum nature in the
presence of strong interactions.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 15:00:47 GMT""},{""version"":""v2"",""created"":""Sat, 16 Sep 2017 10:52:05 GMT""}]","2017-10-06"
"1705.09608","Vedad Pasic Dr","Samir Karasulji\'c, Enes Duvnjakovi\'c, Vedad Pasic, Elvis Barakovic","Construction of a global solution for the one dimensional
  singularly-perturbed boundary value problem","14 pages, 3 figures, 1 table","Journal of Modern Methods in Numerical Mathematics, [S.l.], v. 8,
  n. 1-2, p. 52-65, july 2017. ISSN 2090-4770","10.20454/jmmnm.2017.1275",,"math.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider an approximate solution for the one-dimensional semilinear
singularly-perturbed boundary value problem, using the previously obtained
numerical values of the boundary value problem in the mesh points and the
representation of the exact solution using Green's function. We present an
$\varepsilon$-uniform convergence of such gained the approximate solutions, in
the maximum norm of the order $\mathcal{O}\left(N^{-1}\right)$ on the observed
domain.
  After that, the constructed approximate solution is repaired and we obtain a
solution, which also has $\varepsilon$--uniform convergence, but now of order
$\mathcal{O}\left(\ln^2N/N^2\right)$ on $[0,1].$ In the end a numerical
experiment is presented to confirm previously shown theoretical results.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 15:05:44 GMT""}]","2017-11-21"
"1705.09609","Calvin Newport","Calvin Newport","Gossip in a Smartphone Peer-to-Peer Network","Extended Abstract to Appear in the Proceedings of the ACM Conference
  on the Principles of Distributed Computing (PODC 2017)",,,,"cs.DS cs.DC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we study the fundamental problem of gossip in the mobile
telephone model: a recently introduced variation of the classical telephone
model modified to better describe the local peer-to-peer communication services
implemented in many popular smartphone operating systems. In more detail, the
mobile telephone model differs from the classical telephone model in three
ways: (1) each device can participate in at most one connection per round; (2)
the network topology can undergo a parameterized rate of change; and (3)
devices can advertise a parameterized number of bits about their state to their
neighbors in each round before connection attempts are initiated. We begin by
describing and analyzing new randomized gossip algorithms in this model under
the harsh assumption of a network topology that can change completely in every
round. We prove a significant time complexity gap between the case where nodes
can advertise $0$ bits to their neighbors in each round, and the case where
nodes can advertise $1$ bit. For the latter assumption, we present two
solutions: the first depends on a shared randomness source, while the second
eliminates this assumption using a pseudorandomness generator we prove to exist
with a novel generalization of a classical result from the study of two-party
communication complexity. We then turn our attention to the easier case where
the topology graph is stable, and describe and analyze a new gossip algorithm
that provides a substantial performance improvement for many parameters. We
conclude by studying a relaxed version of gossip in which it is only necessary
for nodes to each learn a specified fraction of the messages in the system.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 15:10:39 GMT""}]","2017-05-29"
"1705.09611","Jackson Fliss","Jackson R. Fliss, Xueda Wen, Onkar Parrikar, Chang-Tse Hsieh, Bo Han,
  Taylor L. Hughes, Robert G. Leigh","Interface Contributions to Topological Entanglement in Abelian
  Chern-Simons Theory","36 pages, 7 figures, two appendices","JHEP 09 (2017) 056","10.1007/JHEP09(2017)056",,"cond-mat.str-el hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the entanglement entropy between (possibly distinct) topological
phases across an interface using an Abelian Chern-Simons description with
topological boundary conditions (TBCs) at the interface. From a microscopic
point of view, these TBCs correspond to turning on particular gapping
interactions between the edge modes across the interface. However, in studying
entanglement in the continuum Chern-Simons description, we must confront the
problem of non-factorization of the Hilbert space, which is a standard property
of gauge theories. We carefully define the entanglement entropy by using an
extended Hilbert space construction directly in the continuum theory. We show
how a given TBC isolates a corresponding gauge invariant state in the extended
Hilbert space, and hence compute the resulting entanglement entropy. We find
that the sub-leading correction to the area law remains universal, but depends
on the choice of topological boundary conditions. This agrees with the
microscopic calculation of \cite{Cano:2014pya}. Additionally, we provide a
replica path integral calculation for the entropy. In the case when the
topological phases across the interface are taken to be identical, our
construction gives a novel explanation of the equivalence between the
left-right entanglement of (1+1)d Ishibashi states and the spatial entanglement
of (2+1)d topological phases.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 15:16:07 GMT""}]","2017-11-09"
"1705.09612","Louis Jeanjean","Tianxiang Gou, Louis Jeanjean","Multiple positive normalized solutions for nonlinear Schr\""odinger
  systems","To appear in Nonlinearity",,"10.1088/1361-6544/aab0bf",,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the existence of multiple positive solutions to the nonlinear
Schr\""odinger systems sets on $H^1(\mathbb{R}^N) \times H^1(\mathbb{R}^N)$, \[
\left\{ \begin{aligned} -\Delta u_1 &= \lambda_1 u_1 + \mu_1 |u_1|^{p_1 -2}u_1
+ \beta r_1 |u_1|^{r_1-2} u_1|u_2|^{r_2}, -\Delta u_2 &= \lambda_2 u_2 + \mu_2
|u_2|^{p_2 -2}u_2 + \beta r_2 |u_1|^{r_1} |u_2|^{r_2 -2} u_2, \end{aligned}
\right. \] under the constraint \[ \int_{\mathbb{R}^N}|u_1|^2 \, dx = a_1,\quad
\int_{\mathbb{R}^N}|u_2|^2 \, dx = a_2. \] Here $a_1, a_2 >0$ are prescribed,
$\mu_1, \mu_2, \beta>0$, and the frequencies $\lambda_1, \lambda_2$ are unknown
and will appear as Lagrange multipliers. Two cases are studied, the first when
$N \geq 1, 2 < p_1, p_2 < 2 + \frac 4N, r_1, r_2 > 1, 2 + \frac 4N < r_1 + r_2
< 2^*$, the second when $ N \geq 1, 2+ \frac 4N < p_1, p_2 < 2^*, r_1, r_2 > 1,
r_1 + r_2 < 2 + \frac 4N.$ In both cases, assuming that $\beta >0$ is
sufficiently small, we prove the existence of two positive solutions. The first
one is a local minimizer for which we establish the compactness of the
minimizing sequences and also discuss the orbital stability of the associated
standing waves. The second solution is obtained through a constrained mountain
pass and a constrained linking respectively.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 15:16:14 GMT""},{""version"":""v2"",""created"":""Fri, 23 Feb 2018 17:19:21 GMT""}]","2018-05-09"
"1705.09616","Fadhil Firyaguna","Fadhil Firyaguna, Jacek Kibilda, Carlo Galiotto and Nicola Marchetti","Coverage and Spectral Efficiency of Indoor mmWave Networks with
  Ceiling-Mounted Access Points","7 pages, 6 figures, submitted and accepted to IEEE GLOBECOM 2017",,,,"cs.IT cs.NI math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Provisioning of high throughput millimetre-wave signal to indoor areas that
potentially serve a large number of users, such as transportation hubs or
convention centres, will require dedicated indoor millimetre-wave access point
deployments. In this article, we study dense deployments of millimetre-wave
access points mounted on the ceiling and illuminating selected spots on the
ground with the use of fixed directional antennas. In this setup, the main
factor limiting signal propagation are blockages by human bodies. We evaluate
our system under a number of scenarios that take into account beamwidth of the
main-lobe, access point density, and positioning of the mobile device with
respect to the user's body. We find that both coverage and area spectral
efficiency curves exhibit non-trivial behaviour which can be classified into
four regions related to the selection of access point density, beamwidth, and
height values. Furthermore, we observe a trade-off in beamwidth design, as the
optimal beamwidth maximizes either coverage or area spectral efficiency, but
not both. Finally, when we consider different body shadowing scenarios, our
network design optimizes coverage or area spectral efficiency performance
towards either devices held in hand or worn directly against the body, as each
of the scenarios requires mutually exclusive settings of access point density
and beamwidth.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 15:21:23 GMT""},{""version"":""v2"",""created"":""Thu, 14 Sep 2017 17:59:19 GMT""},{""version"":""v3"",""created"":""Fri, 16 Feb 2018 14:56:35 GMT""}]","2018-02-19"
"1705.09619","Hadi Ravanbakhsh","Hadi Ravanbakhsh and Sriram Sankaranarayanan","Learning Lyapunov (Potential) Functions from Counterexamples and
  Demonstrations",,,"10.15607/RSS.2017.XIII.049",,"cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a technique for learning control Lyapunov (potential) functions,
which are used in turn to synthesize controllers for nonlinear dynamical
systems. The learning framework uses a demonstrator that implements a
black-box, untrusted strategy presumed to solve the problem of interest, a
learner that poses finitely many queries to the demonstrator to infer a
candidate function and a verifier that checks whether the current candidate is
a valid control Lyapunov function. The overall learning framework is iterative,
eliminating a set of candidates on each iteration using the counterexamples
discovered by the verifier and the demonstrations over these counterexamples.
We prove its convergence using ellipsoidal approximation techniques from convex
optimization. We also implement this scheme using nonlinear MPC controllers to
serve as demonstrators for a set of state and trajectory stabilization problems
for nonlinear dynamical systems. Our approach is able to synthesize relatively
simple polynomial control Lyapunov functions, and in that process replace the
MPC using a guaranteed and computationally less expensive controller.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 15:23:09 GMT""},{""version"":""v2"",""created"":""Wed, 31 May 2017 01:14:37 GMT""},{""version"":""v3"",""created"":""Thu, 1 Jun 2017 15:06:03 GMT""},{""version"":""v4"",""created"":""Thu, 5 Oct 2017 16:42:45 GMT""}]","2017-10-06"
"1705.09622","Sergey A. Trigger","S.A. Trigger","Longitudinal electric field: from Maxwell equation to non-locality in
  time and space","8 pages, 0 figures",,"10.13140/RG.2.2.16614.01601",,"physics.gen-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we use the classical electrodynamics to show that the Lorenz
gauge can be incompatible with some particular solutions of the d Alembert
equations for electromagnetic potentials. In its turn, the d Alembert equations
for the elec- tromagnetic potentials is the result of application of the Lorenz
gauge to general equations for the potentials. The last ones is the
straightforward consequence of Maxwell equations. Since the d Alembert
equations and the electromagnetic poten- tials are necessary for quantum
electrodynamics formulation, one should oblige to satisfy these equations also
in classical case. The solution of d Alembert equations, which modifies
longitudinal electric field is found. The requirement of this modifi- cation
follows from the necessity to satisfy the physical condition of impossibility
of instantaneous transferring of interaction in space.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 17:28:34 GMT""}]","2017-05-29"
"1705.09623","Yang Yang","Wei Su, Yang Yang, and Cuiling Fan","New Optimal Binary Sequences with Period $4p$ via Interleaving
  Ding-Helleseth-Lam Sequences",,"Designs, Codes & Cryptography, 2017","10.1007/s10623-017-0398-5",,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Binary sequences with optimal autocorrelation play important roles in radar,
communication, and cryptography. Finding new binary sequences with optimal
autocorrelation has been an interesting research topic in sequence design.
Ding-Helleseth-Lam sequences are such a class of binary sequences of period
$p$, where $p$ is an odd prime with $p\equiv 1(\bmod~4)$. The objective of this
letter is to present a construction of binary sequences of period $4p$ via
interleaving four suitable Ding-Helleseth-Lam sequences. This construction
generates new binary sequences with optimal autocorrelation which can not be
produced by earlier ones.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 15:28:28 GMT""}]","2017-07-26"
"1705.09624","Mikhail Dubinin","M. N. Dubinin (1), E. Yu. Petrova (1 and 2), E. O. Pozdeeva (1), M. V.
  Sumin (2), S. Yu. Vernov (1) ((1) Skobeltsyn Institute of Nuclear Physics,
  Lomonosov Moscow State University, (2) Physics Department, Lomonosov Moscow
  State University)","MSSM-inspired multifield inflation","27 pages, 4 figures, 5 tables. Version to appear in JHEP. Additions
  made to the text of the Introduction dealing with the issues of conformity of
  this multifield model and models of N=1 supergravity (pages 2-3). Added new
  inflationary scenarios, which are an artifact of such analysis (pages 11-12,
  Tables 1-4). Additional comments on page 9 and page 13. New references added","JHEP 1712 (2017) 036","10.1007/JHEP12(2017)036",,"hep-ph astro-ph.CO gr-qc hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Despite the fact that experimentally with a high degree of statistical
significance only a single Standard Model--like Higgs boson is discovered at
the LHC, extended Higgs sectors with multiple scalar fields not excluded by
combined fits of the data are more preferable theoretically for internally
consistent realistic models of particle physics. We analyze the inflationary
scenarios which could be induced by the two-Higgs doublet potential of the
Minimal Supersymmetric Standard Model (MSSM) where five scalar fields have
nonminimal couplings to gravity. Observables following from such MSSM-inspired
multifield inflation are calculated and a number of consistent inflationary
scenarios are constructed. Cosmological evolution with different initial
conditions for the multifield system leads to consequences fully compatible
with observational data on the spectral index and the tensor-to-scalar ratio.
It is demonstrated that the strong coupling approximation is precise enough to
describe such inflationary scenarios.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 15:29:56 GMT""},{""version"":""v2"",""created"":""Wed, 6 Dec 2017 18:38:42 GMT""}]","2017-12-15"
"1705.09625","Gleb Fedoseev","Gleb Fedoseev, Ko-Ju Chuang, Sergio Ioppolo, Danna Qasim, Ewine F. van
  Dishoeck, and Harold Linnartz","Formation of Glycerol through Hydrogenation of CO ice under Prestellar
  Core Conditions","Accepted for publication in The Astrophysical Journal",,"10.3847/1538-4357/aa74dc",,"astro-ph.SR astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Observational studies reveal that complex organic molecules (COMs) can be
found in various objects associated with different star formation stages. The
identification of COMs in prestellar cores, i.e., cold environments in which
thermally induced chemistry can be excluded and radiolysis is limited by cosmic
rays and cosmic ray induced UV-photons, is particularly important as this stage
sets up the initial chemical composition from which ultimately stars and
planets evolve. Recent laboratory results demonstrate that molecules as complex
as glycolaldehyde and ethylene glycol are efficiently formed on icy dust grains
via non-energetic atom addition reactions between accreting H atoms and CO
molecules, a process that dominates surface chemistry during the 'CO-freeze out
stage' in dense cores. In the present study we demonstrate that a similar
mechanism results in the formation of the biologically relevant molecule
glycerol - HOCH2CH(OH)CH2OH - a three-carbon bearing sugar alcohol necessary
for the formation of membranes of modern living cells and organelles. Our
experimental results are fully consistent with a suggested reaction scheme in
which glycerol is formed along a chain of radical-radical and radical-molecule
interactions between various reactive intermediates produced upon hydrogenation
of CO ice or its hydrogenation products. The tentative identification of the
chemically related simple sugar glyceraldehyde - HOCH2CH(OH)CHO - is discussed
as well. These new laboratory findings indicate that the proposed reaction
mechanism holds much potential to form even more complex sugar alcohols and
simple sugars.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 15:40:14 GMT""}]","2017-06-28"
"1705.09626","Artur Hakobyan","A. A. Hakobyan, L. V. Barkhudaryan, A. G. Karapetyan, G. A. Mamon, D.
  Kunth, V. Adibekyan, L. S. Aramyan, A. R. Petrosian, M. Turatto","Supernovae and their host galaxies - V. The vertical distribution of
  supernovae in disc galaxies","11 pages, 6 figures, 6 tables, accepted for publication in MNRAS",,"10.1093/mnras/stx1608",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present an analysis of the height distributions of the different types of
supernovae (SNe) from the plane of their host galaxies. We use a well-defined
sample of 102 nearby SNe appeared inside high-inclined (i > 85 deg),
morphologically non-disturbed S0-Sd host galaxies from the Sloan Digital Sky
Survey. For the first time, we show that in all the subsamples of spirals, the
vertical distribution of core-collapse (CC) SNe is about twice closer to the
plane of host disc than the distribution of SNe Ia. In Sb-Sc hosts, the
exponential scale height of CC SNe is consistent with those of the younger
stellar population in the Milky Way (MW) thin disc, while the scale height of
SNe Ia is consistent with those of the old population in the MW thick disc. We
show that the ratio of scale lengths to scale heights of the distribution of CC
SNe is consistent with those of the resolved young stars with ages from ~ 10
Myr up to ~ 100 Myr in nearby edge-on galaxies and the unresolved stellar
population of extragalactic thin discs. The corresponding ratio for SNe Ia is
consistent with the same ratios of the two populations of resolved stars with
ages from a few 100 Myr up to a few Gyr and from a few Gyr up to ~ 10 Gyr, as
well as with the unresolved population of the thick disc. These results can be
explained considering the age-scale height relation of the distribution of
stellar population and the mean age difference between Type Ia and CC SNe
progenitors.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 15:41:19 GMT""},{""version"":""v2"",""created"":""Thu, 22 Jun 2017 19:50:47 GMT""}]","2017-08-09"
"1705.09627","Hong Zhang","Hong Zhang","Scalar curvature flow on S^n to a prescribed sign-changing function","23 pages",,,,"math.AP math.DG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we consider the problem of prescribing scalar curvature on
n-sphere. Assume that the candidate curvature function $f$, which is allowed to
change sign, satisfies some kind of Morse index or symmetry condition. By
studying the well-known scalar curvature flow, we are able to prove that the
flow converges to a metric with the prescribed function $f$ as its scalar
curvature.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 15:55:49 GMT""}]","2017-05-29"
"1705.09628","Yen-Huan  Li","Yen-Huan Li and Volkan Cevher","A General Convergence Result for the Exponentiated Gradient Method","18 pages, 2 figures",,,,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The batch exponentiated gradient (EG) method provides a principled approach
to convex smooth minimization on the probability simplex or the space of
quantum density matrices. However, it is not always guaranteed to converge.
Existing convergence analyses of the EG method require certain quantitative
smoothness conditions on the loss function, e.g., Lipschitz continuity of the
loss function or its gradient, but those conditions may not hold in important
applications. In this paper, we prove that the EG method with Armijo line
search always converges for any convex loss function with a locally Lipschitz
continuous gradient. Because of our convergence guarantee, the EG method with
Armijo line search becomes the fastest guaranteed-to-converge algorithm for
maximum-likelihood quantum state estimation, on the real datasets we have.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 15:55:59 GMT""}]","2017-05-29"
"1705.09629","Daniel G. Figueroa","Daniel G. Figueroa and Mikhail Shaposhnikov","Lattice implementation of Abelian gauge theories with Chern-Simons
  number and an axion field","30 pages",,"10.1016/j.nuclphysb.2017.12.001","CERN-TH-2017-116","hep-lat astro-ph.CO hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Real time evolution of classical gauge fields is relevant for a number of
applications in particle physics and cosmology, ranging from the early Universe
to dynamics of quark-gluon plasma. We present a lattice formulation of the
interaction between a $shift$-symmetric field and some $U(1)$ gauge sector,
$a(x)\tilde{F}_{\mu\nu}F^{\mu\nu}$, reproducing the continuum limit to order
$\mathcal{O}(dx_\mu^2)$ and obeying the following properties: (i) the system is
gauge invariant and (ii) shift symmetry is exact on the lattice. For this end
we construct a definition of the {\it topological number density} $Q =
\tilde{F}_{\mu\nu}F^{\mu\nu}$ that admits a lattice total derivative
representation $Q = \Delta_\mu^+ K^\mu$, reproducing to order
$\mathcal{O}(dx_\mu^2)$ the continuum expression $Q = \partial_\mu K^\mu
\propto \vec E \cdot \vec B$. If we consider a homogeneous field $a(x) = a(t)$,
the system can be mapped into an Abelian gauge theory with Hamiltonian
containing a Chern-Simons term for the gauge fields. This allow us to study in
an accompanying paper the real time dynamics of fermion number non-conservation
(or chirality breaking) in Abelian gauge theories at finite temperature. When
$a(x) = a(\vec x,t)$ is inhomogeneous, the set of lattice equations of motion
do not admit however a simple explicit local solution (while preserving an
$\mathcal{O}(dx_\mu^2)$ accuracy). We discuss an iterative scheme allowing to
overcome this difficulty.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 15:58:33 GMT""}]","2018-03-14"
"1705.09630","Riddhi Bandyopadhyay","Riddhi Bandyopadhyay, Mahendra K. Verma","Discrete Symmetries in Dynamo Reversals","12 pages, 5 figures, Accepted for publication in Physics of Plasmas","Phys. Plasmas 24 (2017) 062307","10.1063/1.4985307",,"physics.plasm-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Quantification of the velocity and magnetic field reversals in dynamo remains
an interesting challenge. In this paper, using group-theoretic analysis, we
classify the reversing and non-reversing Fourier modes during a dynamo reversal
in a Cartesian box. Based on odd-even parities of the wavenumber indices, we
categorise the velocity and magnetic Fourier modes into 8 classes each. Then,
using the properties of the nonlinear interactions in magnetohydrodynamics, we
show that these 16 elements form Klein 16-group $Z_2 \times Z_2 \times Z_2
\times Z_2$. We demonstrate that field reversals in a class of Taylor-Green
dynamo, as well as the reversals in earlier experiments and models, belong to
one of the classes predicted by our group-theoretic arguments.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 15:58:47 GMT""}]","2017-07-10"
"1705.09658","David Bravo Bergu\~no","David Bravo-Bergu\~no, Riccardo Mereu, Robert Bruce Vogelaar, Fabio
  Inzoli","Fluid-dynamics in the Borexino Neutrino Detector: behavior of a
  pseudo-stably-stratified, near-equilibrium closed system under asymmetrical,
  changing boundary conditions","14 pages, 6 figures, 1 table",,,,"physics.ins-det hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The strategy to install Borexino's Thermal Monitoring and Management System
(BTMMS) successfully stabilized the thermal environment inside the Borexino
neutrino observatory, which is understood to be a necessary step to improve and
minimize radioactive background contamination inside the active volume of the
detector, allowing for it to achieve better sensitivity in the regions of
interest. Two-dimensional numerical simulations to achieve a proper
understanding of Borexino's fluid-dynamics were developed and optimized for
different regions and periods of interest, focusing on the most critical
effects that were identified as influencing background concentrations.
Literature experimental case studies were reproduced to benchmark the method
and settings, and a Borexino-specific benchmark was constructed in order to
validate the model's thermal transport. Finally, fully-convective models were
implemented to understand general and specific fluid motions impacting the
active detector volume.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 15:00:59 GMT""}]","2017-05-30"
"1705.10014","Lijun Zhang","Xin-Gang Zhao, Ji-Hui Yang, Yuhao Fu, Dongwen Yang, Qiaoling Xu,
  Liping Yu, Su-Huai Wei and Lijun Zhang","Design of Lead-Free Inorganic Halide Perovskites for Solar Cells via
  Cation-Transmutation","pages 19, 4 figures in main text","J. Am. Chem. Soc. 139, 2630 (2017)","10.1021/jacs.6b09645",,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Hybrid organic-inorganic halide perovskites with the prototype material of
CH$_{3}$NH$_{3}$PbI$_{3}$ have recently attracted intense interest as low-cost
and high-performance photovoltaic absorbers. Despite the high power conversion
efficiency exceeding 20% achieved by their solar cells, two key issues -- the
poor device stabilities associated with their intrinsic material instability
and the toxicity due to water soluble Pb$^{2+}$ -- need to be resolved before
large-scale commercialization. Here, we address these issues by exploiting the
strategy of cation-transmutation to design stable inorganic Pb-free halide
perovskites for solar cells. The idea is to convert two divalent Pb$^{2+}$ ions
into one monovalent M$^{+}$ and one trivalent M$^{3+}$ ions, forming a rich
class of quaternary halides in double-perovskite structure. We find through
first-principles calculations this class of materials have good phase stability
against decomposition and wide-range tunable optoelectronic properties. With
photovoltaic-functionality-directed materials screening, we identify eleven
optimal materials with intrinsic thermodynamic stability, suitable band gaps,
small carrier effective masses, and low excitons binding energies as promising
candidates to replace Pb-based photovoltaic absorbers in perovskite solar
cells. The chemical trends of phase stabilities and electronic properties are
also established for this class of materials, offering useful guidance for the
development of perovskite solar cells fabricated with them.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 09:01:53 GMT""}]","2017-05-30"
"1705.10190","Shiyun Chen","Shiyun Chen, Ery Arias-Castro","Sequential Multiple Testing","arXiv admin note: text overlap with arXiv:1604.07520",,,,"math.ST stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study an online multiple testing problem where the hypotheses arrive
sequentially in a stream. The test statistics are independent and assumed to
have the same distribution under their respective null hypotheses. We
investigate two procedures LORD and LOND, proposed by (Javanmard and Montanari,
2015), which are proved to control the FDR in an online manner. In some
(static) model, we show that LORD is optimal in some asymptotic sense, in
particular as powerful as the (static) Benjamini-Hochberg procedure to first
asymptotic order. We also quantify the performance of LOND. Some numerical
experiments complement our theory.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 18:08:05 GMT""}]","2017-05-30"
"1705.10191","Michael Strickland","Mubarak Alqahtani, Mohammad Nopoush, Radoslaw Ryblewski, and Michael
  Strickland","Anisotropic hydrodynamic modeling of 2.76 TeV Pb-Pb collisions","31 pages, 9 figures. v2 - improvements to HBT calculation + typos
  fixed; PRC version. arXiv admin note: text overlap with arXiv:1703.05808","Phys. Rev. C 96, 044910 (2017)","10.1103/PhysRevC.96.044910",,"nucl-th hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We compare phenomenological results from 3+1d quasiparticle anisotropic
hydrodynamics (aHydroQP) with experimental data collected in LHC 2.76 TeV Pb-Pb
collisions. In particular, we present comparisons of particle spectra, average
transverse momentum, elliptic flow, and HBT radii. The aHydroQP model relies on
the introduction of a single temperature-dependent quasiparticle mass which is
fit to lattice QCD data. By taking moments of the resulting Boltzmann equation,
we obtain the dynamical equations used in the hydrodynamic stage which include
the effects of both shear and bulk viscosities. At freeze-out, we use
anisotropic Cooper-Frye freeze-out performed on a fixed-energy-density
hypersurface to convert to hadrons. To model the production and decays of the
hadrons we use THERMINATOR 2 which is customized to sample from ellipsoidal
momentum-space distribution functions. Using smooth Glauber initial conditions,
we find very good agreement with many heavy-ion collision observables.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 23:27:46 GMT""},{""version"":""v2"",""created"":""Mon, 23 Oct 2017 20:18:19 GMT""}]","2017-10-26"
"1705.10192","Ian Jordy Lopez Diaz","Ian Jordy Lopez Diaz and Nilton da Silva Branco","Monte Carlo study of an anisotropic Ising multilayer with
  antiferromagnetic interlayer couplings","13 figures. arXiv admin note: text overlap with arXiv:1607.05221",,"10.1016/j.physa.2017.09.005",,"cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a Monte Carlo study of the magnetic properties of an Ising
multilayer ferrimagnet. The system consists of two kinds of non-equivalent
planes, one of which is site-diluted. All intralayer couplings are
ferromagnetic. The different kinds of planes are stacked alternately and the
interlayer couplings are antiferromagnetic. We perform the simulations using
the Wolff algorithm and employ multiple histogram reweighting and finite-size
scaling methods to analyze the data with special emphasis on the study of
compensation phenomena. Compensation and critical temperatures of the system
are obtained as functions of the Hamiltonian parameters and we present a
detailed discussion about the contribution of each parameter to the presence or
absence of the compensation effect. A comparison is presented between our
results and those reported in the literature for the same model using the pair
approximation. We also compare our results with those obtained through both the
pair approximation and Monte Carlo simulations for the bilayer system.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 21:30:52 GMT""},{""version"":""v2"",""created"":""Fri, 8 Sep 2017 22:00:24 GMT""}]","2017-09-12"
"1705.10193","Miguel Pi\~nar","Clotilde Mart\'inez and Miguel A. Pi\~nar","Asymptotic behaviour of the Christoffel functions on the Unit Ball in
  the presence of a Mass on the Sphere","arXiv admin note: text overlap with arXiv:1512.01064",,,,"math.CA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a family of mutually orthogonal polynomials on the unit ball with
respect to an inner product which includes a mass uniformly distributed on the
sphere. First, connection formulas relating these multivariate orthogonal
polynomials and the classical ball polynomials are obtained. Then, using the
representation formula for these polynomials in terms of spherical harmonics
analytic properties will be deduced. Finally, we analyze the asymptotic
behaviour of the Christoffel functions.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 19:20:48 GMT""}]","2017-05-30"
"1705.10194","Feng Nan","Feng Nan, Venkatesh Saligrama","Adaptive Classification for Prediction Under a Budget","arXiv admin note: substantial text overlap with arXiv:1704.07505",,,,"stat.ML cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a novel adaptive approximation approach for test-time
resource-constrained prediction. Given an input instance at test-time, a gating
function identifies a prediction model for the input among a collection of
models. Our objective is to minimize overall average cost without sacrificing
accuracy. We learn gating and prediction models on fully labeled training data
by means of a bottom-up strategy. Our novel bottom-up method first trains a
high-accuracy complex model. Then a low-complexity gating and prediction model
are subsequently learned to adaptively approximate the high-accuracy model in
regions where low-cost models are capable of making highly accurate
predictions. We pose an empirical loss minimization problem with cost
constraints to jointly train gating and prediction models. On a number of
benchmark datasets our method outperforms state-of-the-art achieving higher
accuracy for the same cost.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 12:28:42 GMT""}]","2017-05-30"
"1705.10197","Scientific Information Service CERN","A. Bignami, F. Broggi, M. Brugger, F. Cerutti, L.S. Esposito, A.
  Lechner, N.V. Mokhov, I.L. Rakhno, C. Santini, E. Skordis and I.S. Tropin","Energy Deposition and Radiation to Electronics","16 pages, chapter 10 in High-Luminosity Large Hadron Collider
  (HL-LHC) : Preliminary Design Report. arXiv admin note: text overlap with
  arXiv:1504.00594","CERN Yellow Report CERN 2015-005, pp.171-186","10.5170/CERN-2015-005.171",,"physics.acc-ph","http://creativecommons.org/licenses/by/4.0/","  Chapter 10 in High-Luminosity Large Hadron Collider (HL-LHC) : Preliminary
Design Report. The Large Hadron Collider (LHC) is one of the largest scientific
instruments ever built. Since opening up a new energy frontier for exploration
in 2010, it has gathered a global user community of about 7,000 scientists
working in fundamental particle physics and the physics of hadronic matter at
extreme temperature and density. To sustain and extend its discovery potential,
the LHC will need a major upgrade in the 2020s. This will increase its
luminosity (rate of collisions) by a factor of five beyond the original design
value and the integrated luminosity (total collisions created) by a factor ten.
The LHC is already a highly complex and exquisitely optimised machine so this
upgrade must be carefully conceived and will require about ten years to
implement. The new configuration, known as High Luminosity LHC (HL-LHC), will
rely on a number of key innovations that push accelerator technology beyond its
present limits. Among these are cutting-edge 11-12 tesla superconducting
magnets, compact superconducting cavities for beam rotation with ultra-precise
phase control, new technology and physical processes for beam collimation and
300 metre-long high-power superconducting links with negligible energy
dissipation. The present document describes the technologies and components
that will be used to realise the project and is intended to serve as the basis
for the detailed engineering design of HL-LHC.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 09:27:37 GMT""}]","2017-05-30"
"1705.10198","Mohammad Hadi","Mohammad Hadi, Mohammad Reza Pakravan","Energy-Efficient Transponder Configuration for FMF-based Elastic Optical
  Networks","4 pages, 4 figures. arXiv admin note: text overlap with
  arXiv:1705.06891",,,,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose an energy-efficient procedure for transponder configuration in
FMF-based elastic optical networks in which quality of service and physical
constraints are guaranteed and joint optimization of transmit optical power,
temporal, spatial and spectral variables are addressed. We use geometric
convexification techniques to provide convex representations for quality of
service, transponder power consumption and transponder configuration problem.
Simulation results show that our convex formulation is considerably faster than
its mixed-integer nonlinear counterpart and its ability to optimize transmit
optical power reduces total transponder power consumption up to 32%. We also
analyze the effect of mode coupling and number of available modes on power
consumption of different network elements.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 08:05:09 GMT""}]","2017-05-30"
"1705.10199","Gavriil Shchedrin","Gavriil Shchedrin, Daniel Jaschke, and Lincoln D. Carr","Absence of Landau damping in driven three-component Bose-Einstein
  condensate in optical lattices",,"Scientific Reports 8, 11523 (2018)","10.1038/s41598-018-29454-y",,"cond-mat.quant-gas","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We explore the quantum many-body physics of a three-component Bose-Einstein
condensate (BEC) in an optical lattices driven by laser fields in $V$ and
$\Lambda$ configurations. We obtain exact analytical expressions for the energy
spectrum and amplitudes of elementary excitations, and discover symmetries
among them. We demonstrate that the applied laser fields induce a gap in the
otherwise gapless Bogoliubov spectrum. We find that Landau damping of the
collective modes above the energy of the gap is carried by laser-induced roton
modes and is considerably suppressed compared to the phonon-mediated damping
endemic to undriven scalar BECs.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 06:46:43 GMT""},{""version"":""v2"",""created"":""Wed, 31 May 2017 01:41:21 GMT""}]","2018-08-28"
"1705.10200","Vera Serganova","Elena Poletaeva and Vera Serganova","On the finite $W$-algebra for the Lie superalgebra Q(N) in the
  non-regular case","arXiv admin note: text overlap with arXiv:1403.3866",,"10.1063/1.4993709",,"math.RT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we study the finite W-algebra for the queer Lie superalgebra
Q(n) associated with the non-regular even nilpotent coadjoint orbits in the
case when the corresponding nilpotent element has Jordan blocks each of size l.
We prove that this finite W-algebra is isomorphic to a quotient of the
super-Yangian of Q({n/l})
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 04:34:43 GMT""}]","2017-11-22"
"1705.10202","Niek Tax","Niek Tax, Natalia Sidorova, Reinder Haakma, Wil M.P. van der Aalst","Mining Process Model Descriptions of Daily Life through Event
  Abstraction","arXiv admin note: substantial text overlap with arXiv:1606.07283","Studies in Computational Intelligence, 751 (2017) 83-104","10.1007/978-3-319-69266-1_5",,"cs.LG cs.AI cs.DB","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Process mining techniques focus on extracting insight in processes from event
logs. Process mining has the potential to provide valuable insights in
(un)healthy habits and to contribute to ambient assisted living solutions when
applied on data from smart home environments. However, events recorded in smart
home environments are on the level of sensor triggers, at which process
discovery algorithms produce overgeneralizing process models that allow for too
much behavior and that are difficult to interpret for human experts. We show
that abstracting the events to a higher-level interpretation can enable
discovery of more precise and more comprehensible models. We present a
framework for the extraction of features that can be used for abstraction with
supervised learning methods that is based on the XES IEEE standard for event
logs. This framework can automatically abstract sensor-level events to their
interpretation at the human activity level, after training it on training data
for which both the sensor and human activity events are known. We demonstrate
our abstraction framework on three real-life smart home event logs and show
that the process models that can be discovered after abstraction are more
precise indeed.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 20:32:56 GMT""}]","2018-01-11"
"1705.10256","Alberto Franceschini","Alberto Franceschini and Giulia Rodighiero","The extragalactic background light revisited and the cosmic
  photon-photon opacity","19 pages, tables included, to appear in Astronomy and Astrophysics","A&A 603, A34 (2017)","10.1051/0004-6361/201629684",,"astro-ph.HE astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In addition to its relevant astrophysical and cosmological significance, the
Extragalactic Background Light (EBL) is a fundamental source of opacity for
cosmic high energy photons, as well as a limitation for the propagation of
high-energy particles in the Universe. We review our previously published
determinations of the EBL photon density in the Universe and its evolution with
cosmic time, in the light of recent surveys of IR sources at long wavelengths.
We exploit deep survey observations by the Herschel Space Observatory and the
Spitzer telescope, matched to optical and near-IR photometric and spectroscopic
data, to re-estimate number counts and luminosity functions longwards of a few
microns, and the contribution of resolved sources to the EBL. These new data
indicate slightly lower photon densities in the mid- and far-infrared and
sub-millimeter compared to previous determinations. This implies slightly lower
cosmic opacity for photon-photon interactions. The new data do not modify
previously published EBL modeling in the UV-optical and near-IR up to several
microns, while reducing the photon density at longer wavelengths. This improved
model of the EBL alleviates some tension that had emerged in the interpretation
of the highest-energy TeV observations of local \textit{blazar}s, reducing the
case for new physics beyond the standard model (like violations of the Lorenz
Invariance, LIV, at the highest particle energies), or for exotic astrophysics,
that had sometimes been called for to explain it. Applications of this improved
EBL model on current data are considered, as well as perspectives for future
instrumentation, the Cherenkov Telescope Array (CTA) in particular.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 07:20:18 GMT""}]","2017-07-05"
"1705.10274","Andrew Norris","Xiaoshi Su and Andrew N. Norris and Colby W. Cushing and Michael R.
  Haberman and Preston S. Wilson","Broadband focusing of underwater sound using a transparent pentamode
  lens","10 pages, 16 figures",,,,"physics.class-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We report an inhomogeneous acoustic metamaterial lens based on spatial
variation of refractive index for broadband focusing of underwater sound. The
index gradient follows a modified hyperbolic secant profile designed to reduce
aberration and suppress side lobes. The gradient index (GRIN) lens is comprised
of transversely isotropic hexagonal microstructures with tunable quasi-static
bulk modulus and mass density. In addition, the unit cells are
impedance-matched to water and have in-plane shear modulus negligible compared
to the effective bulk modulus. The flat GRIN lens is fabricated by cutting
hexagonal centimeter scale hollow microstructures in aluminum plates, which are
then stacked and sealed from the exterior water. Broadband focusing effects are
observed within the homogenization regime of the lattice in both finite element
(FEM) simulations and underwater measurements (20-40 kHz). This design approach
has potential applications in medical ultrasound imaging and underwater
acoustic communications.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 13:02:30 GMT""}]","2017-05-30"
"1705.10275","Qingzhong (Quincy) Deng","Qingzhong Deng, Lu Liu, Zhiping Zhou","Experimental demonstration of an ultra-compact on-chip polarization
  controlling structure","2 pages, 4 figures",,,,"physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We demonstrated a novel on-chip polarization controlling structure,
fabricated by standard 0.18-um foundry technology. It achieved polarization
rotation with a size of 0.726 um * 5.27 um and can be easily extended into
dynamic polarization controllers.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 07:29:25 GMT""}]","2017-05-30"
"1705.10278","Thomas Schenkel","John J. Barnard and Thomas Schenkel","Materials processing with intense pulsed ion beams and masked targets","16 pages, 11 figures",,,,"physics.app-ph cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Intense, pulsed ion beams locally heat materials and deliver dense electronic
excitations that can induce materials modifications and phase transitions.
Materials properties can potentially be stabilized by rapid quenching. Pulsed
ion beams with (sub-) ns pulse lengths have recently become available for
materials processing. Here, we optimize mask geometries for local modification
of materials by intense ion pulses. The goal is to rapidly excite targets
volumetrically to the point where a phase transition or local lattice
reconstruction is induced followed by rapid cooling that stabilizes desired
materials properties fast enough before the target is altered or damaged by e.
g. hydrodynamic expansion. We performed HYDRA simulations that calculate peak
temperatures for a series of excitation conditions and cooling rates of silicon
targets with micro-structured masks and compare these to a simple analytical
model. The model gives scaling laws that can guide the design of targets over a
wide range of pulsed ion beam parameters.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 00:27:08 GMT""}]","2017-05-30"
"1705.10597","Hugo Hernandez-Salda\~na","H. Hern\'andez-Salda\~na","The Locus of the apices of projectile trajectories under constant drag","8 pages, 4 figures, two columns version",,"10.1088/1361-6404/aa8c40",,"physics.gen-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present an analytical solution for the projectile coplanar motion under
constant drag parametrised by the velocity angle. We found the locus formed by
the apices of the projectile trajectories. The range and time of flight are
obtained numerically and we find that the optimal launching angle is smaller
than in the free drag case. This is a good example of problems with constant
dissipation of energy that includes curvature, and it is proper for
intermediate courses of mechanics.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 21:30:20 GMT""}]","2017-11-22"
"1705.10654","Mahmood Mamivand","Mahmood Mamivand, Ying Yang, Jeremy Busby, Dane Morgan","Integrated Modeling of Second Phase Precipitation in Cold-Worked 316
  Stainless Steels under Irradiation",,"Acta Materialia, Volume 130, 15 May 2017, Pages 94 to 110",,,"cond-mat.mtrl-sci physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The current work combines the Cluster Dynamics (CD) technique and
CALPHAD-based precipitation modeling to address the second phase precipitation
in cold-worked (CW) 316 stainless steels (SS) under irradiation at 300-400 C.
CD provides the radiation enhanced diffusion and dislocation evolution as
inputs for the precipitation model. The CALPHAD-based precipitation model
treats the nucleation, growth and coarsening of precipitation processes based
on classical nucleation theory and evolution equations, and simulates the
composition, size and size distribution of precipitate phases. We benchmark the
model against available experimental data at fast reactor conditions (9.4 x
10^-7 dpa/s and 390 C) and then use the model to predict the phase instability
of CW 316 SS under light water reactor (LWR) extended life conditions (7 x
10^-8 dpa/s and 275 C). The model accurately predicts the gamma-prime (Ni3Si)
precipitation evolution under fast reactor conditions and that the formation of
this phase is dominated by radiation enhanced segregation. The model also
predicts a carbide volume fraction that agrees well with available experimental
data from a PWR reactor but is much higher than the volume fraction observed in
fast reactors. We propose that radiation enhanced dissolution and/or carbon
depletion at sinks that occurs at high flux could be the main sources of this
inconsistency. The integrated model predicts ~1.2% volume fraction for carbide
and ~3.0% volume fraction for gamma-prime for typical CW 316 SS (with 0.054
wt.% carbon) under LWR extended life conditions. This work provides valuable
insights into the magnitudes and mechanisms of precipitation in irradiated CW
316 SS for nuclear applications.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 04:38:10 GMT""}]","2017-05-31"
"1705.10655","Luis A. Martinez-Martinez","Luis A. Mart\'inez-Mart\'inez, Raphael F. Ribeiro, Jorge
  Campos-Gonz\'alez-Angulo, Joel Yuen-Zhou","Can ultrastrong coupling change ground state chemical reactions?",,,"10.1021/acsphotonics.7b00610",,"physics.chem-ph cond-mat.mes-hall cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent advancements on the fabrication of organic micro- and nanostructures
have permitted the strong collective light-matter coupling regime to be reached
with molecular materials. Pioneering works in this direction have shown the
effects of this regime in the excited state reactivity of molecular systems and
at the same time has opened up the question of whether it is possible to
introduce any modifications in the electronic ground energy landscape which
could affect chemical thermodynamics and/or kinetics. In this work, we use a
model system of many molecules coupled to a surface-plasmon field to gain
insight on the key parameters which govern the modifications of the
ground-state Potential Energy Surface (PES). Our findings confirm that the
energetic changes per molecule are determined by single-molecule-light
couplings which are essentially local, in contrast with those of the
electronically excited states, for which energetic corrections are of a
collective nature. Still, we reveal some intriguing quantum-coherent effects
associated with pathways of concerted reactions, where two or more molecules
undergo reactions simultaneously, and which can be of relevance in low-barrier
reactions. Finally, we also explore modifications to nonadiabatic dynamics and
conclude that, for this particular model, the presence of a large number of
dark states yields negligible changes. Our study reveals new possibilities as
well as limitations for the emerging field of polariton chemistry.
","[{""version"":""v1"",""created"":""Thu, 25 May 2017 21:15:11 GMT""},{""version"":""v2"",""created"":""Mon, 12 Jun 2017 21:48:58 GMT""}]","2018-04-12"
"1705.10665","Z Yan","Zhenya Yan","Initial-boundary value problem for an integrable spin-1 Gross-Pitaevskii
  system with a 4x4 Lax pair on a finite interval","70 pages, 3 figures. arXiv admin note: substantial text overlap with
  arXiv:1704.08561, arXiv:1704.08534","J. Math. Phys. 60, 083511 (2019)","10.1063/1.5058722",,"nlin.SI math-ph math.AP math.MP quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we explore the initial-boundary value (IBV) problem for an
integrable spin-1 Gross-Pitaevskii system with a 4x4 Lax pair on the finite
interval by extending the Fokas unified transform approach. The solution of
this system can be expressed in terms of the solution of a 4x4 matrix
Riemann-Hilbert (RH) problem formulated in the complex k-plane. Furthermore,
the relevant jump matrices with explicit (x, t)-dependence of the matrix RH
problem can be explicitly found via three spectral functions {s(k), S(k),
S_L(k)} arising from the initial data and the Dirichlet-Neumann boundary
conditions at x=0 and x=L, respectively. The global relation is also found to
deduce two distinct but equivalent types of representations (i.e., one via the
large $k$ of asymptotics of the eigenfunctions and another one in terms of the
Gel'fand-Levitan-Marchenko (GLM) approach) for the Dirichlet and Neumann
boundary value problems. In particular, the formulae for IBV problems on the
finite interval can reduce to ones on a half-line as the length $L$ of the
interval approaches to infinity. Moreover, we also present the linearizable
boundary conditions for the GLM representations.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 00:56:23 GMT""}]","2021-11-24"
"1705.10667","Mingsheng Long","Mingsheng Long, Zhangjie Cao, Jianmin Wang, Michael I. Jordan","Conditional Adversarial Domain Adaptation","32nd Conference on Neural Information Processing Systems (NeurIPS
  2018), Montreal, Canada",,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Adversarial learning has been embedded into deep networks to learn
disentangled and transferable representations for domain adaptation. Existing
adversarial domain adaptation methods may not effectively align different
domains of multimodal distributions native in classification problems. In this
paper, we present conditional adversarial domain adaptation, a principled
framework that conditions the adversarial adaptation models on discriminative
information conveyed in the classifier predictions. Conditional domain
adversarial networks (CDANs) are designed with two novel conditioning
strategies: multilinear conditioning that captures the cross-covariance between
feature representations and classifier predictions to improve the
discriminability, and entropy conditioning that controls the uncertainty of
classifier predictions to guarantee the transferability. With theoretical
guarantees and a few lines of codes, the approach has exceeded state-of-the-art
results on five datasets.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 00:50:36 GMT""},{""version"":""v2"",""created"":""Sat, 10 Feb 2018 00:39:20 GMT""},{""version"":""v3"",""created"":""Fri, 14 Dec 2018 03:57:28 GMT""},{""version"":""v4"",""created"":""Sat, 29 Dec 2018 16:43:57 GMT""}]","2019-01-01"
"1705.11078","Scientific Information Service CERN","S. Claudet and L. Tavian","Cryogenics for the HL-LHC","9 pages, chapter 9 in High-Luminosity Large Hadron Collider (HL-LHC)
  : Preliminary Design Report","CERN Yellow Report CERN 2015-005, pp.161-169","10.5170/CERN-2015-005.161",,"physics.acc-ph","http://creativecommons.org/licenses/by/4.0/","  Chapter 9 in High-Luminosity Large Hadron Collider (HL-LHC) : Preliminary
Design Report. The Large Hadron Collider (LHC) is one of the largest scientific
instruments ever built. Since opening up a new energy frontier for exploration
in 2010, it has gathered a global user community of about 7,000 scientists
working in fundamental particle physics and the physics of hadronic matter at
extreme temperature and density. To sustain and extend its discovery potential,
the LHC will need a major upgrade in the 2020s. This will increase its
luminosity (rate of collisions) by a factor of five beyond the original design
value and the integrated luminosity (total collisions created) by a factor ten.
The LHC is already a highly complex and exquisitely optimised machine so this
upgrade must be carefully conceived and will require about ten years to
implement. The new configuration, known as High Luminosity LHC (HL-LHC), will
rely on a number of key innovations that push accelerator technology beyond its
present limits. Among these are cutting-edge 11-12 tesla superconducting
magnets, compact superconducting cavities for beam rotation with ultra-precise
phase control, new technology and physical processes for beam collimation and
300 metre-long high-power superconducting links with negligible energy
dissipation. The present document describes the technologies and components
that will be used to realise the project and is intended to serve as the basis
for the detailed engineering design of HL-LHC.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 09:23:27 GMT""}]","2017-06-01"
"1705.11079","Scientific Information Service CERN","P. Fessia and S. Weisz","Integration and (De-)installation","8 pages, chapter 15 in High-Luminosity Large Hadron Collider (HL-LHC)
  : Preliminary Design Report","CERN Yellow Report CERN 2015-005, pp.229-236","10.5170/CERN-2015-005.229",,"physics.acc-ph","http://creativecommons.org/licenses/by/4.0/","  Chapter 15 in High-Luminosity Large Hadron Collider (HL-LHC) : Preliminary
Design Report. The Large Hadron Collider (LHC) is one of the largest scientific
instruments ever built. Since opening up a new energy frontier for exploration
in 2010, it has gathered a global user community of about 7,000 scientists
working in fundamental particle physics and the physics of hadronic matter at
extreme temperature and density. To sustain and extend its discovery potential,
the LHC will need a major upgrade in the 2020s. This will increase its
luminosity (rate of collisions) by a factor of five beyond the original design
value and the integrated luminosity (total collisions created) by a factor ten.
The LHC is already a highly complex and exquisitely optimised machine so this
upgrade must be carefully conceived and will require about ten years to
implement. The new configuration, known as High Luminosity LHC (HL-LHC), will
rely on a number of key innovations that push accelerator technology beyond its
present limits. Among these are cutting-edge 11-12 tesla superconducting
magnets, compact superconducting cavities for beam rotation with ultra-precise
phase control, new technology and physical processes for beam collimation and
300 metre-long high-power superconducting links with negligible energy
dissipation. The present document describes the technologies and components
that will be used to realise the project and is intended to serve as the basis
for the detailed engineering design of HL-LHC.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 09:44:38 GMT""}]","2017-06-01"
"1706.00268","Cedric Josz","C\'edric Josz","On the Relationship Between Real and Complex Linear Systems",,,,,"math.RA math.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the problem of solving a linear system of equations which
involves complex variables and their conjugates. We characterize when it
reduces to a complex linear system, that is, a system involving only complex
variables (and not their conjugates). In that case, we show how to construct
the complex linear system. Interestingly, this provides a new insight on the
relationship between real and complex linear systems. In particular, any real
symmetric linear system of equations can be solved via a complex linear system
of equations. Numerical illustrations are provided. The mathematics in this
manuscript constitute an exciting interplay between Schur's complement,
Cholesky's factorization, and Cauchy's interlace theorem.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 12:49:51 GMT""}]","2017-06-02"
"1706.01758","Ming Li","Ming Li, Peilun Xiao, Ju Zhang","A WL-SPPIM Semantic Model for Document Classification","7pages, 5figures, Keywords: LDA, SPPIM, word embedding, low
  frequency, document classification",,,,"cs.CL cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we explore SPPIM-based text classification method, and the
experiment reveals that the SPPIM method is equal to or even superior than SGNS
method in text classification task on three international and standard text
datasets, namely 20newsgroups, Reuters52 and WebKB. Comparing to SGNS, although
SPPMI provides a better solution, it is not necessarily better than SGNS in
text classification tasks. Based on our analysis, SGNS takes into the
consideration of weight calculation during decomposition process, so it has
better performance than SPPIM in some standard datasets. Inspired by this, we
propose a WL-SPPIM semantic model based on SPPIM model, and experiment shows
that WL-SPPIM approach has better classification and higher scalability in the
text classification task compared with LDA, SGNS and SPPIM approaches.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 08:03:10 GMT""}]","2017-06-07"
"1706.05932","Alessandro Fontana","Alessandro Fontana","A deep learning-inspired model of the hippocampus as storage device of
  the brain extended dataset",,,,,"q-bio.NC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The standard model of memory consolidation foresees that memories are
initially recorded in the hippocampus, while features that capture higher-level
generalisations of data are created in the cortex, where they are stored for a
possibly indefinite period of time. Computer scientists have sought inspiration
from nature to build machines that exhibit some of the remarkable properties
present in biological systems. One of the results of this effort is represented
by artificial neural networks, a class of algorithms that represent the state
of the art in many artificial intelligence applications. In this work, we
reverse the inspiration flow and use the experience obtained from neural
networks to gain insight into the design of brain architecture and the
functioning of memory. Our starting observation is that neural networks learn
from data and need to be exposed to each data record many times during
learning: this requires the storage of the entire dataset in computer memory.
Our thesis is that the same holds true for the brain and the main role of the
hippocampus is to store the ""brain dataset"", from which high-level features are
learned and encoded in cortical neurons.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 15:21:43 GMT""}]","2017-06-20"
"1706.06013","Alessandro Guidotti","Oltjon Kodheli, Alessandro Guidotti, Alessandro Vanelli-Coralli","Integration of Satellites in 5G through LEO Constellations","Submitted to IEEE Global Communications Conference (GLOBECOM) 2017",,,,"cs.NI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The standardization of 5G systems is entering in its critical phase, with
3GPP that will publish the PHY standard by June 2017. In order to meet the
demanding 5G requirements both in terms of large throughput and global
connectivity, Satellite Communications provide a valuable resource to extend
and complement terrestrial networks. In this context, we consider a
heterogeneous architecture in which a LEO mega-constellation satellite system
provides backhaul connectivity to terrestrial 5G Relay Nodes, which create an
on-ground 5G network. Since large delays and Doppler shifts related to
satellite channels pose severe challenges to terrestrial-based systems, in this
paper we assess their impact on the future 5G PHY and MAC layer procedures. In
addition, solutions are proposed for Random Access, waveform numerology, and
HARQ procedures.
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 07:14:58 GMT""},{""version"":""v2"",""created"":""Fri, 30 Jun 2017 08:01:39 GMT""}]","2017-07-03"
"1707.08642","Yurii Spirichev Alexeyevich","Yurii A. Spirichev","About the Abraham force in a conducting medium","6 pages",,,,"physics.class-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The article is devoted to the Abraham force in a conducting medium. From the
energy-momentum tensor of the electromagnetic field interaction with moving
charges the equation for the Abraham force is obtained. It is shown that the
Abraham force in a conducting medium, as well as in a dielectric medium, has
vortical character. Current density vectors and vector potential must be
non-collinear
","[{""version"":""v1"",""created"":""Fri, 26 May 2017 03:40:20 GMT""}]","2017-07-28"
